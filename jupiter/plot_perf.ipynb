{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12cfc38d-ceeb-49eb-a0b3-298dfe5d0a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install pandas\n",
    "%pip install matplotlib\n",
    "%pip install seaborn\n",
    "%pip install scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41a15e5a-8968-4fa7-8710-5fc98f175988",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import re\n",
    "\n",
    "# Load data from directories\n",
    "scalar_dir = \"results_scalar\"  # Directory containing scalar CSV files\n",
    "vector_dir = \"results_vector\"  # Directory containing vector CSV file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "899d528c-0f97-4507-a6dc-81d5dae408ce",
   "metadata": {},
   "source": [
    "## Scalar CSV \n",
    "#### Creation of csv file of all perf's results for scalar executables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6e985e1-ea45-4300-ac1e-ee7caa7dc22a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Directory containing the CSV files SCALAR\n",
    "directory = \"results_scalar\"  # Change this to your actual directory\n",
    "\n",
    "# List to hold data from all files\n",
    "dataframes = []\n",
    "\n",
    "# Read all CSV files in the directory\n",
    "# Read all CSV files in the directory\n",
    "for filename in os.listdir(directory):\n",
    "    if filename.endswith(\".csv\"):\n",
    "        filepath = os.path.join(directory, filename)\n",
    "        df = pd.read_csv(filepath)\n",
    "        \n",
    "        # Standardize columns\n",
    "        df.columns = ['Value', 'Unit', 'Metric', 'Percentage', 'Count', 'Total', 'Rate', 'Description']\n",
    "        df.replace('', pd.NA, inplace=True)\n",
    "        df.dropna(subset=['Value'], inplace=True)\n",
    "        df['Value'] = pd.to_numeric(df['Value'])\n",
    "        df['Rate'] = pd.to_numeric(df['Rate'])\n",
    "        \n",
    "        # Add dummy index for pivoting\n",
    "        df['DummyIndex'] = range(len(df))\n",
    "        \n",
    "        # Pivot DataFrame\n",
    "        df_pivot = df.pivot(index='DummyIndex', columns='Metric', values='Value')\n",
    "        df_pivot = df_pivot.reset_index(drop=True)\n",
    "        df_pivot.columns.name = None\n",
    "        \n",
    "        # Rename metrics for clarity\n",
    "        translation_dict = {\n",
    "            'task-clock': 'Task Clock',\n",
    "            'context-switches': 'Context Switch',\n",
    "            'cpu-migrations': 'CPU Migration',\n",
    "            'page-faults': 'Page Faults',\n",
    "            'cycles': 'Cycles',\n",
    "            'instructions': 'Instructions',\n",
    "            'branches': 'Branches',\n",
    "            'branch-misses': 'Branch Misses'\n",
    "        }\n",
    "        df_pivot.rename(columns=translation_dict, inplace=True)\n",
    "        \n",
    "        # Extract sparsity and stride from filename\n",
    "        match = re.search(r\"sparsity_(\\d+)_stride_(\\d+)\", filename)\n",
    "        if match:\n",
    "            sparsity = int(match.group(1))\n",
    "            stride = int(match.group(2))\n",
    "        else:\n",
    "            sparsity = None\n",
    "            stride = None\n",
    "        \n",
    "        # Add extracted data to DataFrame\n",
    "        df_pivot['Executable'] = os.path.splitext(filename)[0]\n",
    "        df_pivot['Sparsity Level'] = sparsity\n",
    "        df_pivot['Stride'] = stride\n",
    "        \n",
    "        dataframes.append(df_pivot)\n",
    "# Merge all DataFrames into one\n",
    "final_df = pd.concat(dataframes, ignore_index=True)\n",
    "# Sort the DataFrame by the 'Executable' column in alphabetical order\n",
    "final_df_sorted = final_df.sort_values(by='Executable')\n",
    "\n",
    "# If you want to sort in descending order (Z to A), add the ascending=False parameter\n",
    "# final_df_sorted = final_df.sort_values(by='Executable', ascending=False)\n",
    "\n",
    "# Reset the index if you want a fresh index after sorting\n",
    "final_df_sorted = final_df_sorted.reset_index(drop=True)\n",
    "name_csv=f\"all_{directory}.csv\"\n",
    "final_df_sorted.to_csv(name_csv)\n",
    "# Display the sorted DataFrame\n",
    "final_df_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0240bfd5-dcfd-455a-9db0-7cc3b853aba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Visualization\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(final_df_sorted.drop(columns=['Executable']).corr(), annot=True, cmap='coolwarm')\n",
    "plt.title(\"Correlation Between Metrics\")\n",
    "plt.show()\n",
    "\n",
    "# Cycles vs Sparsity Level\n",
    "if 'Sparsity Level' in final_df_sorted.columns:\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.scatterplot(x='Sparsity Level', y='Cycles', hue='Executable', data=final_df_sorted)\n",
    "    plt.legend(bbox_to_anchor=(1.02, 1), loc='upper left', borderaxespad=0)\n",
    "    plt.title(\"Cycles vs. Sparsity Level\")\n",
    "    plt.show()\n",
    "\n",
    "# Cycles vs Stride\n",
    "if 'Stride' in final_df_sorted.columns:\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.scatterplot(x='Stride', y='Cycles', hue='Executable', data=final_df_sorted)\n",
    "    plt.legend(bbox_to_anchor=(1.02, 1), loc='upper left', borderaxespad=0)\n",
    "    plt.title(\"Cycles vs. Stride\")\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00285117-4e03-45f6-ace3-23b20b0380f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df_grouped = final_df.groupby('Executable')['Cycles'].sum().reset_index()\n",
    "\n",
    "# Bar plot for grouped cycle count\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.barplot(x='Executable', y='Cycles', data=final_df_grouped)\n",
    "plt.xticks(rotation=90)\n",
    "plt.title(\"Total Cycle Count per Executable\")\n",
    "plt.show()\n",
    "\n",
    "# Violin plot for cycle count distribution\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.violinplot(x='Executable', y='Cycles', data=final_df_sorted)\n",
    "plt.xticks(rotation=90)\n",
    "plt.title(\"Cycle Count Distribution (Violin Plot)\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40b3e141-c0c2-4c44-a339-13063c702abb",
   "metadata": {},
   "source": [
    "## Vector CSV \n",
    "#### Creation of csv file of all perf's results for vectorized executables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e769c3a6-b2a5-4259-9403-1b0cd9bd8fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Directory containing the CSV files VECTOR\n",
    "directory = \"results_vector\"  # Change this to your actual directory\n",
    "\n",
    "# List to hold data from all files\n",
    "dataframes = []\n",
    "\n",
    "# Read all CSV files in the directory\n",
    "# Read all CSV files in the directory\n",
    "for filename in os.listdir(directory):\n",
    "    if filename.endswith(\".csv\"):\n",
    "        filepath = os.path.join(directory, filename)\n",
    "        df = pd.read_csv(filepath)\n",
    "        \n",
    "        # Standardize columns\n",
    "        df.columns = ['Value', 'Unit', 'Metric', 'Percentage', 'Count', 'Total', 'Rate', 'Description']\n",
    "        df.replace('', pd.NA, inplace=True)\n",
    "        df.dropna(subset=['Value'], inplace=True)\n",
    "        df['Value'] = pd.to_numeric(df['Value'])\n",
    "        df['Rate'] = pd.to_numeric(df['Rate'])\n",
    "        \n",
    "        # Add dummy index for pivoting\n",
    "        df['DummyIndex'] = range(len(df))\n",
    "        \n",
    "        # Pivot DataFrame\n",
    "        df_pivot = df.pivot(index='DummyIndex', columns='Metric', values='Value')\n",
    "        df_pivot = df_pivot.reset_index(drop=True)\n",
    "        df_pivot.columns.name = None\n",
    "        \n",
    "        # Rename metrics for clarity\n",
    "        translation_dict = {\n",
    "            'task-clock': 'Task Clock',\n",
    "            'context-switches': 'Context Switch',\n",
    "            'cpu-migrations': 'CPU Migration',\n",
    "            'page-faults': 'Page Faults',\n",
    "            'cycles': 'Cycles',\n",
    "            'instructions': 'Instructions',\n",
    "            'branches': 'Branches',\n",
    "            'branch-misses': 'Branch Misses'\n",
    "        }\n",
    "        df_pivot.rename(columns=translation_dict, inplace=True)\n",
    "        \n",
    "        # Extract sparsity and stride from filename\n",
    "        match = re.search(r\"sparsity_(\\d+)_stride_(\\d+)\", filename)\n",
    "        if match:\n",
    "            sparsity = int(match.group(1))\n",
    "            stride = int(match.group(2))\n",
    "        else:\n",
    "            sparsity = None\n",
    "            stride = None\n",
    "        \n",
    "        # Add extracted data to DataFrame\n",
    "        df_pivot['Executable'] = os.path.splitext(filename)[0]\n",
    "        df_pivot['Sparsity Level'] = sparsity\n",
    "        df_pivot['Stride'] = stride\n",
    "        \n",
    "        dataframes.append(df_pivot)\n",
    "# Merge all DataFrames into one\n",
    "final_df = pd.concat(dataframes, ignore_index=True)\n",
    "# Sort the DataFrame by the 'Executable' column in alphabetical order\n",
    "final_df_sorted = final_df.sort_values(by='Executable')\n",
    "\n",
    "# If you want to sort in descending order (Z to A), add the ascending=False parameter\n",
    "# final_df_sorted = final_df.sort_values(by='Executable', ascending=False)\n",
    "\n",
    "# Reset the index if you want a fresh index after sorting\n",
    "final_df_sorted = final_df_sorted.reset_index(drop=True)\n",
    "name_csv=f\"all_{directory}.csv\"\n",
    "final_df_sorted.to_csv(name_csv)\n",
    "# Display the sorted DataFrame\n",
    "final_df_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34749fb3-e128-49bf-b66d-165b6eb949fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Visualization\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(final_df_sorted.drop(columns=['Executable']).corr(), annot=True, cmap='coolwarm')\n",
    "plt.title(\"Correlation Between Metrics\")\n",
    "plt.show()\n",
    "\n",
    "# Cycles vs Sparsity Level\n",
    "if 'Sparsity Level' in final_df_sorted.columns:\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.scatterplot(x='Sparsity Level', y='Cycles', hue='Executable', data=final_df_sorted)\n",
    "    plt.legend(bbox_to_anchor=(1.02, 1), loc='upper left', borderaxespad=0)\n",
    "\n",
    "    plt.title(\"Cycles vs. Sparsity Level\")\n",
    "    plt.show()\n",
    "\n",
    "# Cycles vs Stride\n",
    "if 'Stride' in final_df_sorted.columns:\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.scatterplot(x='Stride', y='Cycles', hue='Executable', data=final_df_sorted)\n",
    "    plt.legend(bbox_to_anchor=(1.02, 1), loc='upper left', borderaxespad=0)\n",
    "\n",
    "    plt.title(\"Cycles vs. Stride\")\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3625b4e2-d788-4446-ab6c-e8835b9b21da",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df_grouped = final_df.groupby('Executable')['Cycles'].sum().reset_index()\n",
    "\n",
    "# Bar plot for grouped cycle count\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.barplot(x='Executable', y='Cycles', data=final_df_grouped)\n",
    "plt.xticks(rotation=90)\n",
    "plt.title(\"Total Cycle Count per Executable\")\n",
    "plt.show()\n",
    "\n",
    "# Violin plot for cycle count distribution\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.violinplot(x='Executable', y='Cycles', data=final_df_sorted)\n",
    "plt.xticks(rotation=90)\n",
    "plt.title(\"Cycle Count Distribution (Violin Plot)\")\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d6df3c7-7aae-439d-a81d-99fa7d80d103",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import os\n",
    "\n",
    "# Set plot style\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_context(\"notebook\", font_scale=1.2)\n",
    "\n",
    "# Define the data processing functions\n",
    "def load_and_process_data(vector_file, scalar_file):\n",
    "    \"\"\"\n",
    "    Load and process the vector and scalar data from CSV files.\n",
    "    \n",
    "    Parameters:\n",
    "    vector_file (str): Path to the vector CSV file\n",
    "    scalar_file (str): Path to the scalar CSV file\n",
    "    \n",
    "    Returns:\n",
    "    tuple: (vector_df, scalar_df, combined_df)\n",
    "    \"\"\"\n",
    "    # Load the CSV files\n",
    "    vector_raw = pd.read_csv(vector_file)\n",
    "    scalar_raw = pd.read_csv(scalar_file)\n",
    "    \n",
    "    # Add a column to identify the source\n",
    "    vector_raw['Implementation'] = 'Vector'\n",
    "    scalar_raw['Implementation'] = 'Scalar'\n",
    "    \n",
    "    # The data is stored in a sparse format where each row has only one metric value\n",
    "    # Let's reshape it to have one row per experiment\n",
    "    \n",
    "    def reshape_df(df):\n",
    "        # Initialize dictionary to store results\n",
    "        results = {}\n",
    "        \n",
    "        # Extract unique combinations of Executable, Sparsity Level, and Stride\n",
    "        unique_exps = df[['Executable', 'Sparsity Level', 'Stride']].drop_duplicates()\n",
    "        \n",
    "        # For each unique experiment\n",
    "        for _, exp in unique_exps.iterrows():\n",
    "            exe = exp['Executable']\n",
    "            sparsity = exp['Sparsity Level']\n",
    "            stride = exp['Stride']\n",
    "            \n",
    "            # Create a key for this experiment\n",
    "            key = (exe, sparsity, stride)\n",
    "            results[key] = {'Executable': exe, \n",
    "                           'Sparsity Level': sparsity, \n",
    "                           'Stride': stride,\n",
    "                           'Implementation': df['Implementation'].iloc[0]}\n",
    "            \n",
    "            # Find all rows for this experiment\n",
    "            mask = ((df['Executable'] == exe) & \n",
    "                   (df['Sparsity Level'] == sparsity) & \n",
    "                   (df['Stride'] == stride))\n",
    "            \n",
    "            # For each metric, find the corresponding value\n",
    "            for metric in ['Branch Misses', 'Branches', 'Context Switch', 'CPU Migration', \n",
    "                          'Cycles', 'Instructions', 'Page Faults']:\n",
    "                metric_row = df[mask & ~df[metric].isna()]\n",
    "                if len(metric_row) > 0:\n",
    "                    results[key][f'{metric}_value'] = metric_row[metric].iloc[0]\n",
    "        \n",
    "        # Convert results to DataFrame\n",
    "        return pd.DataFrame(list(results.values()))\n",
    "    \n",
    "    # Reshape both dataframes\n",
    "    vector_df = reshape_df(vector_raw)\n",
    "    scalar_df = reshape_df(scalar_raw)\n",
    "    \n",
    "    # Combine them\n",
    "    combined_df = pd.concat([vector_df, scalar_df], ignore_index=True)\n",
    "    \n",
    "    return vector_df, scalar_df, combined_df\n",
    "\n",
    "def calculate_speedup(vector_df, scalar_df):\n",
    "    \"\"\"\n",
    "    Calculate speedup of vector implementation over scalar.\n",
    "    \n",
    "    Parameters:\n",
    "    vector_df (DataFrame): Vector processed dataframe\n",
    "    scalar_df (DataFrame): Scalar processed dataframe\n",
    "    \n",
    "    Returns:\n",
    "    DataFrame: Speedup metrics\n",
    "    \"\"\"\n",
    "    # Merge on Sparsity Level and Stride\n",
    "    merged = pd.merge(vector_df, scalar_df, \n",
    "                     on=['Sparsity Level', 'Stride'],\n",
    "                     suffixes=('_vector', '_scalar'))\n",
    "    \n",
    "    # Calculate speedup metrics\n",
    "    merged['cycles_speedup'] = merged['Cycles_value_scalar'] / merged['Cycles_value_vector']\n",
    "    merged['instructions_speedup'] = merged['Instructions_value_scalar'] / merged['Instructions_value_vector']\n",
    "    merged['branches_speedup'] = merged['Branches_value_scalar'] / merged['Branches_value_vector']\n",
    "    \n",
    "    return merged[['Sparsity Level', 'Stride', 'cycles_speedup', \n",
    "                  'instructions_speedup', 'branches_speedup']]\n",
    "\n",
    "def perform_statistical_analysis(combined_df):\n",
    "    \"\"\"\n",
    "    Perform statistical analysis to determine significance of relationships.\n",
    "    \"\"\"\n",
    "    results = {}\n",
    "    \n",
    "    # For vector implementation\n",
    "    vector_data = combined_df[combined_df['Implementation'] == 'Vector']\n",
    "    \n",
    "    # Correlation between sparsity and cycles for vector\n",
    "    corr_sparsity_cycles_v = stats.pearsonr(\n",
    "        vector_data['Sparsity Level'], vector_data['Cycles_value'])\n",
    "    results['Vector Sparsity-Cycles Correlation'] = {\n",
    "        'r': corr_sparsity_cycles_v[0],\n",
    "        'p-value': corr_sparsity_cycles_v[1]\n",
    "    }\n",
    "    \n",
    "    # Correlation between stride and cycles for vector\n",
    "    corr_stride_cycles_v = stats.pearsonr(\n",
    "        vector_data['Stride'], vector_data['Cycles_value'])\n",
    "    results['Vector Stride-Cycles Correlation'] = {\n",
    "        'r': corr_stride_cycles_v[0],\n",
    "        'p-value': corr_stride_cycles_v[1]\n",
    "    }\n",
    "    \n",
    "    # For scalar implementation\n",
    "    scalar_data = combined_df[combined_df['Implementation'] == 'Scalar']\n",
    "    \n",
    "    # Correlation between sparsity and cycles for scalar\n",
    "    corr_sparsity_cycles_s = stats.pearsonr(\n",
    "        scalar_data['Sparsity Level'], scalar_data['Cycles_value'])\n",
    "    results['Scalar Sparsity-Cycles Correlation'] = {\n",
    "        'r': corr_sparsity_cycles_s[0],\n",
    "        'p-value': corr_sparsity_cycles_s[1]\n",
    "    }\n",
    "    \n",
    "    # Correlation between stride and cycles for scalar\n",
    "    corr_stride_cycles_s = stats.pearsonr(\n",
    "        scalar_data['Stride'], scalar_data['Cycles_value'])\n",
    "    results['Scalar Stride-Cycles Correlation'] = {\n",
    "        'r': corr_stride_cycles_s[0],\n",
    "        'p-value': corr_stride_cycles_s[1]\n",
    "    }\n",
    "    \n",
    "    # T-test comparing cycles between vector and scalar implementations\n",
    "    vector_cycles = vector_data['Cycles_value']\n",
    "    scalar_cycles = scalar_data['Cycles_value']\n",
    "    ttest_result = stats.ttest_ind(vector_cycles, scalar_cycles)\n",
    "    results['Vector vs Scalar Cycles T-test'] = {\n",
    "        't-statistic': ttest_result[0],\n",
    "        'p-value': ttest_result[1]\n",
    "    }\n",
    "    \n",
    "    return results\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Main function to execute the analysis.\n",
    "    \"\"\"\n",
    "    # File paths - update these with your actual file paths\n",
    "    vector_file = 'all_results_vector.csv'\n",
    "    scalar_file = 'all_results_scalar.csv'\n",
    "    \n",
    "    # Create output directory for plots if it doesn't exist\n",
    "    output_dir = 'analysis_output'\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "    \n",
    "    # Load and process data\n",
    "    print(\"Loading and processing data...\")\n",
    "    vector_df, scalar_df, combined_df = load_and_process_data(vector_file, scalar_file)\n",
    "    \n",
    "    # Calculate speedup\n",
    "    print(\"Calculating speedup metrics...\")\n",
    "    speedup_df = calculate_speedup(vector_df, scalar_df)\n",
    "    \n",
    "    # Perform statistical analysis\n",
    "    print(\"Performing statistical analysis...\")\n",
    "    stats_results = perform_statistical_analysis(combined_df)\n",
    "    \n",
    "    # Generate plots\n",
    "    print(\"Generating plots...\")\n",
    "    \n",
    "    # Plot 1: Sparsity Impact\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    for implementation in ['Vector', 'Scalar']:\n",
    "        for stride in [1, 3, 5]:\n",
    "            subset = combined_df[(combined_df['Implementation'] == implementation) & \n",
    "                                (combined_df['Stride'] == stride)]\n",
    "            plt.plot(subset['Sparsity Level'], subset['Cycles_value'], \n",
    "                    marker='o' if implementation == 'Vector' else 's',\n",
    "                    linestyle='-' if implementation == 'Vector' else '--',\n",
    "                    label=f\"{implementation}, Stride={stride}\")\n",
    "    \n",
    "    plt.title('Impact of Sparsity Level on Cycles')\n",
    "    plt.xlabel('Sparsity Level (%)')\n",
    "    plt.ylabel('Cycles')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.legend(loc='best')\n",
    "    plt.savefig(f\"{output_dir}/sparsity_impact_on_cycles.png\", dpi=300, bbox_inches='tight')\n",
    "    \n",
    "    # Plot 2: Stride Impact\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    for implementation in ['Vector', 'Scalar']:\n",
    "        for sparsity in [50, 60, 70, 80, 90]:\n",
    "            subset = combined_df[(combined_df['Implementation'] == implementation) & \n",
    "                                (combined_df['Sparsity Level'] == sparsity)]\n",
    "            plt.plot(subset['Stride'], subset['Cycles_value'], \n",
    "                    marker='o' if implementation == 'Vector' else 's',\n",
    "                    linestyle='-' if implementation == 'Vector' else '--',\n",
    "                    label=f\"{implementation}, Sparsity={sparsity}%\")\n",
    "    \n",
    "    plt.title('Impact of Stride on Cycles')\n",
    "    plt.xlabel('Stride')\n",
    "    plt.ylabel('Cycles')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.legend(loc='best')\n",
    "    plt.savefig(f\"{output_dir}/stride_impact_on_cycles.png\", dpi=300, bbox_inches='tight')\n",
    "    \n",
    "    # Plot 3: Speedup Heatmap for Cycles\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    pivot_df = speedup_df.pivot(index='Stride', columns='Sparsity Level', values='cycles_speedup')\n",
    "    sns.heatmap(pivot_df, annot=True, fmt=\".2f\", cmap=\"YlGnBu\", \n",
    "               cbar_kws={'label': 'Speedup (Scalar/Vector)'})\n",
    "    plt.title('Cycles Speedup (Scalar/Vector): Impact of Sparsity Level and Stride')\n",
    "    plt.xlabel('Sparsity Level (%)')\n",
    "    plt.ylabel('Stride')\n",
    "    plt.savefig(f\"{output_dir}/cycles_speedup_heatmap.png\", dpi=300, bbox_inches='tight')\n",
    "    \n",
    "    # Plot 4: Instructions Comparison\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    for implementation in ['Vector', 'Scalar']:\n",
    "        grouped = combined_df[combined_df['Implementation'] == implementation].groupby('Sparsity Level')['Instructions_value'].mean()\n",
    "        plt.plot(grouped.index, grouped.values, \n",
    "                marker='o' if implementation == 'Vector' else 's',\n",
    "                linestyle='-' if implementation == 'Vector' else '--',\n",
    "                linewidth=2, markersize=8,\n",
    "                label=f\"{implementation}\")\n",
    "    \n",
    "    plt.title('Average Instructions by Sparsity Level')\n",
    "    plt.xlabel('Sparsity Level (%)')\n",
    "    plt.ylabel('Instructions')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.legend(loc='best')\n",
    "    plt.savefig(f\"{output_dir}/avg_instructions_by_sparsity.png\", dpi=300, bbox_inches='tight')\n",
    "    \n",
    "    # Plot 5: Instructions Speedup by Sparsity Level\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    avg_speedup = speedup_df.groupby('Sparsity Level')['instructions_speedup'].mean()\n",
    "    plt.bar(avg_speedup.index, avg_speedup.values, color='skyblue', edgecolor='navy')\n",
    "    plt.axhline(y=1.0, color='red', linestyle='--', alpha=0.7)\n",
    "    plt.title('Average Instructions Speedup by Sparsity Level')\n",
    "    plt.xlabel('Sparsity Level (%)')\n",
    "    plt.ylabel('Instructions Speedup (Scalar/Vector)')\n",
    "    plt.grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    for i, v in enumerate(avg_speedup.values):\n",
    "        plt.text(avg_speedup.index[i], v + 0.1, f\"{v:.2f}\", ha='center')\n",
    "    \n",
    "    plt.savefig(f\"{output_dir}/avg_instructions_speedup_by_sparsity.png\", dpi=300, bbox_inches='tight')\n",
    "    \n",
    "    # Plot 6: Combined analysis of branch misses\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    for implementation in ['Vector', 'Scalar']:\n",
    "        for stride in [1, 3, 5]:\n",
    "            subset = combined_df[(combined_df['Implementation'] == implementation) & \n",
    "                                (combined_df['Stride'] == stride)]\n",
    "            plt.scatter(subset['Sparsity Level'], subset['Branch Misses_value'], \n",
    "                       s=100, alpha=0.7,\n",
    "                       marker='o' if implementation == 'Vector' else 's',\n",
    "                       label=f\"{implementation}, Stride={stride}\")\n",
    "    \n",
    "    plt.title('Branch Misses vs Sparsity Level')\n",
    "    plt.xlabel('Sparsity Level (%)')\n",
    "    plt.ylabel('Branch Misses')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.legend(loc='best')\n",
    "    plt.savefig(f\"{output_dir}/branch_misses_vs_sparsity.png\", dpi=300, bbox_inches='tight')\n",
    "    \n",
    "    # Save statistical analysis results\n",
    "    with open(f\"{output_dir}/statistical_analysis.txt\", 'w') as f:\n",
    "        f.write(\"Statistical Analysis Results\\n\")\n",
    "        f.write(\"============================\\n\\n\")\n",
    "        for key, value in stats_results.items():\n",
    "            f.write(f\"{key}:\\n\")\n",
    "            for stat_key, stat_value in value.items():\n",
    "                f.write(f\"  {stat_key}: {stat_value}\\n\")\n",
    "            f.write(\"\\n\")\n",
    "    \n",
    "    # Print summary of findings\n",
    "    print(\"\\nSummary of Analysis:\")\n",
    "    print(\"===================\")\n",
    "    print(f\"1. Average cycles speedup (scalar/vector): {speedup_df['cycles_speedup'].mean():.2f}x\")\n",
    "    print(f\"2. Average instructions speedup: {speedup_df['instructions_speedup'].mean():.2f}x\")\n",
    "    \n",
    "    # Vector vs Scalar overall comparison\n",
    "    vector_cycles = combined_df[combined_df['Implementation'] == 'Vector']['Cycles_value'].mean()\n",
    "    scalar_cycles = combined_df[combined_df['Implementation'] == 'Scalar']['Cycles_value'].mean()\n",
    "    print(f\"3. Average cycles - Vector: {vector_cycles:.2f}, Scalar: {scalar_cycles:.2f}\")\n",
    "    \n",
    "    # Best speedup scenario\n",
    "    best_speedup_idx = speedup_df['cycles_speedup'].idxmax()\n",
    "    best_scenario = speedup_df.iloc[best_speedup_idx]\n",
    "    print(f\"4. Best cycles speedup: {best_scenario['cycles_speedup']:.2f}x at Sparsity={best_scenario['Sparsity Level']}%, Stride={best_scenario['Stride']}\")\n",
    "    \n",
    "    # Worst speedup scenario\n",
    "    worst_speedup_idx = speedup_df['cycles_speedup'].idxmin()\n",
    "    worst_scenario = speedup_df.iloc[worst_speedup_idx]\n",
    "    print(f\"5. Worst cycles speedup: {worst_scenario['cycles_speedup']:.2f}x at Sparsity={worst_scenario['Sparsity Level']}%, Stride={worst_scenario['Stride']}\")\n",
    "    \n",
    "    # Sparsity impact\n",
    "    high_sparsity = combined_df[combined_df['Sparsity Level'] >= 80]\n",
    "    low_sparsity = combined_df[combined_df['Sparsity Level'] <= 60]\n",
    "    \n",
    "    high_sparsity_vector = high_sparsity[high_sparsity['Implementation'] == 'Vector']['Cycles_value'].mean()\n",
    "    high_sparsity_scalar = high_sparsity[high_sparsity['Implementation'] == 'Scalar']['Cycles_value'].mean()\n",
    "    \n",
    "    low_sparsity_vector = low_sparsity[low_sparsity['Implementation'] == 'Vector']['Cycles_value'].mean()\n",
    "    low_sparsity_scalar = low_sparsity[low_sparsity['Implementation'] == 'Scalar']['Cycles_value'].mean()\n",
    "    \n",
    "    print(f\"6. High sparsity (>=80%) - Vector: {high_sparsity_vector:.2f}, Scalar: {high_sparsity_scalar:.2f}, Ratio: {high_sparsity_scalar/high_sparsity_vector:.2f}x\")\n",
    "    print(f\"7. Low sparsity (<=60%) - Vector: {low_sparsity_vector:.2f}, Scalar: {low_sparsity_scalar:.2f}, Ratio: {low_sparsity_scalar/low_sparsity_vector:.2f}x\")\n",
    "    \n",
    "    # Stride impact\n",
    "    high_stride = combined_df[combined_df['Stride'] >= 4]\n",
    "    low_stride = combined_df[combined_df['Stride'] <= 2]\n",
    "    \n",
    "    high_stride_vector = high_stride[high_stride['Implementation'] == 'Vector']['Cycles_value'].mean()\n",
    "    high_stride_scalar = high_stride[high_stride['Implementation'] == 'Scalar']['Cycles_value'].mean()\n",
    "    \n",
    "    low_stride_vector = low_stride[low_stride['Implementation'] == 'Vector']['Cycles_value'].mean()\n",
    "    low_stride_scalar = low_stride[low_stride['Implementation'] == 'Scalar']['Cycles_value'].mean()\n",
    "    \n",
    "    print(f\"8. High stride (>=4) - Vector: {high_stride_vector:.2f}, Scalar: {high_stride_scalar:.2f}, Ratio: {high_stride_scalar/high_stride_vector:.2f}x\")\n",
    "    print(f\"9. Low stride (<=2) - Vector: {low_stride_vector:.2f}, Scalar: {low_stride_scalar:.2f}, Ratio: {low_stride_scalar/low_stride_vector:.2f}x\")\n",
    "    \n",
    "    # Save all dataframes\n",
    "    vector_df.to_csv(f\"{output_dir}/processed_vector_data.csv\", index=False)\n",
    "    scalar_df.to_csv(f\"{output_dir}/processed_scalar_data.csv\", index=False)\n",
    "    combined_df.to_csv(f\"{output_dir}/combined_data.csv\", index=False)\n",
    "    speedup_df.to_csv(f\"{output_dir}/speedup_metrics.csv\", index=False)\n",
    "    \n",
    "    print(\"\\nAnalysis complete. All results saved to the 'analysis_output' directory.\")\n",
    "\n",
    "\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d9ce77d-3976-40c3-99b3-d2b0550e60a7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
