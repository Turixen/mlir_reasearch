{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c773db7b-01c6-4ccb-aca4-3eac1067d44c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/giorgiomastrotucci/Desktop/Lavoro/AssegnoDiRicerca/mlir_research\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "11008fa9-6c98-41c3-9669-0e72a68523d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and processing data...\n",
      "Calculating speedup metrics...\n",
      "Performing stride-specific analysis...\n",
      "Creating comparative stride analysis...\n",
      "                       Executable  Sparsity Level  Stride Implementation  \\\n",
      "0       mlir_sparsity_50_stride_1              50       1         Vector   \n",
      "1       mlir_sparsity_50_stride_2              50       2         Vector   \n",
      "2       mlir_sparsity_50_stride_3              50       3         Vector   \n",
      "3       mlir_sparsity_55_stride_1              55       1         Vector   \n",
      "4  mlir_sparsity_55_stride_1.llvm              55       1         Vector   \n",
      "\n",
      "   Branch Misses_value  Branches_value  Context Switch_value  \\\n",
      "0              13576.0        189528.0                   0.0   \n",
      "1              13591.0        189648.0                   0.0   \n",
      "2              13522.0        190032.0                   0.0   \n",
      "3              13643.0        181967.0                   0.0   \n",
      "4              13546.0        182473.0                   0.0   \n",
      "\n",
      "   CPU Migration_value  Cycles_value  Instructions_value  Page Faults_value  \n",
      "0                  0.0     6650325.0           1716217.0               82.0  \n",
      "1                  0.0     6693349.0           1718520.0               83.0  \n",
      "2                  0.0     6731025.0           1722838.0               82.0  \n",
      "3                  0.0     6419326.0           1641647.0               83.0  \n",
      "4                  0.0     6550326.0           1587444.0               83.0  \n",
      "                  Executable  Sparsity Level  Stride Implementation  \\\n",
      "0  mlir_sparsity_50_stride_1              50       1         Scalar   \n",
      "1  mlir_sparsity_50_stride_2              50       2         Scalar   \n",
      "2  mlir_sparsity_50_stride_3              50       3         Scalar   \n",
      "3  mlir_sparsity_55_stride_1              55       1         Scalar   \n",
      "4  mlir_sparsity_55_stride_2              55       2         Scalar   \n",
      "\n",
      "   Branch Misses_value  Branches_value  Context Switch_value  \\\n",
      "0              13742.0        620989.0                   0.0   \n",
      "1              13588.0        620953.0                   0.0   \n",
      "2              13611.0        620548.0                   0.0   \n",
      "3              13626.0        570344.0                   0.0   \n",
      "4              13629.0        568754.0                   0.0   \n",
      "\n",
      "   CPU Migration_value  Cycles_value  Instructions_value  Page Faults_value  \n",
      "0                  0.0    10100090.0           6499674.0               83.0  \n",
      "1                  0.0    10032793.0           6500318.0               83.0  \n",
      "2                  0.0    10052251.0           6496454.0               83.0  \n",
      "3                  0.0     9510600.0           5944308.0               83.0  \n",
      "4                  0.0     9428167.0           5933093.0               83.0  \n",
      "   Sparsity Level  Stride  cycles_speedup  instructions_speedup  \\\n",
      "0              50       1        1.518736              3.787210   \n",
      "1              50       2        1.498920              3.782509   \n",
      "2              50       3        1.493421              3.770786   \n",
      "3              55       1        1.481557              3.620942   \n",
      "4              55       1        1.451928              3.744578   \n",
      "\n",
      "   branches_speedup  \n",
      "0          3.276503  \n",
      "1          3.274240  \n",
      "2          3.265492  \n",
      "3          3.134327  \n",
      "4          3.125635  \n",
      "Generating overall instructions speedup plot...\n",
      "\n",
      "Analysis complete. Results organized by stride in the 'stride_grouped_analysis' directory.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import os\n",
    "\n",
    "# Set plot style\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_context(\"notebook\", font_scale=1.2)\n",
    "\n",
    "# Define the data processing functions\n",
    "def load_and_process_data(vector_file, scalar_file):\n",
    "    \"\"\"\n",
    "    Load and process the vector and scalar data from CSV files.\n",
    "    \n",
    "    Parameters:\n",
    "    vector_file (str): Path to the vector CSV file\n",
    "    scalar_file (str): Path to the scalar CSV file\n",
    "    \n",
    "    Returns:\n",
    "    tuple: (vector_df, scalar_df, combined_df)\n",
    "    \"\"\"\n",
    "    # Load the CSV files\n",
    "    vector_raw = pd.read_csv(vector_file)\n",
    "    scalar_raw = pd.read_csv(scalar_file)\n",
    "    \n",
    "    # Add a column to identify the source\n",
    "    vector_raw['Implementation'] = 'Vector'\n",
    "    scalar_raw['Implementation'] = 'Scalar'\n",
    "    \n",
    "    # The data is stored in a sparse format where each row has only one metric value\n",
    "    # Let's reshape it to have one row per experiment\n",
    "    \n",
    "    def reshape_df(df):\n",
    "        # Initialize dictionary to store results\n",
    "        results = {}\n",
    "        \n",
    "        # Extract unique combinations of Executable, Sparsity Level, and Stride\n",
    "        unique_exps = df[['Executable', 'Sparsity Level', 'Stride']].drop_duplicates()\n",
    "        \n",
    "        # For each unique experiment\n",
    "        for _, exp in unique_exps.iterrows():\n",
    "            exe = exp['Executable']\n",
    "            sparsity = exp['Sparsity Level']\n",
    "            stride = exp['Stride']\n",
    "            \n",
    "            # Create a key for this experiment\n",
    "            key = (exe, sparsity, stride)\n",
    "            results[key] = {'Executable': exe, \n",
    "                           'Sparsity Level': sparsity, \n",
    "                           'Stride': stride,\n",
    "                           'Implementation': df['Implementation'].iloc[0]}\n",
    "            \n",
    "            # Find all rows for this experiment\n",
    "            mask = ((df['Executable'] == exe) & \n",
    "                   (df['Sparsity Level'] == sparsity) & \n",
    "                   (df['Stride'] == stride))\n",
    "            \n",
    "            # For each metric, find the corresponding value\n",
    "            for metric in ['Branch Misses', 'Branches', 'Context Switch', 'CPU Migration', \n",
    "                          'Cycles', 'Instructions', 'Page Faults']:\n",
    "                metric_row = df[mask & ~df[metric].isna()]\n",
    "                if len(metric_row) > 0:\n",
    "                    results[key][f'{metric}_value'] = metric_row[metric].iloc[0]\n",
    "        \n",
    "        # Convert results to DataFrame\n",
    "        return pd.DataFrame(list(results.values()))\n",
    "    \n",
    "    # Reshape both dataframes\n",
    "    vector_df = reshape_df(vector_raw)\n",
    "    scalar_df = reshape_df(scalar_raw)\n",
    "    \n",
    "    # Combine them\n",
    "    combined_df = pd.concat([vector_df, scalar_df], ignore_index=True)\n",
    "    \n",
    "    return vector_df, scalar_df, combined_df\n",
    "\n",
    "def calculate_speedup_by_stride(vector_df, scalar_df):\n",
    "    \"\"\"\n",
    "    Calculate speedup of vector implementation over scalar, grouped by stride.\n",
    "    \n",
    "    Parameters:\n",
    "    vector_df (DataFrame): Vector processed dataframe\n",
    "    scalar_df (DataFrame): Scalar processed dataframe\n",
    "    \n",
    "    Returns:\n",
    "    DataFrame: Speedup metrics with stride information\n",
    "    \"\"\"\n",
    "    # Merge on Sparsity Level and Stride\n",
    "    merged = pd.merge(vector_df, scalar_df, \n",
    "                     on=['Sparsity Level', 'Stride'],\n",
    "                     suffixes=('_vector', '_scalar'))\n",
    "    \n",
    "    # Calculate speedup metrics\n",
    "    merged['cycles_speedup'] = merged['Cycles_value_scalar'] / merged['Cycles_value_vector']\n",
    "    merged['instructions_speedup'] = merged['Instructions_value_scalar'] / merged['Instructions_value_vector']\n",
    "    merged['branches_speedup'] = merged['Branches_value_scalar'] / merged['Branches_value_vector']\n",
    "    \n",
    "    return merged[['Sparsity Level', 'Stride', 'cycles_speedup', \n",
    "                  'instructions_speedup', 'branches_speedup']]\n",
    "\n",
    "def analyze_by_stride(combined_df, speedup_df, output_dir):\n",
    "    \"\"\"\n",
    "    Perform analysis grouped by stride values.\n",
    "    \n",
    "    Parameters:\n",
    "    combined_df (DataFrame): Combined data\n",
    "    speedup_df (DataFrame): Speedup metrics\n",
    "    output_dir (str): Directory to save output files\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    # Get unique stride values\n",
    "    strides = combined_df['Stride'].unique()\n",
    "    strides.sort()\n",
    "    \n",
    "    # Create stride-specific directory\n",
    "    stride_dir = f\"{output_dir}/stride_analysis\"\n",
    "    if not os.path.exists(stride_dir):\n",
    "        os.makedirs(stride_dir)\n",
    "    \n",
    "    # For each stride, perform analysis\n",
    "    for stride in strides:\n",
    "        # Filter data for this stride\n",
    "        stride_df = combined_df[combined_df['Stride'] == stride]\n",
    "        stride_speedup = speedup_df[speedup_df['Stride'] == stride]\n",
    "\n",
    "        # Create stride-specific output directory\n",
    "        stride_specific_dir = f\"{stride_dir}/stride_{stride}\"\n",
    "        if not os.path.exists(stride_specific_dir):\n",
    "            os.makedirs(stride_specific_dir)\n",
    "        \n",
    "        # Generate plots for this stride\n",
    "        \n",
    "        # Plot 1: Sparsity Impact for this stride\n",
    "        plt.figure(figsize=(12, 8))\n",
    "        for implementation in ['Vector', 'Scalar']:\n",
    "            subset = stride_df[stride_df['Implementation'] == implementation]\n",
    "            plt.plot(subset['Sparsity Level'], subset['Cycles_value'], \n",
    "                    marker='o' if implementation == 'Vector' else 's',\n",
    "                    linestyle='-' if implementation == 'Vector' else '--',\n",
    "                    label=f\"{implementation}\")\n",
    "        \n",
    "        plt.title(f'Impact of Sparsity Level on Cycles (Stride {stride})')\n",
    "        plt.xlabel('Sparsity Level (%)')\n",
    "        plt.ylabel('Cycles')\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        plt.legend(loc='best')\n",
    "        plt.savefig(f\"{stride_specific_dir}/sparsity_impact_on_cycles.png\", dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        \n",
    "        # Plot 2: Instructions Comparison for this stride\n",
    "        plt.figure(figsize=(12, 8))\n",
    "        for implementation in ['Vector', 'Scalar']:\n",
    "            subset = stride_df[stride_df['Implementation'] == implementation]\n",
    "            plt.plot(subset['Sparsity Level'], subset['Instructions_value'], \n",
    "                    marker='o' if implementation == 'Vector' else 's',\n",
    "                    linestyle='-' if implementation == 'Vector' else '--',\n",
    "                    linewidth=2, markersize=8,\n",
    "                    label=f\"{implementation}\")\n",
    "        \n",
    "        plt.title(f'Instructions by Sparsity Level (Stride {stride})')\n",
    "        plt.xlabel('Sparsity Level (%)')\n",
    "        plt.ylabel('Instructions')\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        plt.legend(loc='best')\n",
    "        plt.savefig(f\"{stride_specific_dir}/instructions_by_sparsity.png\", dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        \n",
    "        # Plot 3: Instructions Speedup by Sparsity Level for this stride\n",
    "        plt.figure(figsize=(12, 8))\n",
    "        plt.bar(stride_speedup['Sparsity Level'], stride_speedup['instructions_speedup'], color='skyblue', edgecolor='navy')\n",
    "        plt.axhline(y=1.0, color='red', linestyle='--', alpha=0.7)\n",
    "        plt.title(f'Instructions Speedup by Sparsity Level (Stride {stride})')\n",
    "        plt.xlabel('Sparsity Level (%)')\n",
    "        plt.ylabel('Instructions Speedup (Scalar/Vector)')\n",
    "        plt.grid(True, alpha=0.3, axis='y')\n",
    "        \n",
    "        for i, v in enumerate(stride_speedup['instructions_speedup']):\n",
    "            plt.text(stride_speedup['Sparsity Level'].iloc[i], v + 0.1, f\"{v:.2f}\", ha='center')\n",
    "        \n",
    "        plt.savefig(f\"{stride_specific_dir}/instructions_speedup_by_sparsity.png\", dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        \n",
    "        # Plot 4: Branch Misses vs Sparsity Level for this stride\n",
    "        plt.figure(figsize=(12, 8))\n",
    "        for implementation in ['Vector', 'Scalar']:\n",
    "            subset = stride_df[stride_df['Implementation'] == implementation]\n",
    "            plt.scatter(subset['Sparsity Level'], subset['Branch Misses_value'], \n",
    "                       s=100, alpha=0.7,\n",
    "                       marker='o' if implementation == 'Vector' else 's',\n",
    "                       label=f\"{implementation}\")\n",
    "        \n",
    "        plt.title(f'Branch Misses vs Sparsity Level (Stride {stride})')\n",
    "        plt.xlabel('Sparsity Level (%)')\n",
    "        plt.ylabel('Branch Misses')\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        plt.legend(loc='best')\n",
    "        plt.savefig(f\"{stride_specific_dir}/branch_misses_vs_sparsity.png\", dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        \n",
    "        # Statistical analysis for this stride\n",
    "        vector_cycles = stride_df[stride_df['Implementation'] == 'Vector']['Cycles_value'].mean()\n",
    "        scalar_cycles = stride_df[stride_df['Implementation'] == 'Scalar']['Cycles_value'].mean()\n",
    "        \n",
    "        vector_instr = stride_df[stride_df['Implementation'] == 'Vector']['Instructions_value'].mean()\n",
    "        scalar_instr = stride_df[stride_df['Implementation'] == 'Scalar']['Instructions_value'].mean()\n",
    "        \n",
    "        # Save summary for this stride\n",
    "        with open(f\"{stride_specific_dir}/summary.txt\", 'w') as f:\n",
    "            f.write(f\"Performance Summary for Stride {stride}\\n\")\n",
    "            f.write(\"===============================\\n\\n\")\n",
    "            f.write(f\"1. Average cycles - Vector: {vector_cycles:.2f}, Scalar: {scalar_cycles:.2f}, Speedup: {scalar_cycles/vector_cycles:.2f}x\\n\")\n",
    "            f.write(f\"2. Average instructions - Vector: {vector_instr:.2f}, Scalar: {scalar_instr:.2f}, Speedup: {scalar_instr/vector_instr:.2f}x\\n\")\n",
    "            \n",
    "            # Best and worst speedup for this stride\n",
    "            if len(stride_speedup) > 0:\n",
    "                best_speedup_idx = stride_speedup['instructions_speedup'].idxmax()\n",
    "                best_scenario = stride_speedup.loc[best_speedup_idx]\n",
    "                f.write(f\"3. Best instructions speedup: {best_scenario['instructions_speedup']:.2f}x at Sparsity={best_scenario['Sparsity Level']}%\\n\")\n",
    "                \n",
    "                worst_speedup_idx = stride_speedup['instructions_speedup'].idxmin()\n",
    "                worst_scenario = stride_speedup.loc[worst_speedup_idx]\n",
    "                f.write(f\"4. Worst instructions speedup: {worst_scenario['instructions_speedup']:.2f}x at Sparsity={worst_scenario['Sparsity Level']}%\\n\")\n",
    "        \n",
    "        # Save stride-specific data\n",
    "        stride_df.to_csv(f\"{stride_specific_dir}/stride_{stride}_data.csv\", index=False)\n",
    "        if len(stride_speedup) > 0:\n",
    "            stride_speedup.to_csv(f\"{stride_specific_dir}/stride_{stride}_speedup.csv\", index=False)\n",
    "\n",
    "def create_comparative_stride_analysis(combined_df, speedup_df, output_dir):\n",
    "    \"\"\"\n",
    "    Create comparative analysis across different strides.\n",
    "    \n",
    "    Parameters:\n",
    "    combined_df (DataFrame): Combined data\n",
    "    speedup_df (DataFrame): Speedup metrics\n",
    "    output_dir (str): Directory to save output files\n",
    "    \"\"\"\n",
    "    stride_dir = f\"{output_dir}/stride_comparison\"\n",
    "    if not os.path.exists(stride_dir):\n",
    "        os.makedirs(stride_dir)\n",
    "    \n",
    "    # Get unique stride values\n",
    "    strides = combined_df['Stride'].unique()\n",
    "    strides.sort()\n",
    "    \n",
    "    # 1. Average Instructions Speedup by Stride\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    avg_speedup_by_stride = speedup_df.groupby('Stride')['instructions_speedup'].mean().reset_index()\n",
    "    \n",
    "    plt.bar(avg_speedup_by_stride['Stride'], avg_speedup_by_stride['instructions_speedup'], \n",
    "           color='skyblue', edgecolor='navy')\n",
    "    plt.axhline(y=1.0, color='red', linestyle='--', alpha=0.7)\n",
    "    \n",
    "    plt.title('Average Instructions Speedup by Stride')\n",
    "    plt.xlabel('Stride')\n",
    "    plt.ylabel('Instructions Speedup (Scalar/Vector)')\n",
    "    plt.grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    for i, v in enumerate(avg_speedup_by_stride['instructions_speedup']):\n",
    "        plt.text(avg_speedup_by_stride['Stride'].iloc[i], v + 0.1, f\"{v:.2f}\", ha='center')\n",
    "    \n",
    "    plt.savefig(f\"{stride_dir}/avg_instructions_speedup_by_stride.png\", dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    # 2. Heatmap of Instructions Speedup by Stride and Sparsity\n",
    "    pivot_data = speedup_df.pivot_table(index='Stride', columns='Sparsity Level', \n",
    "                                       values='instructions_speedup', aggfunc='mean')\n",
    "    \n",
    "    plt.figure(figsize=(14, 8))\n",
    "    sns.heatmap(pivot_data, annot=True, cmap='YlGnBu', fmt='.2f', cbar_kws={'label': 'Instructions Speedup'})\n",
    "    \n",
    "    plt.title('Instructions Speedup Heatmap (Stride vs Sparsity)')\n",
    "    plt.ylabel('Stride')\n",
    "    plt.xlabel('Sparsity Level (%)')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"{stride_dir}/instructions_speedup_heatmap.png\", dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    # 3. Comparative line plot for each stride\n",
    "    plt.figure(figsize=(14, 8))\n",
    "    \n",
    "    for stride in strides:\n",
    "        stride_data = speedup_df[speedup_df['Stride'] == stride]\n",
    "        plt.plot(stride_data['Sparsity Level'], stride_data['instructions_speedup'], \n",
    "                marker='o', linestyle='-', linewidth=2, \n",
    "                label=f\"Stride {stride}\")\n",
    "    \n",
    "    plt.axhline(y=1.0, color='red', linestyle='--', alpha=0.7)\n",
    "    plt.title('Instructions Speedup by Sparsity Level Across Different Strides')\n",
    "    plt.xlabel('Sparsity Level (%)')\n",
    "    plt.ylabel('Instructions Speedup (Scalar/Vector)')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.legend(loc='best')\n",
    "    plt.savefig(f\"{stride_dir}/instructions_speedup_comparison.png\", dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    # Save summary of stride comparison\n",
    "    with open(f\"{stride_dir}/stride_comparison_summary.txt\", 'w') as f:\n",
    "        f.write(\"Stride Comparison Summary\\n\")\n",
    "        f.write(\"========================\\n\\n\")\n",
    "        \n",
    "        for stride in strides:\n",
    "            stride_speedup = speedup_df[speedup_df['Stride'] == stride]['instructions_speedup'].mean()\n",
    "            f.write(f\"Stride {stride} - Average Instructions Speedup: {stride_speedup:.2f}x\\n\")\n",
    "        \n",
    "        f.write(\"\\nBest Performing Combinations:\\n\")\n",
    "        f.write(\"----------------------------\\n\")\n",
    "        \n",
    "        # Top 5 best performing combinations\n",
    "        top5 = speedup_df.nlargest(5, 'instructions_speedup')\n",
    "        for idx, row in top5.iterrows():\n",
    "            f.write(f\"Stride {row['Stride']}, Sparsity {row['Sparsity Level']}% - Speedup: {row['instructions_speedup']:.2f}x\\n\")\n",
    "        \n",
    "        f.write(\"\\nWorst Performing Combinations:\\n\")\n",
    "        f.write(\"-----------------------------\\n\")\n",
    "        \n",
    "        # Top 5 worst performing combinations\n",
    "        bottom5 = speedup_df.nsmallest(5, 'instructions_speedup')\n",
    "        for idx, row in bottom5.iterrows():\n",
    "            f.write(f\"Stride {row['Stride']}, Sparsity {row['Sparsity Level']}% - Speedup: {row['instructions_speedup']:.2f}x\\n\")\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Main function to execute the analysis with stride-grouped approach.\n",
    "    \"\"\"\n",
    "    # File paths - update these with your actual file paths\n",
    "    vector_file = 'all_results_vector.csv'\n",
    "    scalar_file = 'all_results_scalar.csv'\n",
    "    \n",
    "    # Create output directory for plots if it doesn't exist\n",
    "    output_dir = 'stride_grouped_analysis'\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "    \n",
    "    # Load and process data\n",
    "    print(\"Loading and processing data...\")\n",
    "    vector_df, scalar_df, combined_df = load_and_process_data(vector_file, scalar_file)\n",
    "    \n",
    "    # Calculate speedup by stride\n",
    "    print(\"Calculating speedup metrics...\")\n",
    "    speedup_df = calculate_speedup_by_stride(vector_df, scalar_df)\n",
    "    \n",
    "    # Perform stride-specific analysis\n",
    "    print(\"Performing stride-specific analysis...\")\n",
    "    analyze_by_stride(combined_df, speedup_df, output_dir)\n",
    "    \n",
    "    # Create comparative stride analysis\n",
    "    print(\"Creating comparative stride analysis...\")\n",
    "    create_comparative_stride_analysis(combined_df, speedup_df, output_dir)\n",
    "    print(vector_df.head())\n",
    "    print(scalar_df.head())\n",
    "    print(speedup_df.head())\n",
    "\n",
    "    # Generate overall instructions speedup visualization\n",
    "    print(\"Generating overall instructions speedup plot...\")\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    avg_speedup = speedup_df.groupby('Sparsity Level')['instructions_speedup'].mean()\n",
    "    plt.bar(avg_speedup.index, avg_speedup.values, color='skyblue', edgecolor='navy')\n",
    "    plt.axhline(y=1.0, color='red', linestyle='--', alpha=0.7)\n",
    "    plt.title('Average Instructions Speedup by Sparsity Level (All Strides)')\n",
    "    plt.xlabel('Sparsity Level (%)')\n",
    "    plt.ylabel('Instructions Speedup (Scalar/Vector)')\n",
    "    plt.grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    for i, v in enumerate(avg_speedup.values):\n",
    "        plt.text(avg_speedup.index[i], v + 0.1, f\"{v:.2f}\", ha='center')\n",
    "    \n",
    "    plt.savefig(f\"{output_dir}/overall_instructions_speedup_by_sparsity.png\", dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    # Save all dataframes\n",
    "    vector_df.to_csv(f\"{output_dir}/processed_vector_data.csv\", index=False)\n",
    "    scalar_df.to_csv(f\"{output_dir}/processed_scalar_data.csv\", index=False)\n",
    "    combined_df.to_csv(f\"{output_dir}/combined_data.csv\", index=False)\n",
    "    speedup_df.to_csv(f\"{output_dir}/speedup_metrics.csv\", index=False)\n",
    "    \n",
    "    print(\"\\nAnalysis complete. Results organized by stride in the 'stride_grouped_analysis' directory.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93c1f4c9-7776-43c0-b973-907e46b49027",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
