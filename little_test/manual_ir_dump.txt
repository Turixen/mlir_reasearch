// -----// IR Dump After SparseTensorCodegen (sparse-tensor-codegen) //----- //
#map = affine_map<(d0, d1)[s0] -> (4, d0 - d1)>
#sparse = #sparse_tensor.encoding<{ map = (d0, d1) -> (d0 : dense, d1 : compressed) }>
module {
  memref.global "private" constant @__constant_30xindex : memref<30xindex> = dense<[8, 3, 4, 6, 9, 2, 4, 0, 1, 2, 3, 5, 7, 8, 3, 6, 2, 3, 4, 5, 8, 1, 5, 7, 8, 5, 9, 4, 7, 7]> {alignment = 64 : i64}
  memref.global "private" constant @__constant_11xindex : memref<11xindex> = dense<[0, 1, 5, 7, 14, 16, 21, 25, 27, 29, 30]> {alignment = 64 : i64}
  memref.global "private" constant @__constant_30xf64 : memref<30xf64> = dense<[4.7563469999999999, 2.102859, 5.4238689999999998, 5.577680e+00, 3.001240e-01, 4.8357549999999998, 8.8596050000000002, 1.592490e+00, 7.372070e+00, 7.2462879999999998, 5.9191609999999999, 5.9593920000000002, 4.6956530000000001, 6.328630e-01, 3.1591619999999998, 4.7083050000000002, 8.4356449999999992, 5.4309390000000004, 2.1190630000000001, 1.545420e-01, 2.595040e+00, 1.4655819999999999, 1.321259, 3.702925, 3.542246, 6.831162, 1.723510e+00, 7.8729019999999998, 6.0081550000000004, 1.047045]> {alignment = 64 : i64}
  memref.global "private" constant @__constant_10x10xf64 : memref<10x10xf64> = dense<[[5.0072820879405331, 2.1420497309468542, 8.4364357946217474, 3.3512684114489364, 4.8578737173077684, 6.5026873298607608, 4.481183080848961, 1.6018142840321781, 1.6482067031075565, 2.7697353449463433], [8.2796435610104453, 9.7956308688691446, 5.066309369035312, 1.0691978274975567, 7.2754747197326219, 7.4679216752662611, 1.8460472498040226, 1.7245060332115747, 9.828847678500983, 5.8523888503628294], [4.735129046344202, 0.21389279999051047, 9.9823910553584571, 0.22751442405574696, 4.3063298537464378, 1.0300462704374436, 7.1885192597496097, 1.7297134743393461, 7.4494154821665912, 8.2180913094628564], [0.55370097211729696, 7.0871105126860554, 7.7450498540614178, 4.2448327660994876, 1.2746000519648371, 9.4391729894286023, 6.1902689198805465, 6.0312877871821424, 8.7890699247898425, 3.1611885774377635], [8.9903796016343396, 3.4471256572948263, 8.4932841564173884, 9.9373309006088171, 2.6191045587156303, 0.77351004199567641, 1.4024547359632467, 7.454551829233095, 2.6194195569905077, 4.0298520046877577], [4.7641019675563543, 3.8129279818642861, 9.0747728919768225, 6.4920816381757511, 6.7882405668469881, 7.0063465072165911, 5.7386637585592792, 7.5230234961300599, 0.91592641387099771, 8.6646639602141899], [5.6862365678538973, 4.8755032417073192, 9.5859588536709328, 8.1186668576209513, 5.3811119011589454, 3.8280043169558411, 9.9983397606134918, 6.1835824149566241, 3.4201107815517515, 0.84968218962971687], [2.791270331453247, 2.9735813587818685, 3.0654358664150494, 5.4929582569491755, 3.9238922832952996, 9.2657934977933269, 5.0681592194030571, 9.6910348814034712, 2.0972430846802959, 0.96789458347651514], [3.1989914495545624, 3.7607248895716507, 5.5182323136835318, 2.4724154287944913, 7.2920674615977124, 9.7009225179758473, 9.9421519655410044, 2.6109645810252315, 9.0484630420475316, 3.6771724535825703], [6.305746358135309, 7.6948754823713771, 3.6012681436537397, 1.263350310992416, 3.8581878444772943, 7.1047027925517909, 2.1904752468927735, 0.32914734762647391, 3.1668377278172235, 2.0518472657841924]]> {alignment = 64 : i64}
  func.func @matmul(%arg0: memref<?xindex>, %arg1: memref<?xindex>, %arg2: memref<?xf64>, %arg3: !sparse_tensor.storage_specifier<#sparse>, %arg4: tensor<10x10xf64>, %arg5: tensor<10x10xf64>) -> tensor<10x10xf64> {
    %cst = arith.constant dense<0.000000e+00> : vector<4xf64>
    %c4 = arith.constant 4 : index
    %c1 = arith.constant 1 : index
    %c0 = arith.constant 0 : index
    %c10 = arith.constant 10 : index
    %0 = sparse_tensor.storage_specifier.get %arg3  val_mem_sz : !sparse_tensor.storage_specifier<#sparse>
    %subview = memref.subview %arg2[0] [%0] [1] : memref<?xf64> to memref<?xf64>
    %1 = bufferization.to_memref %arg4 : tensor<10x10xf64> to memref<10x10xf64>
    %2 = bufferization.to_memref %arg5 : tensor<10x10xf64> to memref<10x10xf64>
    %3 = sparse_tensor.storage_specifier.get %arg3  pos_mem_sz at 1 : !sparse_tensor.storage_specifier<#sparse>
    %subview_0 = memref.subview %arg0[0] [%3] [1] : memref<?xindex> to memref<?xindex>
    %4 = sparse_tensor.storage_specifier.get %arg3  crd_mem_sz at 1 : !sparse_tensor.storage_specifier<#sparse>
    %subview_1 = memref.subview %arg1[0] [%4] [1] : memref<?xindex> to memref<?xindex>
    scf.for %arg6 = %c0 to %c10 step %c1 {
      %6 = memref.load %subview_0[%arg6] : memref<?xindex>
      %7 = arith.addi %arg6, %c1 : index
      %8 = memref.load %subview_0[%7] : memref<?xindex>
      scf.for %arg7 = %6 to %8 step %c1 {
        %9 = memref.load %subview_1[%arg7] : memref<?xindex>
        %10 = memref.load %subview[%arg7] : memref<?xf64>
        scf.for %arg8 = %c0 to %c10 step %c4 {
          %11 = affine.min #map(%c10, %arg8)[%c4]
          %12 = vector.create_mask %11 : vector<4xi1>
          %13 = vector.maskedload %2[%arg6, %arg8], %12, %cst : memref<10x10xf64>, vector<4xi1>, vector<4xf64> into vector<4xf64>
          %14 = vector.broadcast %10 : f64 to vector<4xf64>
          %15 = vector.maskedload %1[%9, %arg8], %12, %cst : memref<10x10xf64>, vector<4xi1>, vector<4xf64> into vector<4xf64>
          %16 = arith.mulf %14, %15 : vector<4xf64>
          %17 = arith.addf %13, %16 : vector<4xf64>
          vector.maskedstore %2[%arg6, %arg8], %12, %17 : memref<10x10xf64>, vector<4xi1>, vector<4xf64>
        } {"Emitted from" = "linalg.generic"}
      } {"Emitted from" = "linalg.generic"}
    } {"Emitted from" = "linalg.generic"}
    %5 = bufferization.to_tensor %2 : memref<10x10xf64> to tensor<10x10xf64>
    return %5 : tensor<10x10xf64>
  }
  func.func @main() -> i64 {
    %c8 = arith.constant 8 : index
    %cst = arith.constant 0.000000e+00 : f64
    %c1 = arith.constant 1 : index
    %c10 = arith.constant 10 : index
    %c0 = arith.constant 0 : index
    %0 = memref.get_global @__constant_10x10xf64 : memref<10x10xf64>
    %1 = bufferization.to_tensor %0 : memref<10x10xf64> to tensor<10x10xf64>
    %2 = bufferization.alloc_tensor() : tensor<10x10xf64>
    %3:4 = call @assemble_sparse() : () -> (memref<?xindex>, memref<?xindex>, memref<?xf64>, !sparse_tensor.storage_specifier<#sparse>)
    %4 = call @matmul(%3#0, %3#1, %3#2, %3#3, %1, %2) : (memref<?xindex>, memref<?xindex>, memref<?xf64>, !sparse_tensor.storage_specifier<#sparse>, tensor<10x10xf64>, tensor<10x10xf64>) -> tensor<10x10xf64>
    %5 = bufferization.to_memref %4 : tensor<10x10xf64> to memref<10x10xf64, strided<[?, ?], offset: ?>>
    scf.for %arg0 = %c0 to %c10 step %c1 {
      %8 = vector.transfer_read %4[%arg0, %c0], %cst {in_bounds = [true]} : tensor<10x10xf64>, vector<10xf64>
      vector.print %8 : vector<10xf64>
    }
    %6 = memref.load %5[%c8, %c8] : memref<10x10xf64, strided<[?, ?], offset: ?>>
    %7 = arith.fptosi %6 : f64 to i64
    return %7 : i64
  }
  func.func @assemble_sparse() -> (memref<?xindex>, memref<?xindex>, memref<?xf64>, !sparse_tensor.storage_specifier<#sparse>) {
    %0 = memref.get_global @__constant_30xf64 : memref<30xf64>
    %1 = bufferization.to_tensor %0 : memref<30xf64> to tensor<30xf64>
    %2 = memref.get_global @__constant_11xindex : memref<11xindex>
    %3 = bufferization.to_tensor %2 : memref<11xindex> to tensor<11xindex>
    %4 = memref.get_global @__constant_30xindex : memref<30xindex>
    %5 = bufferization.to_tensor %4 : memref<30xindex> to tensor<30xindex>
    %6 = bufferization.to_memref %3 : tensor<11xindex> to memref<11xindex>
    %cast = memref.cast %6 : memref<11xindex> to memref<?xindex>
    %7 = bufferization.to_memref %5 : tensor<30xindex> to memref<30xindex>
    %cast_0 = memref.cast %7 : memref<30xindex> to memref<?xindex>
    %8 = bufferization.to_memref %1 : tensor<30xf64> to memref<30xf64>
    %cast_1 = memref.cast %8 : memref<30xf64> to memref<?xf64>
    %9 = sparse_tensor.storage_specifier.init : !sparse_tensor.storage_specifier<#sparse>
    %c0 = arith.constant 0 : index
    %c1 = arith.constant 1 : index
    %c2 = arith.constant 2 : index
    %c10 = arith.constant 10 : index
    %10 = sparse_tensor.storage_specifier.set %9  lvl_sz at 0 with %c10 : !sparse_tensor.storage_specifier<#sparse>
    %11 = arith.muli %c10, %c1 : index
    %12 = arith.subi %11, %c1 : index
    %c10_2 = arith.constant 10 : index
    %13 = sparse_tensor.storage_specifier.set %10  lvl_sz at 1 with %c10_2 : !sparse_tensor.storage_specifier<#sparse>
    %14 = arith.addi %11, %c1 : index
    %15 = sparse_tensor.storage_specifier.set %13  pos_mem_sz at 1 with %14 : !sparse_tensor.storage_specifier<#sparse>
    %c0_3 = arith.constant 0 : index
    %16 = memref.load %cast[%11] : memref<?xindex>
    %17 = arith.subi %11, %c1 : index
    %18 = sparse_tensor.storage_specifier.set %15  crd_mem_sz at 1 with %16 : !sparse_tensor.storage_specifier<#sparse>
    %19 = sparse_tensor.storage_specifier.set %18  val_mem_sz with %16 : !sparse_tensor.storage_specifier<#sparse>
    return %cast, %cast_0, %cast_1, %19 : memref<?xindex>, memref<?xindex>, memref<?xf64>, !sparse_tensor.storage_specifier<#sparse>
  }
}


// -----// IR Dump After SparseBufferRewrite (sparse-buffer-rewrite) //----- //
#map = affine_map<(d0, d1)[s0] -> (4, d0 - d1)>
#sparse = #sparse_tensor.encoding<{ map = (d0, d1) -> (d0 : dense, d1 : compressed) }>
module {
  memref.global "private" constant @__constant_30xindex : memref<30xindex> = dense<[8, 3, 4, 6, 9, 2, 4, 0, 1, 2, 3, 5, 7, 8, 3, 6, 2, 3, 4, 5, 8, 1, 5, 7, 8, 5, 9, 4, 7, 7]> {alignment = 64 : i64}
  memref.global "private" constant @__constant_11xindex : memref<11xindex> = dense<[0, 1, 5, 7, 14, 16, 21, 25, 27, 29, 30]> {alignment = 64 : i64}
  memref.global "private" constant @__constant_30xf64 : memref<30xf64> = dense<[4.7563469999999999, 2.102859, 5.4238689999999998, 5.577680e+00, 3.001240e-01, 4.8357549999999998, 8.8596050000000002, 1.592490e+00, 7.372070e+00, 7.2462879999999998, 5.9191609999999999, 5.9593920000000002, 4.6956530000000001, 6.328630e-01, 3.1591619999999998, 4.7083050000000002, 8.4356449999999992, 5.4309390000000004, 2.1190630000000001, 1.545420e-01, 2.595040e+00, 1.4655819999999999, 1.321259, 3.702925, 3.542246, 6.831162, 1.723510e+00, 7.8729019999999998, 6.0081550000000004, 1.047045]> {alignment = 64 : i64}
  memref.global "private" constant @__constant_10x10xf64 : memref<10x10xf64> = dense<[[5.0072820879405331, 2.1420497309468542, 8.4364357946217474, 3.3512684114489364, 4.8578737173077684, 6.5026873298607608, 4.481183080848961, 1.6018142840321781, 1.6482067031075565, 2.7697353449463433], [8.2796435610104453, 9.7956308688691446, 5.066309369035312, 1.0691978274975567, 7.2754747197326219, 7.4679216752662611, 1.8460472498040226, 1.7245060332115747, 9.828847678500983, 5.8523888503628294], [4.735129046344202, 0.21389279999051047, 9.9823910553584571, 0.22751442405574696, 4.3063298537464378, 1.0300462704374436, 7.1885192597496097, 1.7297134743393461, 7.4494154821665912, 8.2180913094628564], [0.55370097211729696, 7.0871105126860554, 7.7450498540614178, 4.2448327660994876, 1.2746000519648371, 9.4391729894286023, 6.1902689198805465, 6.0312877871821424, 8.7890699247898425, 3.1611885774377635], [8.9903796016343396, 3.4471256572948263, 8.4932841564173884, 9.9373309006088171, 2.6191045587156303, 0.77351004199567641, 1.4024547359632467, 7.454551829233095, 2.6194195569905077, 4.0298520046877577], [4.7641019675563543, 3.8129279818642861, 9.0747728919768225, 6.4920816381757511, 6.7882405668469881, 7.0063465072165911, 5.7386637585592792, 7.5230234961300599, 0.91592641387099771, 8.6646639602141899], [5.6862365678538973, 4.8755032417073192, 9.5859588536709328, 8.1186668576209513, 5.3811119011589454, 3.8280043169558411, 9.9983397606134918, 6.1835824149566241, 3.4201107815517515, 0.84968218962971687], [2.791270331453247, 2.9735813587818685, 3.0654358664150494, 5.4929582569491755, 3.9238922832952996, 9.2657934977933269, 5.0681592194030571, 9.6910348814034712, 2.0972430846802959, 0.96789458347651514], [3.1989914495545624, 3.7607248895716507, 5.5182323136835318, 2.4724154287944913, 7.2920674615977124, 9.7009225179758473, 9.9421519655410044, 2.6109645810252315, 9.0484630420475316, 3.6771724535825703], [6.305746358135309, 7.6948754823713771, 3.6012681436537397, 1.263350310992416, 3.8581878444772943, 7.1047027925517909, 2.1904752468927735, 0.32914734762647391, 3.1668377278172235, 2.0518472657841924]]> {alignment = 64 : i64}
  func.func @matmul(%arg0: memref<?xindex>, %arg1: memref<?xindex>, %arg2: memref<?xf64>, %arg3: !sparse_tensor.storage_specifier<#sparse>, %arg4: tensor<10x10xf64>, %arg5: tensor<10x10xf64>) -> tensor<10x10xf64> {
    %cst = arith.constant dense<0.000000e+00> : vector<4xf64>
    %c4 = arith.constant 4 : index
    %c1 = arith.constant 1 : index
    %c0 = arith.constant 0 : index
    %c10 = arith.constant 10 : index
    %0 = sparse_tensor.storage_specifier.get %arg3  val_mem_sz : !sparse_tensor.storage_specifier<#sparse>
    %subview = memref.subview %arg2[0] [%0] [1] : memref<?xf64> to memref<?xf64>
    %1 = bufferization.to_memref %arg4 : tensor<10x10xf64> to memref<10x10xf64>
    %2 = bufferization.to_memref %arg5 : tensor<10x10xf64> to memref<10x10xf64>
    %3 = sparse_tensor.storage_specifier.get %arg3  pos_mem_sz at 1 : !sparse_tensor.storage_specifier<#sparse>
    %subview_0 = memref.subview %arg0[0] [%3] [1] : memref<?xindex> to memref<?xindex>
    %4 = sparse_tensor.storage_specifier.get %arg3  crd_mem_sz at 1 : !sparse_tensor.storage_specifier<#sparse>
    %subview_1 = memref.subview %arg1[0] [%4] [1] : memref<?xindex> to memref<?xindex>
    scf.for %arg6 = %c0 to %c10 step %c1 {
      %6 = memref.load %subview_0[%arg6] : memref<?xindex>
      %7 = arith.addi %arg6, %c1 : index
      %8 = memref.load %subview_0[%7] : memref<?xindex>
      scf.for %arg7 = %6 to %8 step %c1 {
        %9 = memref.load %subview_1[%arg7] : memref<?xindex>
        %10 = memref.load %subview[%arg7] : memref<?xf64>
        scf.for %arg8 = %c0 to %c10 step %c4 {
          %11 = affine.min #map(%c10, %arg8)[%c4]
          %12 = vector.create_mask %11 : vector<4xi1>
          %13 = vector.maskedload %2[%arg6, %arg8], %12, %cst : memref<10x10xf64>, vector<4xi1>, vector<4xf64> into vector<4xf64>
          %14 = vector.broadcast %10 : f64 to vector<4xf64>
          %15 = vector.maskedload %1[%9, %arg8], %12, %cst : memref<10x10xf64>, vector<4xi1>, vector<4xf64> into vector<4xf64>
          %16 = arith.mulf %14, %15 : vector<4xf64>
          %17 = arith.addf %13, %16 : vector<4xf64>
          vector.maskedstore %2[%arg6, %arg8], %12, %17 : memref<10x10xf64>, vector<4xi1>, vector<4xf64>
        } {"Emitted from" = "linalg.generic"}
      } {"Emitted from" = "linalg.generic"}
    } {"Emitted from" = "linalg.generic"}
    %5 = bufferization.to_tensor %2 : memref<10x10xf64> to tensor<10x10xf64>
    return %5 : tensor<10x10xf64>
  }
  func.func @main() -> i64 {
    %c8 = arith.constant 8 : index
    %cst = arith.constant 0.000000e+00 : f64
    %c1 = arith.constant 1 : index
    %c10 = arith.constant 10 : index
    %c0 = arith.constant 0 : index
    %0 = memref.get_global @__constant_10x10xf64 : memref<10x10xf64>
    %1 = bufferization.to_tensor %0 : memref<10x10xf64> to tensor<10x10xf64>
    %2 = bufferization.alloc_tensor() : tensor<10x10xf64>
    %3:4 = call @assemble_sparse() : () -> (memref<?xindex>, memref<?xindex>, memref<?xf64>, !sparse_tensor.storage_specifier<#sparse>)
    %4 = call @matmul(%3#0, %3#1, %3#2, %3#3, %1, %2) : (memref<?xindex>, memref<?xindex>, memref<?xf64>, !sparse_tensor.storage_specifier<#sparse>, tensor<10x10xf64>, tensor<10x10xf64>) -> tensor<10x10xf64>
    %5 = bufferization.to_memref %4 : tensor<10x10xf64> to memref<10x10xf64, strided<[?, ?], offset: ?>>
    scf.for %arg0 = %c0 to %c10 step %c1 {
      %8 = vector.transfer_read %4[%arg0, %c0], %cst {in_bounds = [true]} : tensor<10x10xf64>, vector<10xf64>
      vector.print %8 : vector<10xf64>
    }
    %6 = memref.load %5[%c8, %c8] : memref<10x10xf64, strided<[?, ?], offset: ?>>
    %7 = arith.fptosi %6 : f64 to i64
    return %7 : i64
  }
  func.func @assemble_sparse() -> (memref<?xindex>, memref<?xindex>, memref<?xf64>, !sparse_tensor.storage_specifier<#sparse>) {
    %c11 = arith.constant 11 : index
    %c10 = arith.constant 10 : index
    %0 = memref.get_global @__constant_30xf64 : memref<30xf64>
    %1 = memref.get_global @__constant_11xindex : memref<11xindex>
    %2 = memref.get_global @__constant_30xindex : memref<30xindex>
    %cast = memref.cast %1 : memref<11xindex> to memref<?xindex>
    %cast_0 = memref.cast %2 : memref<30xindex> to memref<?xindex>
    %cast_1 = memref.cast %0 : memref<30xf64> to memref<?xf64>
    %3 = sparse_tensor.storage_specifier.init : !sparse_tensor.storage_specifier<#sparse>
    %4 = sparse_tensor.storage_specifier.set %3  lvl_sz at 0 with %c10 : !sparse_tensor.storage_specifier<#sparse>
    %5 = sparse_tensor.storage_specifier.set %4  lvl_sz at 1 with %c10 : !sparse_tensor.storage_specifier<#sparse>
    %6 = sparse_tensor.storage_specifier.set %5  pos_mem_sz at 1 with %c11 : !sparse_tensor.storage_specifier<#sparse>
    %7 = memref.load %1[%c10] : memref<11xindex>
    %8 = sparse_tensor.storage_specifier.set %6  crd_mem_sz at 1 with %7 : !sparse_tensor.storage_specifier<#sparse>
    %9 = sparse_tensor.storage_specifier.set %8  val_mem_sz with %7 : !sparse_tensor.storage_specifier<#sparse>
    return %cast, %cast_0, %cast_1, %9 : memref<?xindex>, memref<?xindex>, memref<?xf64>, !sparse_tensor.storage_specifier<#sparse>
  }
}


// -----// IR Dump After StorageSpecifierToLLVM (sparse-storage-specifier-to-llvm) //----- //
#map = affine_map<(d0, d1)[s0] -> (4, d0 - d1)>
module {
  memref.global "private" constant @__constant_30xindex : memref<30xindex> = dense<[8, 3, 4, 6, 9, 2, 4, 0, 1, 2, 3, 5, 7, 8, 3, 6, 2, 3, 4, 5, 8, 1, 5, 7, 8, 5, 9, 4, 7, 7]> {alignment = 64 : i64}
  memref.global "private" constant @__constant_11xindex : memref<11xindex> = dense<[0, 1, 5, 7, 14, 16, 21, 25, 27, 29, 30]> {alignment = 64 : i64}
  memref.global "private" constant @__constant_30xf64 : memref<30xf64> = dense<[4.7563469999999999, 2.102859, 5.4238689999999998, 5.577680e+00, 3.001240e-01, 4.8357549999999998, 8.8596050000000002, 1.592490e+00, 7.372070e+00, 7.2462879999999998, 5.9191609999999999, 5.9593920000000002, 4.6956530000000001, 6.328630e-01, 3.1591619999999998, 4.7083050000000002, 8.4356449999999992, 5.4309390000000004, 2.1190630000000001, 1.545420e-01, 2.595040e+00, 1.4655819999999999, 1.321259, 3.702925, 3.542246, 6.831162, 1.723510e+00, 7.8729019999999998, 6.0081550000000004, 1.047045]> {alignment = 64 : i64}
  memref.global "private" constant @__constant_10x10xf64 : memref<10x10xf64> = dense<[[5.0072820879405331, 2.1420497309468542, 8.4364357946217474, 3.3512684114489364, 4.8578737173077684, 6.5026873298607608, 4.481183080848961, 1.6018142840321781, 1.6482067031075565, 2.7697353449463433], [8.2796435610104453, 9.7956308688691446, 5.066309369035312, 1.0691978274975567, 7.2754747197326219, 7.4679216752662611, 1.8460472498040226, 1.7245060332115747, 9.828847678500983, 5.8523888503628294], [4.735129046344202, 0.21389279999051047, 9.9823910553584571, 0.22751442405574696, 4.3063298537464378, 1.0300462704374436, 7.1885192597496097, 1.7297134743393461, 7.4494154821665912, 8.2180913094628564], [0.55370097211729696, 7.0871105126860554, 7.7450498540614178, 4.2448327660994876, 1.2746000519648371, 9.4391729894286023, 6.1902689198805465, 6.0312877871821424, 8.7890699247898425, 3.1611885774377635], [8.9903796016343396, 3.4471256572948263, 8.4932841564173884, 9.9373309006088171, 2.6191045587156303, 0.77351004199567641, 1.4024547359632467, 7.454551829233095, 2.6194195569905077, 4.0298520046877577], [4.7641019675563543, 3.8129279818642861, 9.0747728919768225, 6.4920816381757511, 6.7882405668469881, 7.0063465072165911, 5.7386637585592792, 7.5230234961300599, 0.91592641387099771, 8.6646639602141899], [5.6862365678538973, 4.8755032417073192, 9.5859588536709328, 8.1186668576209513, 5.3811119011589454, 3.8280043169558411, 9.9983397606134918, 6.1835824149566241, 3.4201107815517515, 0.84968218962971687], [2.791270331453247, 2.9735813587818685, 3.0654358664150494, 5.4929582569491755, 3.9238922832952996, 9.2657934977933269, 5.0681592194030571, 9.6910348814034712, 2.0972430846802959, 0.96789458347651514], [3.1989914495545624, 3.7607248895716507, 5.5182323136835318, 2.4724154287944913, 7.2920674615977124, 9.7009225179758473, 9.9421519655410044, 2.6109645810252315, 9.0484630420475316, 3.6771724535825703], [6.305746358135309, 7.6948754823713771, 3.6012681436537397, 1.263350310992416, 3.8581878444772943, 7.1047027925517909, 2.1904752468927735, 0.32914734762647391, 3.1668377278172235, 2.0518472657841924]]> {alignment = 64 : i64}
  func.func @matmul(%arg0: memref<?xindex>, %arg1: memref<?xindex>, %arg2: memref<?xf64>, %arg3: !llvm.struct<(array<2 x i64>, array<3 x i64>)>, %arg4: tensor<10x10xf64>, %arg5: tensor<10x10xf64>) -> tensor<10x10xf64> {
    %cst = arith.constant dense<0.000000e+00> : vector<4xf64>
    %c4 = arith.constant 4 : index
    %c1 = arith.constant 1 : index
    %c0 = arith.constant 0 : index
    %c10 = arith.constant 10 : index
    %0 = llvm.extractvalue %arg3[1, 2] : !llvm.struct<(array<2 x i64>, array<3 x i64>)> 
    %1 = arith.index_cast %0 : i64 to index
    %subview = memref.subview %arg2[0] [%1] [1] : memref<?xf64> to memref<?xf64>
    %2 = bufferization.to_memref %arg4 : tensor<10x10xf64> to memref<10x10xf64>
    %3 = bufferization.to_memref %arg5 : tensor<10x10xf64> to memref<10x10xf64>
    %4 = llvm.extractvalue %arg3[1, 0] : !llvm.struct<(array<2 x i64>, array<3 x i64>)> 
    %5 = arith.index_cast %4 : i64 to index
    %subview_0 = memref.subview %arg0[0] [%5] [1] : memref<?xindex> to memref<?xindex>
    %6 = llvm.extractvalue %arg3[1, 1] : !llvm.struct<(array<2 x i64>, array<3 x i64>)> 
    %7 = arith.index_cast %6 : i64 to index
    %subview_1 = memref.subview %arg1[0] [%7] [1] : memref<?xindex> to memref<?xindex>
    scf.for %arg6 = %c0 to %c10 step %c1 {
      %9 = memref.load %subview_0[%arg6] : memref<?xindex>
      %10 = arith.addi %arg6, %c1 : index
      %11 = memref.load %subview_0[%10] : memref<?xindex>
      scf.for %arg7 = %9 to %11 step %c1 {
        %12 = memref.load %subview_1[%arg7] : memref<?xindex>
        %13 = memref.load %subview[%arg7] : memref<?xf64>
        scf.for %arg8 = %c0 to %c10 step %c4 {
          %14 = affine.min #map(%c10, %arg8)[%c4]
          %15 = vector.create_mask %14 : vector<4xi1>
          %16 = vector.maskedload %3[%arg6, %arg8], %15, %cst : memref<10x10xf64>, vector<4xi1>, vector<4xf64> into vector<4xf64>
          %17 = vector.broadcast %13 : f64 to vector<4xf64>
          %18 = vector.maskedload %2[%12, %arg8], %15, %cst : memref<10x10xf64>, vector<4xi1>, vector<4xf64> into vector<4xf64>
          %19 = arith.mulf %17, %18 : vector<4xf64>
          %20 = arith.addf %16, %19 : vector<4xf64>
          vector.maskedstore %3[%arg6, %arg8], %15, %20 : memref<10x10xf64>, vector<4xi1>, vector<4xf64>
        } {"Emitted from" = "linalg.generic"}
      } {"Emitted from" = "linalg.generic"}
    } {"Emitted from" = "linalg.generic"}
    %8 = bufferization.to_tensor %3 : memref<10x10xf64> to tensor<10x10xf64>
    return %8 : tensor<10x10xf64>
  }
  func.func @main() -> i64 {
    %c8 = arith.constant 8 : index
    %cst = arith.constant 0.000000e+00 : f64
    %c1 = arith.constant 1 : index
    %c10 = arith.constant 10 : index
    %c0 = arith.constant 0 : index
    %0 = memref.get_global @__constant_10x10xf64 : memref<10x10xf64>
    %1 = bufferization.to_tensor %0 : memref<10x10xf64> to tensor<10x10xf64>
    %2 = bufferization.alloc_tensor() : tensor<10x10xf64>
    %3:4 = call @assemble_sparse() : () -> (memref<?xindex>, memref<?xindex>, memref<?xf64>, !llvm.struct<(array<2 x i64>, array<3 x i64>)>)
    %4 = call @matmul(%3#0, %3#1, %3#2, %3#3, %1, %2) : (memref<?xindex>, memref<?xindex>, memref<?xf64>, !llvm.struct<(array<2 x i64>, array<3 x i64>)>, tensor<10x10xf64>, tensor<10x10xf64>) -> tensor<10x10xf64>
    %5 = bufferization.to_memref %4 : tensor<10x10xf64> to memref<10x10xf64, strided<[?, ?], offset: ?>>
    scf.for %arg0 = %c0 to %c10 step %c1 {
      %8 = vector.transfer_read %4[%arg0, %c0], %cst {in_bounds = [true]} : tensor<10x10xf64>, vector<10xf64>
      vector.print %8 : vector<10xf64>
    }
    %6 = memref.load %5[%c8, %c8] : memref<10x10xf64, strided<[?, ?], offset: ?>>
    %7 = arith.fptosi %6 : f64 to i64
    return %7 : i64
  }
  func.func @assemble_sparse() -> (memref<?xindex>, memref<?xindex>, memref<?xf64>, !llvm.struct<(array<2 x i64>, array<3 x i64>)>) {
    %c11 = arith.constant 11 : index
    %c10 = arith.constant 10 : index
    %0 = memref.get_global @__constant_30xf64 : memref<30xf64>
    %1 = memref.get_global @__constant_11xindex : memref<11xindex>
    %2 = memref.get_global @__constant_30xindex : memref<30xindex>
    %cast = memref.cast %1 : memref<11xindex> to memref<?xindex>
    %cast_0 = memref.cast %2 : memref<30xindex> to memref<?xindex>
    %cast_1 = memref.cast %0 : memref<30xf64> to memref<?xf64>
    %3 = llvm.mlir.poison : !llvm.struct<(array<2 x i64>, array<3 x i64>)>
    %c0_i64 = arith.constant 0 : i64
    %4 = llvm.insertvalue %c0_i64, %3[1, 0] : !llvm.struct<(array<2 x i64>, array<3 x i64>)> 
    %5 = llvm.insertvalue %c0_i64, %4[1, 1] : !llvm.struct<(array<2 x i64>, array<3 x i64>)> 
    %6 = llvm.insertvalue %c0_i64, %5[1, 2] : !llvm.struct<(array<2 x i64>, array<3 x i64>)> 
    %7 = arith.index_cast %c10 : index to i64
    %8 = llvm.insertvalue %7, %6[0, 0] : !llvm.struct<(array<2 x i64>, array<3 x i64>)> 
    %9 = arith.index_cast %c10 : index to i64
    %10 = llvm.insertvalue %9, %8[0, 1] : !llvm.struct<(array<2 x i64>, array<3 x i64>)> 
    %11 = arith.index_cast %c11 : index to i64
    %12 = llvm.insertvalue %11, %10[1, 0] : !llvm.struct<(array<2 x i64>, array<3 x i64>)> 
    %13 = memref.load %1[%c10] : memref<11xindex>
    %14 = arith.index_cast %13 : index to i64
    %15 = llvm.insertvalue %14, %12[1, 1] : !llvm.struct<(array<2 x i64>, array<3 x i64>)> 
    %16 = arith.index_cast %13 : index to i64
    %17 = llvm.insertvalue %16, %15[1, 2] : !llvm.struct<(array<2 x i64>, array<3 x i64>)> 
    return %cast, %cast_0, %cast_1, %17 : memref<?xindex>, memref<?xindex>, memref<?xf64>, !llvm.struct<(array<2 x i64>, array<3 x i64>)>
  }
}


// -----// IR Dump After Canonicalizer (canonicalize) //----- //
#map = affine_map<(d0) -> (-d0 + 10, 4)>
module {
  memref.global "private" constant @__constant_30xindex : memref<30xindex> = dense<[8, 3, 4, 6, 9, 2, 4, 0, 1, 2, 3, 5, 7, 8, 3, 6, 2, 3, 4, 5, 8, 1, 5, 7, 8, 5, 9, 4, 7, 7]> {alignment = 64 : i64}
  memref.global "private" constant @__constant_11xindex : memref<11xindex> = dense<[0, 1, 5, 7, 14, 16, 21, 25, 27, 29, 30]> {alignment = 64 : i64}
  memref.global "private" constant @__constant_30xf64 : memref<30xf64> = dense<[4.7563469999999999, 2.102859, 5.4238689999999998, 5.577680e+00, 3.001240e-01, 4.8357549999999998, 8.8596050000000002, 1.592490e+00, 7.372070e+00, 7.2462879999999998, 5.9191609999999999, 5.9593920000000002, 4.6956530000000001, 6.328630e-01, 3.1591619999999998, 4.7083050000000002, 8.4356449999999992, 5.4309390000000004, 2.1190630000000001, 1.545420e-01, 2.595040e+00, 1.4655819999999999, 1.321259, 3.702925, 3.542246, 6.831162, 1.723510e+00, 7.8729019999999998, 6.0081550000000004, 1.047045]> {alignment = 64 : i64}
  memref.global "private" constant @__constant_10x10xf64 : memref<10x10xf64> = dense<[[5.0072820879405331, 2.1420497309468542, 8.4364357946217474, 3.3512684114489364, 4.8578737173077684, 6.5026873298607608, 4.481183080848961, 1.6018142840321781, 1.6482067031075565, 2.7697353449463433], [8.2796435610104453, 9.7956308688691446, 5.066309369035312, 1.0691978274975567, 7.2754747197326219, 7.4679216752662611, 1.8460472498040226, 1.7245060332115747, 9.828847678500983, 5.8523888503628294], [4.735129046344202, 0.21389279999051047, 9.9823910553584571, 0.22751442405574696, 4.3063298537464378, 1.0300462704374436, 7.1885192597496097, 1.7297134743393461, 7.4494154821665912, 8.2180913094628564], [0.55370097211729696, 7.0871105126860554, 7.7450498540614178, 4.2448327660994876, 1.2746000519648371, 9.4391729894286023, 6.1902689198805465, 6.0312877871821424, 8.7890699247898425, 3.1611885774377635], [8.9903796016343396, 3.4471256572948263, 8.4932841564173884, 9.9373309006088171, 2.6191045587156303, 0.77351004199567641, 1.4024547359632467, 7.454551829233095, 2.6194195569905077, 4.0298520046877577], [4.7641019675563543, 3.8129279818642861, 9.0747728919768225, 6.4920816381757511, 6.7882405668469881, 7.0063465072165911, 5.7386637585592792, 7.5230234961300599, 0.91592641387099771, 8.6646639602141899], [5.6862365678538973, 4.8755032417073192, 9.5859588536709328, 8.1186668576209513, 5.3811119011589454, 3.8280043169558411, 9.9983397606134918, 6.1835824149566241, 3.4201107815517515, 0.84968218962971687], [2.791270331453247, 2.9735813587818685, 3.0654358664150494, 5.4929582569491755, 3.9238922832952996, 9.2657934977933269, 5.0681592194030571, 9.6910348814034712, 2.0972430846802959, 0.96789458347651514], [3.1989914495545624, 3.7607248895716507, 5.5182323136835318, 2.4724154287944913, 7.2920674615977124, 9.7009225179758473, 9.9421519655410044, 2.6109645810252315, 9.0484630420475316, 3.6771724535825703], [6.305746358135309, 7.6948754823713771, 3.6012681436537397, 1.263350310992416, 3.8581878444772943, 7.1047027925517909, 2.1904752468927735, 0.32914734762647391, 3.1668377278172235, 2.0518472657841924]]> {alignment = 64 : i64}
  func.func @matmul(%arg0: memref<?xindex>, %arg1: memref<?xindex>, %arg2: memref<?xf64>, %arg3: !llvm.struct<(array<2 x i64>, array<3 x i64>)>, %arg4: tensor<10x10xf64>, %arg5: tensor<10x10xf64>) -> tensor<10x10xf64> {
    %cst = arith.constant dense<0.000000e+00> : vector<4xf64>
    %c4 = arith.constant 4 : index
    %c1 = arith.constant 1 : index
    %c0 = arith.constant 0 : index
    %c10 = arith.constant 10 : index
    %0 = llvm.extractvalue %arg3[1, 2] : !llvm.struct<(array<2 x i64>, array<3 x i64>)> 
    %1 = arith.index_cast %0 : i64 to index
    %subview = memref.subview %arg2[0] [%1] [1] : memref<?xf64> to memref<?xf64>
    %2 = bufferization.to_memref %arg4 : tensor<10x10xf64> to memref<10x10xf64>
    %3 = bufferization.to_memref %arg5 : tensor<10x10xf64> to memref<10x10xf64>
    %4 = llvm.extractvalue %arg3[1, 0] : !llvm.struct<(array<2 x i64>, array<3 x i64>)> 
    %5 = arith.index_cast %4 : i64 to index
    %subview_0 = memref.subview %arg0[0] [%5] [1] : memref<?xindex> to memref<?xindex>
    %6 = llvm.extractvalue %arg3[1, 1] : !llvm.struct<(array<2 x i64>, array<3 x i64>)> 
    %7 = arith.index_cast %6 : i64 to index
    %subview_1 = memref.subview %arg1[0] [%7] [1] : memref<?xindex> to memref<?xindex>
    scf.for %arg6 = %c0 to %c10 step %c1 {
      %9 = memref.load %subview_0[%arg6] : memref<?xindex>
      %10 = arith.addi %arg6, %c1 : index
      %11 = memref.load %subview_0[%10] : memref<?xindex>
      scf.for %arg7 = %9 to %11 step %c1 {
        %12 = memref.load %subview_1[%arg7] : memref<?xindex>
        %13 = memref.load %subview[%arg7] : memref<?xf64>
        scf.for %arg8 = %c0 to %c10 step %c4 {
          %14 = affine.min #map(%arg8)
          %15 = vector.create_mask %14 : vector<4xi1>
          %16 = vector.maskedload %3[%arg6, %arg8], %15, %cst : memref<10x10xf64>, vector<4xi1>, vector<4xf64> into vector<4xf64>
          %17 = vector.broadcast %13 : f64 to vector<4xf64>
          %18 = vector.maskedload %2[%12, %arg8], %15, %cst : memref<10x10xf64>, vector<4xi1>, vector<4xf64> into vector<4xf64>
          %19 = arith.mulf %17, %18 : vector<4xf64>
          %20 = arith.addf %16, %19 : vector<4xf64>
          vector.maskedstore %3[%arg6, %arg8], %15, %20 : memref<10x10xf64>, vector<4xi1>, vector<4xf64>
        } {"Emitted from" = "linalg.generic"}
      } {"Emitted from" = "linalg.generic"}
    } {"Emitted from" = "linalg.generic"}
    %8 = bufferization.to_tensor %3 : memref<10x10xf64> to tensor<10x10xf64>
    return %8 : tensor<10x10xf64>
  }
  func.func @main() -> i64 {
    %c8 = arith.constant 8 : index
    %cst = arith.constant 0.000000e+00 : f64
    %c1 = arith.constant 1 : index
    %c10 = arith.constant 10 : index
    %c0 = arith.constant 0 : index
    %0 = memref.get_global @__constant_10x10xf64 : memref<10x10xf64>
    %1 = bufferization.to_tensor %0 : memref<10x10xf64> to tensor<10x10xf64>
    %2 = bufferization.alloc_tensor() : tensor<10x10xf64>
    %3:4 = call @assemble_sparse() : () -> (memref<?xindex>, memref<?xindex>, memref<?xf64>, !llvm.struct<(array<2 x i64>, array<3 x i64>)>)
    %4 = call @matmul(%3#0, %3#1, %3#2, %3#3, %1, %2) : (memref<?xindex>, memref<?xindex>, memref<?xf64>, !llvm.struct<(array<2 x i64>, array<3 x i64>)>, tensor<10x10xf64>, tensor<10x10xf64>) -> tensor<10x10xf64>
    scf.for %arg0 = %c0 to %c10 step %c1 {
      %6 = vector.transfer_read %4[%arg0, %c0], %cst {in_bounds = [true]} : tensor<10x10xf64>, vector<10xf64>
      vector.print %6 : vector<10xf64>
    }
    %extracted = tensor.extract %4[%c8, %c8] : tensor<10x10xf64>
    %5 = arith.fptosi %extracted : f64 to i64
    return %5 : i64
  }
  func.func @assemble_sparse() -> (memref<?xindex>, memref<?xindex>, memref<?xf64>, !llvm.struct<(array<2 x i64>, array<3 x i64>)>) {
    %c11_i64 = arith.constant 11 : i64
    %c10_i64 = arith.constant 10 : i64
    %c0_i64 = arith.constant 0 : i64
    %0 = llvm.mlir.poison : !llvm.struct<(array<2 x i64>, array<3 x i64>)>
    %c10 = arith.constant 10 : index
    %1 = memref.get_global @__constant_30xf64 : memref<30xf64>
    %2 = memref.get_global @__constant_11xindex : memref<11xindex>
    %3 = memref.get_global @__constant_30xindex : memref<30xindex>
    %cast = memref.cast %2 : memref<11xindex> to memref<?xindex>
    %cast_0 = memref.cast %3 : memref<30xindex> to memref<?xindex>
    %cast_1 = memref.cast %1 : memref<30xf64> to memref<?xf64>
    %4 = llvm.insertvalue %c0_i64, %0[1, 0] : !llvm.struct<(array<2 x i64>, array<3 x i64>)> 
    %5 = llvm.insertvalue %c0_i64, %4[1, 1] : !llvm.struct<(array<2 x i64>, array<3 x i64>)> 
    %6 = llvm.insertvalue %c0_i64, %5[1, 2] : !llvm.struct<(array<2 x i64>, array<3 x i64>)> 
    %7 = llvm.insertvalue %c10_i64, %6[0, 0] : !llvm.struct<(array<2 x i64>, array<3 x i64>)> 
    %8 = llvm.insertvalue %c10_i64, %7[0, 1] : !llvm.struct<(array<2 x i64>, array<3 x i64>)> 
    %9 = llvm.insertvalue %c11_i64, %8[1, 0] : !llvm.struct<(array<2 x i64>, array<3 x i64>)> 
    %10 = memref.load %2[%c10] : memref<11xindex>
    %11 = arith.index_cast %10 : index to i64
    %12 = llvm.insertvalue %11, %9[1, 1] : !llvm.struct<(array<2 x i64>, array<3 x i64>)> 
    %13 = arith.index_cast %10 : index to i64
    %14 = llvm.insertvalue %13, %12[1, 2] : !llvm.struct<(array<2 x i64>, array<3 x i64>)> 
    return %cast, %cast_0, %cast_1, %14 : memref<?xindex>, memref<?xindex>, memref<?xf64>, !llvm.struct<(array<2 x i64>, array<3 x i64>)>
  }
}


// -----// IR Dump After ConvertLinalgToLoopsPass (convert-linalg-to-loops) //----- //
#map = affine_map<(d0) -> (-d0 + 10, 4)>
module {
  memref.global "private" constant @__constant_30xindex : memref<30xindex> = dense<[8, 3, 4, 6, 9, 2, 4, 0, 1, 2, 3, 5, 7, 8, 3, 6, 2, 3, 4, 5, 8, 1, 5, 7, 8, 5, 9, 4, 7, 7]> {alignment = 64 : i64}
  memref.global "private" constant @__constant_11xindex : memref<11xindex> = dense<[0, 1, 5, 7, 14, 16, 21, 25, 27, 29, 30]> {alignment = 64 : i64}
  memref.global "private" constant @__constant_30xf64 : memref<30xf64> = dense<[4.7563469999999999, 2.102859, 5.4238689999999998, 5.577680e+00, 3.001240e-01, 4.8357549999999998, 8.8596050000000002, 1.592490e+00, 7.372070e+00, 7.2462879999999998, 5.9191609999999999, 5.9593920000000002, 4.6956530000000001, 6.328630e-01, 3.1591619999999998, 4.7083050000000002, 8.4356449999999992, 5.4309390000000004, 2.1190630000000001, 1.545420e-01, 2.595040e+00, 1.4655819999999999, 1.321259, 3.702925, 3.542246, 6.831162, 1.723510e+00, 7.8729019999999998, 6.0081550000000004, 1.047045]> {alignment = 64 : i64}
  memref.global "private" constant @__constant_10x10xf64 : memref<10x10xf64> = dense<[[5.0072820879405331, 2.1420497309468542, 8.4364357946217474, 3.3512684114489364, 4.8578737173077684, 6.5026873298607608, 4.481183080848961, 1.6018142840321781, 1.6482067031075565, 2.7697353449463433], [8.2796435610104453, 9.7956308688691446, 5.066309369035312, 1.0691978274975567, 7.2754747197326219, 7.4679216752662611, 1.8460472498040226, 1.7245060332115747, 9.828847678500983, 5.8523888503628294], [4.735129046344202, 0.21389279999051047, 9.9823910553584571, 0.22751442405574696, 4.3063298537464378, 1.0300462704374436, 7.1885192597496097, 1.7297134743393461, 7.4494154821665912, 8.2180913094628564], [0.55370097211729696, 7.0871105126860554, 7.7450498540614178, 4.2448327660994876, 1.2746000519648371, 9.4391729894286023, 6.1902689198805465, 6.0312877871821424, 8.7890699247898425, 3.1611885774377635], [8.9903796016343396, 3.4471256572948263, 8.4932841564173884, 9.9373309006088171, 2.6191045587156303, 0.77351004199567641, 1.4024547359632467, 7.454551829233095, 2.6194195569905077, 4.0298520046877577], [4.7641019675563543, 3.8129279818642861, 9.0747728919768225, 6.4920816381757511, 6.7882405668469881, 7.0063465072165911, 5.7386637585592792, 7.5230234961300599, 0.91592641387099771, 8.6646639602141899], [5.6862365678538973, 4.8755032417073192, 9.5859588536709328, 8.1186668576209513, 5.3811119011589454, 3.8280043169558411, 9.9983397606134918, 6.1835824149566241, 3.4201107815517515, 0.84968218962971687], [2.791270331453247, 2.9735813587818685, 3.0654358664150494, 5.4929582569491755, 3.9238922832952996, 9.2657934977933269, 5.0681592194030571, 9.6910348814034712, 2.0972430846802959, 0.96789458347651514], [3.1989914495545624, 3.7607248895716507, 5.5182323136835318, 2.4724154287944913, 7.2920674615977124, 9.7009225179758473, 9.9421519655410044, 2.6109645810252315, 9.0484630420475316, 3.6771724535825703], [6.305746358135309, 7.6948754823713771, 3.6012681436537397, 1.263350310992416, 3.8581878444772943, 7.1047027925517909, 2.1904752468927735, 0.32914734762647391, 3.1668377278172235, 2.0518472657841924]]> {alignment = 64 : i64}
  func.func @matmul(%arg0: memref<?xindex>, %arg1: memref<?xindex>, %arg2: memref<?xf64>, %arg3: !llvm.struct<(array<2 x i64>, array<3 x i64>)>, %arg4: tensor<10x10xf64>, %arg5: tensor<10x10xf64>) -> tensor<10x10xf64> {
    %cst = arith.constant dense<0.000000e+00> : vector<4xf64>
    %c4 = arith.constant 4 : index
    %c1 = arith.constant 1 : index
    %c0 = arith.constant 0 : index
    %c10 = arith.constant 10 : index
    %0 = llvm.extractvalue %arg3[1, 2] : !llvm.struct<(array<2 x i64>, array<3 x i64>)> 
    %1 = arith.index_cast %0 : i64 to index
    %subview = memref.subview %arg2[0] [%1] [1] : memref<?xf64> to memref<?xf64>
    %2 = bufferization.to_memref %arg4 : tensor<10x10xf64> to memref<10x10xf64>
    %3 = bufferization.to_memref %arg5 : tensor<10x10xf64> to memref<10x10xf64>
    %4 = llvm.extractvalue %arg3[1, 0] : !llvm.struct<(array<2 x i64>, array<3 x i64>)> 
    %5 = arith.index_cast %4 : i64 to index
    %subview_0 = memref.subview %arg0[0] [%5] [1] : memref<?xindex> to memref<?xindex>
    %6 = llvm.extractvalue %arg3[1, 1] : !llvm.struct<(array<2 x i64>, array<3 x i64>)> 
    %7 = arith.index_cast %6 : i64 to index
    %subview_1 = memref.subview %arg1[0] [%7] [1] : memref<?xindex> to memref<?xindex>
    scf.for %arg6 = %c0 to %c10 step %c1 {
      %9 = memref.load %subview_0[%arg6] : memref<?xindex>
      %10 = arith.addi %arg6, %c1 : index
      %11 = memref.load %subview_0[%10] : memref<?xindex>
      scf.for %arg7 = %9 to %11 step %c1 {
        %12 = memref.load %subview_1[%arg7] : memref<?xindex>
        %13 = memref.load %subview[%arg7] : memref<?xf64>
        scf.for %arg8 = %c0 to %c10 step %c4 {
          %14 = affine.min #map(%arg8)
          %15 = vector.create_mask %14 : vector<4xi1>
          %16 = vector.maskedload %3[%arg6, %arg8], %15, %cst : memref<10x10xf64>, vector<4xi1>, vector<4xf64> into vector<4xf64>
          %17 = vector.broadcast %13 : f64 to vector<4xf64>
          %18 = vector.maskedload %2[%12, %arg8], %15, %cst : memref<10x10xf64>, vector<4xi1>, vector<4xf64> into vector<4xf64>
          %19 = arith.mulf %17, %18 : vector<4xf64>
          %20 = arith.addf %16, %19 : vector<4xf64>
          vector.maskedstore %3[%arg6, %arg8], %15, %20 : memref<10x10xf64>, vector<4xi1>, vector<4xf64>
        } {"Emitted from" = "linalg.generic"}
      } {"Emitted from" = "linalg.generic"}
    } {"Emitted from" = "linalg.generic"}
    %8 = bufferization.to_tensor %3 : memref<10x10xf64> to tensor<10x10xf64>
    return %8 : tensor<10x10xf64>
  }
  func.func @main() -> i64 {
    %c8 = arith.constant 8 : index
    %cst = arith.constant 0.000000e+00 : f64
    %c1 = arith.constant 1 : index
    %c10 = arith.constant 10 : index
    %c0 = arith.constant 0 : index
    %0 = memref.get_global @__constant_10x10xf64 : memref<10x10xf64>
    %1 = bufferization.to_tensor %0 : memref<10x10xf64> to tensor<10x10xf64>
    %2 = bufferization.alloc_tensor() : tensor<10x10xf64>
    %3:4 = call @assemble_sparse() : () -> (memref<?xindex>, memref<?xindex>, memref<?xf64>, !llvm.struct<(array<2 x i64>, array<3 x i64>)>)
    %4 = call @matmul(%3#0, %3#1, %3#2, %3#3, %1, %2) : (memref<?xindex>, memref<?xindex>, memref<?xf64>, !llvm.struct<(array<2 x i64>, array<3 x i64>)>, tensor<10x10xf64>, tensor<10x10xf64>) -> tensor<10x10xf64>
    scf.for %arg0 = %c0 to %c10 step %c1 {
      %6 = vector.transfer_read %4[%arg0, %c0], %cst {in_bounds = [true]} : tensor<10x10xf64>, vector<10xf64>
      vector.print %6 : vector<10xf64>
    }
    %extracted = tensor.extract %4[%c8, %c8] : tensor<10x10xf64>
    %5 = arith.fptosi %extracted : f64 to i64
    return %5 : i64
  }
  func.func @assemble_sparse() -> (memref<?xindex>, memref<?xindex>, memref<?xf64>, !llvm.struct<(array<2 x i64>, array<3 x i64>)>) {
    %c11_i64 = arith.constant 11 : i64
    %c10_i64 = arith.constant 10 : i64
    %c0_i64 = arith.constant 0 : i64
    %0 = llvm.mlir.poison : !llvm.struct<(array<2 x i64>, array<3 x i64>)>
    %c10 = arith.constant 10 : index
    %1 = memref.get_global @__constant_30xf64 : memref<30xf64>
    %2 = memref.get_global @__constant_11xindex : memref<11xindex>
    %3 = memref.get_global @__constant_30xindex : memref<30xindex>
    %cast = memref.cast %2 : memref<11xindex> to memref<?xindex>
    %cast_0 = memref.cast %3 : memref<30xindex> to memref<?xindex>
    %cast_1 = memref.cast %1 : memref<30xf64> to memref<?xf64>
    %4 = llvm.insertvalue %c0_i64, %0[1, 0] : !llvm.struct<(array<2 x i64>, array<3 x i64>)> 
    %5 = llvm.insertvalue %c0_i64, %4[1, 1] : !llvm.struct<(array<2 x i64>, array<3 x i64>)> 
    %6 = llvm.insertvalue %c0_i64, %5[1, 2] : !llvm.struct<(array<2 x i64>, array<3 x i64>)> 
    %7 = llvm.insertvalue %c10_i64, %6[0, 0] : !llvm.struct<(array<2 x i64>, array<3 x i64>)> 
    %8 = llvm.insertvalue %c10_i64, %7[0, 1] : !llvm.struct<(array<2 x i64>, array<3 x i64>)> 
    %9 = llvm.insertvalue %c11_i64, %8[1, 0] : !llvm.struct<(array<2 x i64>, array<3 x i64>)> 
    %10 = memref.load %2[%c10] : memref<11xindex>
    %11 = arith.index_cast %10 : index to i64
    %12 = llvm.insertvalue %11, %9[1, 1] : !llvm.struct<(array<2 x i64>, array<3 x i64>)> 
    %13 = arith.index_cast %10 : index to i64
    %14 = llvm.insertvalue %13, %12[1, 2] : !llvm.struct<(array<2 x i64>, array<3 x i64>)> 
    return %cast, %cast_0, %cast_1, %14 : memref<?xindex>, memref<?xindex>, memref<?xf64>, !llvm.struct<(array<2 x i64>, array<3 x i64>)>
  }
}


// -----// IR Dump After ConvertVectorToSCF (convert-vector-to-scf) //----- //
#map = affine_map<(d0) -> (-d0 + 10, 4)>
module {
  memref.global "private" constant @__constant_30xindex : memref<30xindex> = dense<[8, 3, 4, 6, 9, 2, 4, 0, 1, 2, 3, 5, 7, 8, 3, 6, 2, 3, 4, 5, 8, 1, 5, 7, 8, 5, 9, 4, 7, 7]> {alignment = 64 : i64}
  memref.global "private" constant @__constant_11xindex : memref<11xindex> = dense<[0, 1, 5, 7, 14, 16, 21, 25, 27, 29, 30]> {alignment = 64 : i64}
  memref.global "private" constant @__constant_30xf64 : memref<30xf64> = dense<[4.7563469999999999, 2.102859, 5.4238689999999998, 5.577680e+00, 3.001240e-01, 4.8357549999999998, 8.8596050000000002, 1.592490e+00, 7.372070e+00, 7.2462879999999998, 5.9191609999999999, 5.9593920000000002, 4.6956530000000001, 6.328630e-01, 3.1591619999999998, 4.7083050000000002, 8.4356449999999992, 5.4309390000000004, 2.1190630000000001, 1.545420e-01, 2.595040e+00, 1.4655819999999999, 1.321259, 3.702925, 3.542246, 6.831162, 1.723510e+00, 7.8729019999999998, 6.0081550000000004, 1.047045]> {alignment = 64 : i64}
  memref.global "private" constant @__constant_10x10xf64 : memref<10x10xf64> = dense<[[5.0072820879405331, 2.1420497309468542, 8.4364357946217474, 3.3512684114489364, 4.8578737173077684, 6.5026873298607608, 4.481183080848961, 1.6018142840321781, 1.6482067031075565, 2.7697353449463433], [8.2796435610104453, 9.7956308688691446, 5.066309369035312, 1.0691978274975567, 7.2754747197326219, 7.4679216752662611, 1.8460472498040226, 1.7245060332115747, 9.828847678500983, 5.8523888503628294], [4.735129046344202, 0.21389279999051047, 9.9823910553584571, 0.22751442405574696, 4.3063298537464378, 1.0300462704374436, 7.1885192597496097, 1.7297134743393461, 7.4494154821665912, 8.2180913094628564], [0.55370097211729696, 7.0871105126860554, 7.7450498540614178, 4.2448327660994876, 1.2746000519648371, 9.4391729894286023, 6.1902689198805465, 6.0312877871821424, 8.7890699247898425, 3.1611885774377635], [8.9903796016343396, 3.4471256572948263, 8.4932841564173884, 9.9373309006088171, 2.6191045587156303, 0.77351004199567641, 1.4024547359632467, 7.454551829233095, 2.6194195569905077, 4.0298520046877577], [4.7641019675563543, 3.8129279818642861, 9.0747728919768225, 6.4920816381757511, 6.7882405668469881, 7.0063465072165911, 5.7386637585592792, 7.5230234961300599, 0.91592641387099771, 8.6646639602141899], [5.6862365678538973, 4.8755032417073192, 9.5859588536709328, 8.1186668576209513, 5.3811119011589454, 3.8280043169558411, 9.9983397606134918, 6.1835824149566241, 3.4201107815517515, 0.84968218962971687], [2.791270331453247, 2.9735813587818685, 3.0654358664150494, 5.4929582569491755, 3.9238922832952996, 9.2657934977933269, 5.0681592194030571, 9.6910348814034712, 2.0972430846802959, 0.96789458347651514], [3.1989914495545624, 3.7607248895716507, 5.5182323136835318, 2.4724154287944913, 7.2920674615977124, 9.7009225179758473, 9.9421519655410044, 2.6109645810252315, 9.0484630420475316, 3.6771724535825703], [6.305746358135309, 7.6948754823713771, 3.6012681436537397, 1.263350310992416, 3.8581878444772943, 7.1047027925517909, 2.1904752468927735, 0.32914734762647391, 3.1668377278172235, 2.0518472657841924]]> {alignment = 64 : i64}
  func.func @matmul(%arg0: memref<?xindex>, %arg1: memref<?xindex>, %arg2: memref<?xf64>, %arg3: !llvm.struct<(array<2 x i64>, array<3 x i64>)>, %arg4: tensor<10x10xf64>, %arg5: tensor<10x10xf64>) -> tensor<10x10xf64> {
    %cst = arith.constant dense<0.000000e+00> : vector<4xf64>
    %c4 = arith.constant 4 : index
    %c1 = arith.constant 1 : index
    %c0 = arith.constant 0 : index
    %c10 = arith.constant 10 : index
    %0 = llvm.extractvalue %arg3[1, 2] : !llvm.struct<(array<2 x i64>, array<3 x i64>)> 
    %1 = arith.index_cast %0 : i64 to index
    %subview = memref.subview %arg2[0] [%1] [1] : memref<?xf64> to memref<?xf64>
    %2 = bufferization.to_memref %arg4 : tensor<10x10xf64> to memref<10x10xf64>
    %3 = bufferization.to_memref %arg5 : tensor<10x10xf64> to memref<10x10xf64>
    %4 = llvm.extractvalue %arg3[1, 0] : !llvm.struct<(array<2 x i64>, array<3 x i64>)> 
    %5 = arith.index_cast %4 : i64 to index
    %subview_0 = memref.subview %arg0[0] [%5] [1] : memref<?xindex> to memref<?xindex>
    %6 = llvm.extractvalue %arg3[1, 1] : !llvm.struct<(array<2 x i64>, array<3 x i64>)> 
    %7 = arith.index_cast %6 : i64 to index
    %subview_1 = memref.subview %arg1[0] [%7] [1] : memref<?xindex> to memref<?xindex>
    scf.for %arg6 = %c0 to %c10 step %c1 {
      %9 = memref.load %subview_0[%arg6] : memref<?xindex>
      %10 = arith.addi %arg6, %c1 : index
      %11 = memref.load %subview_0[%10] : memref<?xindex>
      scf.for %arg7 = %9 to %11 step %c1 {
        %12 = memref.load %subview_1[%arg7] : memref<?xindex>
        %13 = memref.load %subview[%arg7] : memref<?xf64>
        scf.for %arg8 = %c0 to %c10 step %c4 {
          %14 = affine.min #map(%arg8)
          %15 = vector.create_mask %14 : vector<4xi1>
          %16 = vector.maskedload %3[%arg6, %arg8], %15, %cst : memref<10x10xf64>, vector<4xi1>, vector<4xf64> into vector<4xf64>
          %17 = vector.broadcast %13 : f64 to vector<4xf64>
          %18 = vector.maskedload %2[%12, %arg8], %15, %cst : memref<10x10xf64>, vector<4xi1>, vector<4xf64> into vector<4xf64>
          %19 = arith.mulf %17, %18 : vector<4xf64>
          %20 = arith.addf %16, %19 : vector<4xf64>
          vector.maskedstore %3[%arg6, %arg8], %15, %20 : memref<10x10xf64>, vector<4xi1>, vector<4xf64>
        } {"Emitted from" = "linalg.generic"}
      } {"Emitted from" = "linalg.generic"}
    } {"Emitted from" = "linalg.generic"}
    %8 = bufferization.to_tensor %3 : memref<10x10xf64> to tensor<10x10xf64>
    return %8 : tensor<10x10xf64>
  }
  func.func @main() -> i64 {
    %c9 = arith.constant 9 : index
    %c8 = arith.constant 8 : index
    %cst = arith.constant 0.000000e+00 : f64
    %c1 = arith.constant 1 : index
    %c10 = arith.constant 10 : index
    %c0 = arith.constant 0 : index
    %0 = memref.get_global @__constant_10x10xf64 : memref<10x10xf64>
    %1 = bufferization.to_tensor %0 : memref<10x10xf64> to tensor<10x10xf64>
    %2 = bufferization.alloc_tensor() : tensor<10x10xf64>
    %3:4 = call @assemble_sparse() : () -> (memref<?xindex>, memref<?xindex>, memref<?xf64>, !llvm.struct<(array<2 x i64>, array<3 x i64>)>)
    %4 = call @matmul(%3#0, %3#1, %3#2, %3#3, %1, %2) : (memref<?xindex>, memref<?xindex>, memref<?xf64>, !llvm.struct<(array<2 x i64>, array<3 x i64>)>, tensor<10x10xf64>, tensor<10x10xf64>) -> tensor<10x10xf64>
    scf.for %arg0 = %c0 to %c10 step %c1 {
      %6 = vector.transfer_read %4[%arg0, %c0], %cst {in_bounds = [true]} : tensor<10x10xf64>, vector<10xf64>
      vector.print punctuation <open>
      scf.for %arg1 = %c0 to %c10 step %c1 {
        %7 = vector.extractelement %6[%arg1 : index] : vector<10xf64>
        vector.print %7 : f64 punctuation <no_punctuation>
        %8 = arith.cmpi ult, %arg1, %c9 : index
        scf.if %8 {
          vector.print punctuation <comma>
        }
      }
      vector.print punctuation <close>
      vector.print
    }
    %extracted = tensor.extract %4[%c8, %c8] : tensor<10x10xf64>
    %5 = arith.fptosi %extracted : f64 to i64
    return %5 : i64
  }
  func.func @assemble_sparse() -> (memref<?xindex>, memref<?xindex>, memref<?xf64>, !llvm.struct<(array<2 x i64>, array<3 x i64>)>) {
    %c11_i64 = arith.constant 11 : i64
    %c10_i64 = arith.constant 10 : i64
    %c0_i64 = arith.constant 0 : i64
    %0 = llvm.mlir.poison : !llvm.struct<(array<2 x i64>, array<3 x i64>)>
    %c10 = arith.constant 10 : index
    %1 = memref.get_global @__constant_30xf64 : memref<30xf64>
    %2 = memref.get_global @__constant_11xindex : memref<11xindex>
    %3 = memref.get_global @__constant_30xindex : memref<30xindex>
    %cast = memref.cast %2 : memref<11xindex> to memref<?xindex>
    %cast_0 = memref.cast %3 : memref<30xindex> to memref<?xindex>
    %cast_1 = memref.cast %1 : memref<30xf64> to memref<?xf64>
    %4 = llvm.insertvalue %c0_i64, %0[1, 0] : !llvm.struct<(array<2 x i64>, array<3 x i64>)> 
    %5 = llvm.insertvalue %c0_i64, %4[1, 1] : !llvm.struct<(array<2 x i64>, array<3 x i64>)> 
    %6 = llvm.insertvalue %c0_i64, %5[1, 2] : !llvm.struct<(array<2 x i64>, array<3 x i64>)> 
    %7 = llvm.insertvalue %c10_i64, %6[0, 0] : !llvm.struct<(array<2 x i64>, array<3 x i64>)> 
    %8 = llvm.insertvalue %c10_i64, %7[0, 1] : !llvm.struct<(array<2 x i64>, array<3 x i64>)> 
    %9 = llvm.insertvalue %c11_i64, %8[1, 0] : !llvm.struct<(array<2 x i64>, array<3 x i64>)> 
    %10 = memref.load %2[%c10] : memref<11xindex>
    %11 = arith.index_cast %10 : index to i64
    %12 = llvm.insertvalue %11, %9[1, 1] : !llvm.struct<(array<2 x i64>, array<3 x i64>)> 
    %13 = arith.index_cast %10 : index to i64
    %14 = llvm.insertvalue %13, %12[1, 2] : !llvm.struct<(array<2 x i64>, array<3 x i64>)> 
    return %cast, %cast_0, %cast_1, %14 : memref<?xindex>, memref<?xindex>, memref<?xf64>, !llvm.struct<(array<2 x i64>, array<3 x i64>)>
  }
}


// -----// IR Dump After ExpandRealloc (expand-realloc) //----- //
#map = affine_map<(d0) -> (-d0 + 10, 4)>
module {
  memref.global "private" constant @__constant_30xindex : memref<30xindex> = dense<[8, 3, 4, 6, 9, 2, 4, 0, 1, 2, 3, 5, 7, 8, 3, 6, 2, 3, 4, 5, 8, 1, 5, 7, 8, 5, 9, 4, 7, 7]> {alignment = 64 : i64}
  memref.global "private" constant @__constant_11xindex : memref<11xindex> = dense<[0, 1, 5, 7, 14, 16, 21, 25, 27, 29, 30]> {alignment = 64 : i64}
  memref.global "private" constant @__constant_30xf64 : memref<30xf64> = dense<[4.7563469999999999, 2.102859, 5.4238689999999998, 5.577680e+00, 3.001240e-01, 4.8357549999999998, 8.8596050000000002, 1.592490e+00, 7.372070e+00, 7.2462879999999998, 5.9191609999999999, 5.9593920000000002, 4.6956530000000001, 6.328630e-01, 3.1591619999999998, 4.7083050000000002, 8.4356449999999992, 5.4309390000000004, 2.1190630000000001, 1.545420e-01, 2.595040e+00, 1.4655819999999999, 1.321259, 3.702925, 3.542246, 6.831162, 1.723510e+00, 7.8729019999999998, 6.0081550000000004, 1.047045]> {alignment = 64 : i64}
  memref.global "private" constant @__constant_10x10xf64 : memref<10x10xf64> = dense<[[5.0072820879405331, 2.1420497309468542, 8.4364357946217474, 3.3512684114489364, 4.8578737173077684, 6.5026873298607608, 4.481183080848961, 1.6018142840321781, 1.6482067031075565, 2.7697353449463433], [8.2796435610104453, 9.7956308688691446, 5.066309369035312, 1.0691978274975567, 7.2754747197326219, 7.4679216752662611, 1.8460472498040226, 1.7245060332115747, 9.828847678500983, 5.8523888503628294], [4.735129046344202, 0.21389279999051047, 9.9823910553584571, 0.22751442405574696, 4.3063298537464378, 1.0300462704374436, 7.1885192597496097, 1.7297134743393461, 7.4494154821665912, 8.2180913094628564], [0.55370097211729696, 7.0871105126860554, 7.7450498540614178, 4.2448327660994876, 1.2746000519648371, 9.4391729894286023, 6.1902689198805465, 6.0312877871821424, 8.7890699247898425, 3.1611885774377635], [8.9903796016343396, 3.4471256572948263, 8.4932841564173884, 9.9373309006088171, 2.6191045587156303, 0.77351004199567641, 1.4024547359632467, 7.454551829233095, 2.6194195569905077, 4.0298520046877577], [4.7641019675563543, 3.8129279818642861, 9.0747728919768225, 6.4920816381757511, 6.7882405668469881, 7.0063465072165911, 5.7386637585592792, 7.5230234961300599, 0.91592641387099771, 8.6646639602141899], [5.6862365678538973, 4.8755032417073192, 9.5859588536709328, 8.1186668576209513, 5.3811119011589454, 3.8280043169558411, 9.9983397606134918, 6.1835824149566241, 3.4201107815517515, 0.84968218962971687], [2.791270331453247, 2.9735813587818685, 3.0654358664150494, 5.4929582569491755, 3.9238922832952996, 9.2657934977933269, 5.0681592194030571, 9.6910348814034712, 2.0972430846802959, 0.96789458347651514], [3.1989914495545624, 3.7607248895716507, 5.5182323136835318, 2.4724154287944913, 7.2920674615977124, 9.7009225179758473, 9.9421519655410044, 2.6109645810252315, 9.0484630420475316, 3.6771724535825703], [6.305746358135309, 7.6948754823713771, 3.6012681436537397, 1.263350310992416, 3.8581878444772943, 7.1047027925517909, 2.1904752468927735, 0.32914734762647391, 3.1668377278172235, 2.0518472657841924]]> {alignment = 64 : i64}
  func.func @matmul(%arg0: memref<?xindex>, %arg1: memref<?xindex>, %arg2: memref<?xf64>, %arg3: !llvm.struct<(array<2 x i64>, array<3 x i64>)>, %arg4: tensor<10x10xf64>, %arg5: tensor<10x10xf64>) -> tensor<10x10xf64> {
    %cst = arith.constant dense<0.000000e+00> : vector<4xf64>
    %c4 = arith.constant 4 : index
    %c1 = arith.constant 1 : index
    %c0 = arith.constant 0 : index
    %c10 = arith.constant 10 : index
    %0 = llvm.extractvalue %arg3[1, 2] : !llvm.struct<(array<2 x i64>, array<3 x i64>)> 
    %1 = arith.index_cast %0 : i64 to index
    %subview = memref.subview %arg2[0] [%1] [1] : memref<?xf64> to memref<?xf64>
    %2 = bufferization.to_memref %arg4 : tensor<10x10xf64> to memref<10x10xf64>
    %3 = bufferization.to_memref %arg5 : tensor<10x10xf64> to memref<10x10xf64>
    %4 = llvm.extractvalue %arg3[1, 0] : !llvm.struct<(array<2 x i64>, array<3 x i64>)> 
    %5 = arith.index_cast %4 : i64 to index
    %subview_0 = memref.subview %arg0[0] [%5] [1] : memref<?xindex> to memref<?xindex>
    %6 = llvm.extractvalue %arg3[1, 1] : !llvm.struct<(array<2 x i64>, array<3 x i64>)> 
    %7 = arith.index_cast %6 : i64 to index
    %subview_1 = memref.subview %arg1[0] [%7] [1] : memref<?xindex> to memref<?xindex>
    scf.for %arg6 = %c0 to %c10 step %c1 {
      %9 = memref.load %subview_0[%arg6] : memref<?xindex>
      %10 = arith.addi %arg6, %c1 : index
      %11 = memref.load %subview_0[%10] : memref<?xindex>
      scf.for %arg7 = %9 to %11 step %c1 {
        %12 = memref.load %subview_1[%arg7] : memref<?xindex>
        %13 = memref.load %subview[%arg7] : memref<?xf64>
        scf.for %arg8 = %c0 to %c10 step %c4 {
          %14 = affine.min #map(%arg8)
          %15 = vector.create_mask %14 : vector<4xi1>
          %16 = vector.maskedload %3[%arg6, %arg8], %15, %cst : memref<10x10xf64>, vector<4xi1>, vector<4xf64> into vector<4xf64>
          %17 = vector.broadcast %13 : f64 to vector<4xf64>
          %18 = vector.maskedload %2[%12, %arg8], %15, %cst : memref<10x10xf64>, vector<4xi1>, vector<4xf64> into vector<4xf64>
          %19 = arith.mulf %17, %18 : vector<4xf64>
          %20 = arith.addf %16, %19 : vector<4xf64>
          vector.maskedstore %3[%arg6, %arg8], %15, %20 : memref<10x10xf64>, vector<4xi1>, vector<4xf64>
        } {"Emitted from" = "linalg.generic"}
      } {"Emitted from" = "linalg.generic"}
    } {"Emitted from" = "linalg.generic"}
    %8 = bufferization.to_tensor %3 : memref<10x10xf64> to tensor<10x10xf64>
    return %8 : tensor<10x10xf64>
  }
  func.func @main() -> i64 {
    %c9 = arith.constant 9 : index
    %c8 = arith.constant 8 : index
    %cst = arith.constant 0.000000e+00 : f64
    %c1 = arith.constant 1 : index
    %c10 = arith.constant 10 : index
    %c0 = arith.constant 0 : index
    %0 = memref.get_global @__constant_10x10xf64 : memref<10x10xf64>
    %1 = bufferization.to_tensor %0 : memref<10x10xf64> to tensor<10x10xf64>
    %2 = bufferization.alloc_tensor() : tensor<10x10xf64>
    %3:4 = call @assemble_sparse() : () -> (memref<?xindex>, memref<?xindex>, memref<?xf64>, !llvm.struct<(array<2 x i64>, array<3 x i64>)>)
    %4 = call @matmul(%3#0, %3#1, %3#2, %3#3, %1, %2) : (memref<?xindex>, memref<?xindex>, memref<?xf64>, !llvm.struct<(array<2 x i64>, array<3 x i64>)>, tensor<10x10xf64>, tensor<10x10xf64>) -> tensor<10x10xf64>
    scf.for %arg0 = %c0 to %c10 step %c1 {
      %6 = vector.transfer_read %4[%arg0, %c0], %cst {in_bounds = [true]} : tensor<10x10xf64>, vector<10xf64>
      vector.print punctuation <open>
      scf.for %arg1 = %c0 to %c10 step %c1 {
        %7 = vector.extractelement %6[%arg1 : index] : vector<10xf64>
        vector.print %7 : f64 punctuation <no_punctuation>
        %8 = arith.cmpi ult, %arg1, %c9 : index
        scf.if %8 {
          vector.print punctuation <comma>
        }
      }
      vector.print punctuation <close>
      vector.print
    }
    %extracted = tensor.extract %4[%c8, %c8] : tensor<10x10xf64>
    %5 = arith.fptosi %extracted : f64 to i64
    return %5 : i64
  }
  func.func @assemble_sparse() -> (memref<?xindex>, memref<?xindex>, memref<?xf64>, !llvm.struct<(array<2 x i64>, array<3 x i64>)>) {
    %c11_i64 = arith.constant 11 : i64
    %c10_i64 = arith.constant 10 : i64
    %c0_i64 = arith.constant 0 : i64
    %0 = llvm.mlir.poison : !llvm.struct<(array<2 x i64>, array<3 x i64>)>
    %c10 = arith.constant 10 : index
    %1 = memref.get_global @__constant_30xf64 : memref<30xf64>
    %2 = memref.get_global @__constant_11xindex : memref<11xindex>
    %3 = memref.get_global @__constant_30xindex : memref<30xindex>
    %cast = memref.cast %2 : memref<11xindex> to memref<?xindex>
    %cast_0 = memref.cast %3 : memref<30xindex> to memref<?xindex>
    %cast_1 = memref.cast %1 : memref<30xf64> to memref<?xf64>
    %4 = llvm.insertvalue %c0_i64, %0[1, 0] : !llvm.struct<(array<2 x i64>, array<3 x i64>)> 
    %5 = llvm.insertvalue %c0_i64, %4[1, 1] : !llvm.struct<(array<2 x i64>, array<3 x i64>)> 
    %6 = llvm.insertvalue %c0_i64, %5[1, 2] : !llvm.struct<(array<2 x i64>, array<3 x i64>)> 
    %7 = llvm.insertvalue %c10_i64, %6[0, 0] : !llvm.struct<(array<2 x i64>, array<3 x i64>)> 
    %8 = llvm.insertvalue %c10_i64, %7[0, 1] : !llvm.struct<(array<2 x i64>, array<3 x i64>)> 
    %9 = llvm.insertvalue %c11_i64, %8[1, 0] : !llvm.struct<(array<2 x i64>, array<3 x i64>)> 
    %10 = memref.load %2[%c10] : memref<11xindex>
    %11 = arith.index_cast %10 : index to i64
    %12 = llvm.insertvalue %11, %9[1, 1] : !llvm.struct<(array<2 x i64>, array<3 x i64>)> 
    %13 = arith.index_cast %10 : index to i64
    %14 = llvm.insertvalue %13, %12[1, 2] : !llvm.struct<(array<2 x i64>, array<3 x i64>)> 
    return %cast, %cast_0, %cast_1, %14 : memref<?xindex>, memref<?xindex>, memref<?xf64>, !llvm.struct<(array<2 x i64>, array<3 x i64>)>
  }
}


// -----// IR Dump After SCFToControlFlowPass (convert-scf-to-cf) //----- //
#map = affine_map<(d0) -> (-d0 + 10, 4)>
module {
  memref.global "private" constant @__constant_30xindex : memref<30xindex> = dense<[8, 3, 4, 6, 9, 2, 4, 0, 1, 2, 3, 5, 7, 8, 3, 6, 2, 3, 4, 5, 8, 1, 5, 7, 8, 5, 9, 4, 7, 7]> {alignment = 64 : i64}
  memref.global "private" constant @__constant_11xindex : memref<11xindex> = dense<[0, 1, 5, 7, 14, 16, 21, 25, 27, 29, 30]> {alignment = 64 : i64}
  memref.global "private" constant @__constant_30xf64 : memref<30xf64> = dense<[4.7563469999999999, 2.102859, 5.4238689999999998, 5.577680e+00, 3.001240e-01, 4.8357549999999998, 8.8596050000000002, 1.592490e+00, 7.372070e+00, 7.2462879999999998, 5.9191609999999999, 5.9593920000000002, 4.6956530000000001, 6.328630e-01, 3.1591619999999998, 4.7083050000000002, 8.4356449999999992, 5.4309390000000004, 2.1190630000000001, 1.545420e-01, 2.595040e+00, 1.4655819999999999, 1.321259, 3.702925, 3.542246, 6.831162, 1.723510e+00, 7.8729019999999998, 6.0081550000000004, 1.047045]> {alignment = 64 : i64}
  memref.global "private" constant @__constant_10x10xf64 : memref<10x10xf64> = dense<[[5.0072820879405331, 2.1420497309468542, 8.4364357946217474, 3.3512684114489364, 4.8578737173077684, 6.5026873298607608, 4.481183080848961, 1.6018142840321781, 1.6482067031075565, 2.7697353449463433], [8.2796435610104453, 9.7956308688691446, 5.066309369035312, 1.0691978274975567, 7.2754747197326219, 7.4679216752662611, 1.8460472498040226, 1.7245060332115747, 9.828847678500983, 5.8523888503628294], [4.735129046344202, 0.21389279999051047, 9.9823910553584571, 0.22751442405574696, 4.3063298537464378, 1.0300462704374436, 7.1885192597496097, 1.7297134743393461, 7.4494154821665912, 8.2180913094628564], [0.55370097211729696, 7.0871105126860554, 7.7450498540614178, 4.2448327660994876, 1.2746000519648371, 9.4391729894286023, 6.1902689198805465, 6.0312877871821424, 8.7890699247898425, 3.1611885774377635], [8.9903796016343396, 3.4471256572948263, 8.4932841564173884, 9.9373309006088171, 2.6191045587156303, 0.77351004199567641, 1.4024547359632467, 7.454551829233095, 2.6194195569905077, 4.0298520046877577], [4.7641019675563543, 3.8129279818642861, 9.0747728919768225, 6.4920816381757511, 6.7882405668469881, 7.0063465072165911, 5.7386637585592792, 7.5230234961300599, 0.91592641387099771, 8.6646639602141899], [5.6862365678538973, 4.8755032417073192, 9.5859588536709328, 8.1186668576209513, 5.3811119011589454, 3.8280043169558411, 9.9983397606134918, 6.1835824149566241, 3.4201107815517515, 0.84968218962971687], [2.791270331453247, 2.9735813587818685, 3.0654358664150494, 5.4929582569491755, 3.9238922832952996, 9.2657934977933269, 5.0681592194030571, 9.6910348814034712, 2.0972430846802959, 0.96789458347651514], [3.1989914495545624, 3.7607248895716507, 5.5182323136835318, 2.4724154287944913, 7.2920674615977124, 9.7009225179758473, 9.9421519655410044, 2.6109645810252315, 9.0484630420475316, 3.6771724535825703], [6.305746358135309, 7.6948754823713771, 3.6012681436537397, 1.263350310992416, 3.8581878444772943, 7.1047027925517909, 2.1904752468927735, 0.32914734762647391, 3.1668377278172235, 2.0518472657841924]]> {alignment = 64 : i64}
  func.func @matmul(%arg0: memref<?xindex>, %arg1: memref<?xindex>, %arg2: memref<?xf64>, %arg3: !llvm.struct<(array<2 x i64>, array<3 x i64>)>, %arg4: tensor<10x10xf64>, %arg5: tensor<10x10xf64>) -> tensor<10x10xf64> {
    %cst = arith.constant dense<0.000000e+00> : vector<4xf64>
    %c4 = arith.constant 4 : index
    %c1 = arith.constant 1 : index
    %c0 = arith.constant 0 : index
    %c10 = arith.constant 10 : index
    %0 = llvm.extractvalue %arg3[1, 2] : !llvm.struct<(array<2 x i64>, array<3 x i64>)> 
    %1 = arith.index_cast %0 : i64 to index
    %subview = memref.subview %arg2[0] [%1] [1] : memref<?xf64> to memref<?xf64>
    %2 = bufferization.to_memref %arg4 : tensor<10x10xf64> to memref<10x10xf64>
    %3 = bufferization.to_memref %arg5 : tensor<10x10xf64> to memref<10x10xf64>
    %4 = llvm.extractvalue %arg3[1, 0] : !llvm.struct<(array<2 x i64>, array<3 x i64>)> 
    %5 = arith.index_cast %4 : i64 to index
    %subview_0 = memref.subview %arg0[0] [%5] [1] : memref<?xindex> to memref<?xindex>
    %6 = llvm.extractvalue %arg3[1, 1] : !llvm.struct<(array<2 x i64>, array<3 x i64>)> 
    %7 = arith.index_cast %6 : i64 to index
    %subview_1 = memref.subview %arg1[0] [%7] [1] : memref<?xindex> to memref<?xindex>
    cf.br ^bb1(%c0 : index)
  ^bb1(%8: index):  // 2 preds: ^bb0, ^bb8
    %9 = arith.cmpi slt, %8, %c10 : index
    cf.cond_br %9, ^bb2, ^bb9
  ^bb2:  // pred: ^bb1
    %10 = memref.load %subview_0[%8] : memref<?xindex>
    %11 = arith.addi %8, %c1 : index
    %12 = memref.load %subview_0[%11] : memref<?xindex>
    cf.br ^bb3(%10 : index)
  ^bb3(%13: index):  // 2 preds: ^bb2, ^bb7
    %14 = arith.cmpi slt, %13, %12 : index
    cf.cond_br %14, ^bb4, ^bb8
  ^bb4:  // pred: ^bb3
    %15 = memref.load %subview_1[%13] : memref<?xindex>
    %16 = memref.load %subview[%13] : memref<?xf64>
    cf.br ^bb5(%c0 : index)
  ^bb5(%17: index):  // 2 preds: ^bb4, ^bb6
    %18 = arith.cmpi slt, %17, %c10 : index
    cf.cond_br %18, ^bb6, ^bb7
  ^bb6:  // pred: ^bb5
    %19 = affine.min #map(%17)
    %20 = vector.create_mask %19 : vector<4xi1>
    %21 = vector.maskedload %3[%8, %17], %20, %cst : memref<10x10xf64>, vector<4xi1>, vector<4xf64> into vector<4xf64>
    %22 = vector.broadcast %16 : f64 to vector<4xf64>
    %23 = vector.maskedload %2[%15, %17], %20, %cst : memref<10x10xf64>, vector<4xi1>, vector<4xf64> into vector<4xf64>
    %24 = arith.mulf %22, %23 : vector<4xf64>
    %25 = arith.addf %21, %24 : vector<4xf64>
    vector.maskedstore %3[%8, %17], %20, %25 : memref<10x10xf64>, vector<4xi1>, vector<4xf64>
    %26 = arith.addi %17, %c4 : index
    cf.br ^bb5(%26 : index)
  ^bb7:  // pred: ^bb5
    %27 = arith.addi %13, %c1 : index
    cf.br ^bb3(%27 : index)
  ^bb8:  // pred: ^bb3
    %28 = arith.addi %8, %c1 : index
    cf.br ^bb1(%28 : index)
  ^bb9:  // pred: ^bb1
    %29 = bufferization.to_tensor %3 : memref<10x10xf64> to tensor<10x10xf64>
    return %29 : tensor<10x10xf64>
  }
  func.func @main() -> i64 {
    %c9 = arith.constant 9 : index
    %c8 = arith.constant 8 : index
    %cst = arith.constant 0.000000e+00 : f64
    %c1 = arith.constant 1 : index
    %c10 = arith.constant 10 : index
    %c0 = arith.constant 0 : index
    %0 = memref.get_global @__constant_10x10xf64 : memref<10x10xf64>
    %1 = bufferization.to_tensor %0 : memref<10x10xf64> to tensor<10x10xf64>
    %2 = bufferization.alloc_tensor() : tensor<10x10xf64>
    %3:4 = call @assemble_sparse() : () -> (memref<?xindex>, memref<?xindex>, memref<?xf64>, !llvm.struct<(array<2 x i64>, array<3 x i64>)>)
    %4 = call @matmul(%3#0, %3#1, %3#2, %3#3, %1, %2) : (memref<?xindex>, memref<?xindex>, memref<?xf64>, !llvm.struct<(array<2 x i64>, array<3 x i64>)>, tensor<10x10xf64>, tensor<10x10xf64>) -> tensor<10x10xf64>
    cf.br ^bb1(%c0 : index)
  ^bb1(%5: index):  // 2 preds: ^bb0, ^bb7
    %6 = arith.cmpi slt, %5, %c10 : index
    cf.cond_br %6, ^bb2, ^bb8
  ^bb2:  // pred: ^bb1
    %7 = vector.transfer_read %4[%5, %c0], %cst {in_bounds = [true]} : tensor<10x10xf64>, vector<10xf64>
    vector.print punctuation <open>
    cf.br ^bb3(%c0 : index)
  ^bb3(%8: index):  // 2 preds: ^bb2, ^bb6
    %9 = arith.cmpi slt, %8, %c10 : index
    cf.cond_br %9, ^bb4, ^bb7
  ^bb4:  // pred: ^bb3
    %10 = vector.extractelement %7[%8 : index] : vector<10xf64>
    vector.print %10 : f64 punctuation <no_punctuation>
    %11 = arith.cmpi ult, %8, %c9 : index
    cf.cond_br %11, ^bb5, ^bb6
  ^bb5:  // pred: ^bb4
    vector.print punctuation <comma>
    cf.br ^bb6
  ^bb6:  // 2 preds: ^bb4, ^bb5
    %12 = arith.addi %8, %c1 : index
    cf.br ^bb3(%12 : index)
  ^bb7:  // pred: ^bb3
    vector.print punctuation <close>
    vector.print
    %13 = arith.addi %5, %c1 : index
    cf.br ^bb1(%13 : index)
  ^bb8:  // pred: ^bb1
    %extracted = tensor.extract %4[%c8, %c8] : tensor<10x10xf64>
    %14 = arith.fptosi %extracted : f64 to i64
    return %14 : i64
  }
  func.func @assemble_sparse() -> (memref<?xindex>, memref<?xindex>, memref<?xf64>, !llvm.struct<(array<2 x i64>, array<3 x i64>)>) {
    %c11_i64 = arith.constant 11 : i64
    %c10_i64 = arith.constant 10 : i64
    %c0_i64 = arith.constant 0 : i64
    %0 = llvm.mlir.poison : !llvm.struct<(array<2 x i64>, array<3 x i64>)>
    %c10 = arith.constant 10 : index
    %1 = memref.get_global @__constant_30xf64 : memref<30xf64>
    %2 = memref.get_global @__constant_11xindex : memref<11xindex>
    %3 = memref.get_global @__constant_30xindex : memref<30xindex>
    %cast = memref.cast %2 : memref<11xindex> to memref<?xindex>
    %cast_0 = memref.cast %3 : memref<30xindex> to memref<?xindex>
    %cast_1 = memref.cast %1 : memref<30xf64> to memref<?xf64>
    %4 = llvm.insertvalue %c0_i64, %0[1, 0] : !llvm.struct<(array<2 x i64>, array<3 x i64>)> 
    %5 = llvm.insertvalue %c0_i64, %4[1, 1] : !llvm.struct<(array<2 x i64>, array<3 x i64>)> 
    %6 = llvm.insertvalue %c0_i64, %5[1, 2] : !llvm.struct<(array<2 x i64>, array<3 x i64>)> 
    %7 = llvm.insertvalue %c10_i64, %6[0, 0] : !llvm.struct<(array<2 x i64>, array<3 x i64>)> 
    %8 = llvm.insertvalue %c10_i64, %7[0, 1] : !llvm.struct<(array<2 x i64>, array<3 x i64>)> 
    %9 = llvm.insertvalue %c11_i64, %8[1, 0] : !llvm.struct<(array<2 x i64>, array<3 x i64>)> 
    %10 = memref.load %2[%c10] : memref<11xindex>
    %11 = arith.index_cast %10 : index to i64
    %12 = llvm.insertvalue %11, %9[1, 1] : !llvm.struct<(array<2 x i64>, array<3 x i64>)> 
    %13 = arith.index_cast %10 : index to i64
    %14 = llvm.insertvalue %13, %12[1, 2] : !llvm.struct<(array<2 x i64>, array<3 x i64>)> 
    return %cast, %cast_0, %cast_1, %14 : memref<?xindex>, memref<?xindex>, memref<?xf64>, !llvm.struct<(array<2 x i64>, array<3 x i64>)>
  }
}


// -----// IR Dump After ExpandStridedMetadata (expand-strided-metadata) //----- //
#map = affine_map<(d0) -> (-d0 + 10, 4)>
module {
  memref.global "private" constant @__constant_30xindex : memref<30xindex> = dense<[8, 3, 4, 6, 9, 2, 4, 0, 1, 2, 3, 5, 7, 8, 3, 6, 2, 3, 4, 5, 8, 1, 5, 7, 8, 5, 9, 4, 7, 7]> {alignment = 64 : i64}
  memref.global "private" constant @__constant_11xindex : memref<11xindex> = dense<[0, 1, 5, 7, 14, 16, 21, 25, 27, 29, 30]> {alignment = 64 : i64}
  memref.global "private" constant @__constant_30xf64 : memref<30xf64> = dense<[4.7563469999999999, 2.102859, 5.4238689999999998, 5.577680e+00, 3.001240e-01, 4.8357549999999998, 8.8596050000000002, 1.592490e+00, 7.372070e+00, 7.2462879999999998, 5.9191609999999999, 5.9593920000000002, 4.6956530000000001, 6.328630e-01, 3.1591619999999998, 4.7083050000000002, 8.4356449999999992, 5.4309390000000004, 2.1190630000000001, 1.545420e-01, 2.595040e+00, 1.4655819999999999, 1.321259, 3.702925, 3.542246, 6.831162, 1.723510e+00, 7.8729019999999998, 6.0081550000000004, 1.047045]> {alignment = 64 : i64}
  memref.global "private" constant @__constant_10x10xf64 : memref<10x10xf64> = dense<[[5.0072820879405331, 2.1420497309468542, 8.4364357946217474, 3.3512684114489364, 4.8578737173077684, 6.5026873298607608, 4.481183080848961, 1.6018142840321781, 1.6482067031075565, 2.7697353449463433], [8.2796435610104453, 9.7956308688691446, 5.066309369035312, 1.0691978274975567, 7.2754747197326219, 7.4679216752662611, 1.8460472498040226, 1.7245060332115747, 9.828847678500983, 5.8523888503628294], [4.735129046344202, 0.21389279999051047, 9.9823910553584571, 0.22751442405574696, 4.3063298537464378, 1.0300462704374436, 7.1885192597496097, 1.7297134743393461, 7.4494154821665912, 8.2180913094628564], [0.55370097211729696, 7.0871105126860554, 7.7450498540614178, 4.2448327660994876, 1.2746000519648371, 9.4391729894286023, 6.1902689198805465, 6.0312877871821424, 8.7890699247898425, 3.1611885774377635], [8.9903796016343396, 3.4471256572948263, 8.4932841564173884, 9.9373309006088171, 2.6191045587156303, 0.77351004199567641, 1.4024547359632467, 7.454551829233095, 2.6194195569905077, 4.0298520046877577], [4.7641019675563543, 3.8129279818642861, 9.0747728919768225, 6.4920816381757511, 6.7882405668469881, 7.0063465072165911, 5.7386637585592792, 7.5230234961300599, 0.91592641387099771, 8.6646639602141899], [5.6862365678538973, 4.8755032417073192, 9.5859588536709328, 8.1186668576209513, 5.3811119011589454, 3.8280043169558411, 9.9983397606134918, 6.1835824149566241, 3.4201107815517515, 0.84968218962971687], [2.791270331453247, 2.9735813587818685, 3.0654358664150494, 5.4929582569491755, 3.9238922832952996, 9.2657934977933269, 5.0681592194030571, 9.6910348814034712, 2.0972430846802959, 0.96789458347651514], [3.1989914495545624, 3.7607248895716507, 5.5182323136835318, 2.4724154287944913, 7.2920674615977124, 9.7009225179758473, 9.9421519655410044, 2.6109645810252315, 9.0484630420475316, 3.6771724535825703], [6.305746358135309, 7.6948754823713771, 3.6012681436537397, 1.263350310992416, 3.8581878444772943, 7.1047027925517909, 2.1904752468927735, 0.32914734762647391, 3.1668377278172235, 2.0518472657841924]]> {alignment = 64 : i64}
  func.func @matmul(%arg0: memref<?xindex>, %arg1: memref<?xindex>, %arg2: memref<?xf64>, %arg3: !llvm.struct<(array<2 x i64>, array<3 x i64>)>, %arg4: tensor<10x10xf64>, %arg5: tensor<10x10xf64>) -> tensor<10x10xf64> {
    %cst = arith.constant dense<0.000000e+00> : vector<4xf64>
    %c4 = arith.constant 4 : index
    %c1 = arith.constant 1 : index
    %c0 = arith.constant 0 : index
    %c10 = arith.constant 10 : index
    %0 = llvm.extractvalue %arg3[1, 2] : !llvm.struct<(array<2 x i64>, array<3 x i64>)> 
    %1 = arith.index_cast %0 : i64 to index
    %base_buffer, %offset, %sizes, %strides = memref.extract_strided_metadata %arg2 : memref<?xf64> -> memref<f64>, index, index, index
    %reinterpret_cast = memref.reinterpret_cast %base_buffer to offset: [0], sizes: [%1], strides: [1] : memref<f64> to memref<?xf64>
    %2 = bufferization.to_memref %arg4 : tensor<10x10xf64> to memref<10x10xf64>
    %3 = bufferization.to_memref %arg5 : tensor<10x10xf64> to memref<10x10xf64>
    %4 = llvm.extractvalue %arg3[1, 0] : !llvm.struct<(array<2 x i64>, array<3 x i64>)> 
    %5 = arith.index_cast %4 : i64 to index
    %base_buffer_0, %offset_1, %sizes_2, %strides_3 = memref.extract_strided_metadata %arg0 : memref<?xindex> -> memref<index>, index, index, index
    %reinterpret_cast_4 = memref.reinterpret_cast %base_buffer_0 to offset: [0], sizes: [%5], strides: [1] : memref<index> to memref<?xindex>
    %6 = llvm.extractvalue %arg3[1, 1] : !llvm.struct<(array<2 x i64>, array<3 x i64>)> 
    %7 = arith.index_cast %6 : i64 to index
    %base_buffer_5, %offset_6, %sizes_7, %strides_8 = memref.extract_strided_metadata %arg1 : memref<?xindex> -> memref<index>, index, index, index
    %reinterpret_cast_9 = memref.reinterpret_cast %base_buffer_5 to offset: [0], sizes: [%7], strides: [1] : memref<index> to memref<?xindex>
    cf.br ^bb1(%c0 : index)
  ^bb1(%8: index):  // 2 preds: ^bb0, ^bb8
    %9 = arith.cmpi slt, %8, %c10 : index
    cf.cond_br %9, ^bb2, ^bb9
  ^bb2:  // pred: ^bb1
    %10 = memref.load %reinterpret_cast_4[%8] : memref<?xindex>
    %11 = arith.addi %8, %c1 : index
    %12 = memref.load %reinterpret_cast_4[%11] : memref<?xindex>
    cf.br ^bb3(%10 : index)
  ^bb3(%13: index):  // 2 preds: ^bb2, ^bb7
    %14 = arith.cmpi slt, %13, %12 : index
    cf.cond_br %14, ^bb4, ^bb8
  ^bb4:  // pred: ^bb3
    %15 = memref.load %reinterpret_cast_9[%13] : memref<?xindex>
    %16 = memref.load %reinterpret_cast[%13] : memref<?xf64>
    cf.br ^bb5(%c0 : index)
  ^bb5(%17: index):  // 2 preds: ^bb4, ^bb6
    %18 = arith.cmpi slt, %17, %c10 : index
    cf.cond_br %18, ^bb6, ^bb7
  ^bb6:  // pred: ^bb5
    %19 = affine.min #map(%17)
    %20 = vector.create_mask %19 : vector<4xi1>
    %21 = vector.maskedload %3[%8, %17], %20, %cst : memref<10x10xf64>, vector<4xi1>, vector<4xf64> into vector<4xf64>
    %22 = vector.broadcast %16 : f64 to vector<4xf64>
    %23 = vector.maskedload %2[%15, %17], %20, %cst : memref<10x10xf64>, vector<4xi1>, vector<4xf64> into vector<4xf64>
    %24 = arith.mulf %22, %23 : vector<4xf64>
    %25 = arith.addf %21, %24 : vector<4xf64>
    vector.maskedstore %3[%8, %17], %20, %25 : memref<10x10xf64>, vector<4xi1>, vector<4xf64>
    %26 = arith.addi %17, %c4 : index
    cf.br ^bb5(%26 : index)
  ^bb7:  // pred: ^bb5
    %27 = arith.addi %13, %c1 : index
    cf.br ^bb3(%27 : index)
  ^bb8:  // pred: ^bb3
    %28 = arith.addi %8, %c1 : index
    cf.br ^bb1(%28 : index)
  ^bb9:  // pred: ^bb1
    %29 = bufferization.to_tensor %3 : memref<10x10xf64> to tensor<10x10xf64>
    return %29 : tensor<10x10xf64>
  }
  func.func @main() -> i64 {
    %c9 = arith.constant 9 : index
    %c8 = arith.constant 8 : index
    %cst = arith.constant 0.000000e+00 : f64
    %c1 = arith.constant 1 : index
    %c10 = arith.constant 10 : index
    %c0 = arith.constant 0 : index
    %0 = memref.get_global @__constant_10x10xf64 : memref<10x10xf64>
    %1 = bufferization.to_tensor %0 : memref<10x10xf64> to tensor<10x10xf64>
    %2 = bufferization.alloc_tensor() : tensor<10x10xf64>
    %3:4 = call @assemble_sparse() : () -> (memref<?xindex>, memref<?xindex>, memref<?xf64>, !llvm.struct<(array<2 x i64>, array<3 x i64>)>)
    %4 = call @matmul(%3#0, %3#1, %3#2, %3#3, %1, %2) : (memref<?xindex>, memref<?xindex>, memref<?xf64>, !llvm.struct<(array<2 x i64>, array<3 x i64>)>, tensor<10x10xf64>, tensor<10x10xf64>) -> tensor<10x10xf64>
    cf.br ^bb1(%c0 : index)
  ^bb1(%5: index):  // 2 preds: ^bb0, ^bb7
    %6 = arith.cmpi slt, %5, %c10 : index
    cf.cond_br %6, ^bb2, ^bb8
  ^bb2:  // pred: ^bb1
    %7 = vector.transfer_read %4[%5, %c0], %cst {in_bounds = [true]} : tensor<10x10xf64>, vector<10xf64>
    vector.print punctuation <open>
    cf.br ^bb3(%c0 : index)
  ^bb3(%8: index):  // 2 preds: ^bb2, ^bb6
    %9 = arith.cmpi slt, %8, %c10 : index
    cf.cond_br %9, ^bb4, ^bb7
  ^bb4:  // pred: ^bb3
    %10 = vector.extractelement %7[%8 : index] : vector<10xf64>
    vector.print %10 : f64 punctuation <no_punctuation>
    %11 = arith.cmpi ult, %8, %c9 : index
    cf.cond_br %11, ^bb5, ^bb6
  ^bb5:  // pred: ^bb4
    vector.print punctuation <comma>
    cf.br ^bb6
  ^bb6:  // 2 preds: ^bb4, ^bb5
    %12 = arith.addi %8, %c1 : index
    cf.br ^bb3(%12 : index)
  ^bb7:  // pred: ^bb3
    vector.print punctuation <close>
    vector.print
    %13 = arith.addi %5, %c1 : index
    cf.br ^bb1(%13 : index)
  ^bb8:  // pred: ^bb1
    %extracted = tensor.extract %4[%c8, %c8] : tensor<10x10xf64>
    %14 = arith.fptosi %extracted : f64 to i64
    return %14 : i64
  }
  func.func @assemble_sparse() -> (memref<?xindex>, memref<?xindex>, memref<?xf64>, !llvm.struct<(array<2 x i64>, array<3 x i64>)>) {
    %c11_i64 = arith.constant 11 : i64
    %c10_i64 = arith.constant 10 : i64
    %c0_i64 = arith.constant 0 : i64
    %0 = llvm.mlir.poison : !llvm.struct<(array<2 x i64>, array<3 x i64>)>
    %c10 = arith.constant 10 : index
    %1 = memref.get_global @__constant_30xf64 : memref<30xf64>
    %2 = memref.get_global @__constant_11xindex : memref<11xindex>
    %3 = memref.get_global @__constant_30xindex : memref<30xindex>
    %cast = memref.cast %2 : memref<11xindex> to memref<?xindex>
    %cast_0 = memref.cast %3 : memref<30xindex> to memref<?xindex>
    %cast_1 = memref.cast %1 : memref<30xf64> to memref<?xf64>
    %4 = llvm.insertvalue %c0_i64, %0[1, 0] : !llvm.struct<(array<2 x i64>, array<3 x i64>)> 
    %5 = llvm.insertvalue %c0_i64, %4[1, 1] : !llvm.struct<(array<2 x i64>, array<3 x i64>)> 
    %6 = llvm.insertvalue %c0_i64, %5[1, 2] : !llvm.struct<(array<2 x i64>, array<3 x i64>)> 
    %7 = llvm.insertvalue %c10_i64, %6[0, 0] : !llvm.struct<(array<2 x i64>, array<3 x i64>)> 
    %8 = llvm.insertvalue %c10_i64, %7[0, 1] : !llvm.struct<(array<2 x i64>, array<3 x i64>)> 
    %9 = llvm.insertvalue %c11_i64, %8[1, 0] : !llvm.struct<(array<2 x i64>, array<3 x i64>)> 
    %10 = memref.load %2[%c10] : memref<11xindex>
    %11 = arith.index_cast %10 : index to i64
    %12 = llvm.insertvalue %11, %9[1, 1] : !llvm.struct<(array<2 x i64>, array<3 x i64>)> 
    %13 = arith.index_cast %10 : index to i64
    %14 = llvm.insertvalue %13, %12[1, 2] : !llvm.struct<(array<2 x i64>, array<3 x i64>)> 
    return %cast, %cast_0, %cast_1, %14 : memref<?xindex>, memref<?xindex>, memref<?xf64>, !llvm.struct<(array<2 x i64>, array<3 x i64>)>
  }
}


// -----// IR Dump After LowerAffinePass (lower-affine) //----- //
module {
  memref.global "private" constant @__constant_30xindex : memref<30xindex> = dense<[8, 3, 4, 6, 9, 2, 4, 0, 1, 2, 3, 5, 7, 8, 3, 6, 2, 3, 4, 5, 8, 1, 5, 7, 8, 5, 9, 4, 7, 7]> {alignment = 64 : i64}
  memref.global "private" constant @__constant_11xindex : memref<11xindex> = dense<[0, 1, 5, 7, 14, 16, 21, 25, 27, 29, 30]> {alignment = 64 : i64}
  memref.global "private" constant @__constant_30xf64 : memref<30xf64> = dense<[4.7563469999999999, 2.102859, 5.4238689999999998, 5.577680e+00, 3.001240e-01, 4.8357549999999998, 8.8596050000000002, 1.592490e+00, 7.372070e+00, 7.2462879999999998, 5.9191609999999999, 5.9593920000000002, 4.6956530000000001, 6.328630e-01, 3.1591619999999998, 4.7083050000000002, 8.4356449999999992, 5.4309390000000004, 2.1190630000000001, 1.545420e-01, 2.595040e+00, 1.4655819999999999, 1.321259, 3.702925, 3.542246, 6.831162, 1.723510e+00, 7.8729019999999998, 6.0081550000000004, 1.047045]> {alignment = 64 : i64}
  memref.global "private" constant @__constant_10x10xf64 : memref<10x10xf64> = dense<[[5.0072820879405331, 2.1420497309468542, 8.4364357946217474, 3.3512684114489364, 4.8578737173077684, 6.5026873298607608, 4.481183080848961, 1.6018142840321781, 1.6482067031075565, 2.7697353449463433], [8.2796435610104453, 9.7956308688691446, 5.066309369035312, 1.0691978274975567, 7.2754747197326219, 7.4679216752662611, 1.8460472498040226, 1.7245060332115747, 9.828847678500983, 5.8523888503628294], [4.735129046344202, 0.21389279999051047, 9.9823910553584571, 0.22751442405574696, 4.3063298537464378, 1.0300462704374436, 7.1885192597496097, 1.7297134743393461, 7.4494154821665912, 8.2180913094628564], [0.55370097211729696, 7.0871105126860554, 7.7450498540614178, 4.2448327660994876, 1.2746000519648371, 9.4391729894286023, 6.1902689198805465, 6.0312877871821424, 8.7890699247898425, 3.1611885774377635], [8.9903796016343396, 3.4471256572948263, 8.4932841564173884, 9.9373309006088171, 2.6191045587156303, 0.77351004199567641, 1.4024547359632467, 7.454551829233095, 2.6194195569905077, 4.0298520046877577], [4.7641019675563543, 3.8129279818642861, 9.0747728919768225, 6.4920816381757511, 6.7882405668469881, 7.0063465072165911, 5.7386637585592792, 7.5230234961300599, 0.91592641387099771, 8.6646639602141899], [5.6862365678538973, 4.8755032417073192, 9.5859588536709328, 8.1186668576209513, 5.3811119011589454, 3.8280043169558411, 9.9983397606134918, 6.1835824149566241, 3.4201107815517515, 0.84968218962971687], [2.791270331453247, 2.9735813587818685, 3.0654358664150494, 5.4929582569491755, 3.9238922832952996, 9.2657934977933269, 5.0681592194030571, 9.6910348814034712, 2.0972430846802959, 0.96789458347651514], [3.1989914495545624, 3.7607248895716507, 5.5182323136835318, 2.4724154287944913, 7.2920674615977124, 9.7009225179758473, 9.9421519655410044, 2.6109645810252315, 9.0484630420475316, 3.6771724535825703], [6.305746358135309, 7.6948754823713771, 3.6012681436537397, 1.263350310992416, 3.8581878444772943, 7.1047027925517909, 2.1904752468927735, 0.32914734762647391, 3.1668377278172235, 2.0518472657841924]]> {alignment = 64 : i64}
  func.func @matmul(%arg0: memref<?xindex>, %arg1: memref<?xindex>, %arg2: memref<?xf64>, %arg3: !llvm.struct<(array<2 x i64>, array<3 x i64>)>, %arg4: tensor<10x10xf64>, %arg5: tensor<10x10xf64>) -> tensor<10x10xf64> {
    %cst = arith.constant dense<0.000000e+00> : vector<4xf64>
    %c4 = arith.constant 4 : index
    %c1 = arith.constant 1 : index
    %c0 = arith.constant 0 : index
    %c10 = arith.constant 10 : index
    %0 = llvm.extractvalue %arg3[1, 2] : !llvm.struct<(array<2 x i64>, array<3 x i64>)> 
    %1 = arith.index_cast %0 : i64 to index
    %base_buffer, %offset, %sizes, %strides = memref.extract_strided_metadata %arg2 : memref<?xf64> -> memref<f64>, index, index, index
    %reinterpret_cast = memref.reinterpret_cast %base_buffer to offset: [0], sizes: [%1], strides: [1] : memref<f64> to memref<?xf64>
    %2 = bufferization.to_memref %arg4 : tensor<10x10xf64> to memref<10x10xf64>
    %3 = bufferization.to_memref %arg5 : tensor<10x10xf64> to memref<10x10xf64>
    %4 = llvm.extractvalue %arg3[1, 0] : !llvm.struct<(array<2 x i64>, array<3 x i64>)> 
    %5 = arith.index_cast %4 : i64 to index
    %base_buffer_0, %offset_1, %sizes_2, %strides_3 = memref.extract_strided_metadata %arg0 : memref<?xindex> -> memref<index>, index, index, index
    %reinterpret_cast_4 = memref.reinterpret_cast %base_buffer_0 to offset: [0], sizes: [%5], strides: [1] : memref<index> to memref<?xindex>
    %6 = llvm.extractvalue %arg3[1, 1] : !llvm.struct<(array<2 x i64>, array<3 x i64>)> 
    %7 = arith.index_cast %6 : i64 to index
    %base_buffer_5, %offset_6, %sizes_7, %strides_8 = memref.extract_strided_metadata %arg1 : memref<?xindex> -> memref<index>, index, index, index
    %reinterpret_cast_9 = memref.reinterpret_cast %base_buffer_5 to offset: [0], sizes: [%7], strides: [1] : memref<index> to memref<?xindex>
    cf.br ^bb1(%c0 : index)
  ^bb1(%8: index):  // 2 preds: ^bb0, ^bb8
    %9 = arith.cmpi slt, %8, %c10 : index
    cf.cond_br %9, ^bb2, ^bb9
  ^bb2:  // pred: ^bb1
    %10 = memref.load %reinterpret_cast_4[%8] : memref<?xindex>
    %11 = arith.addi %8, %c1 : index
    %12 = memref.load %reinterpret_cast_4[%11] : memref<?xindex>
    cf.br ^bb3(%10 : index)
  ^bb3(%13: index):  // 2 preds: ^bb2, ^bb7
    %14 = arith.cmpi slt, %13, %12 : index
    cf.cond_br %14, ^bb4, ^bb8
  ^bb4:  // pred: ^bb3
    %15 = memref.load %reinterpret_cast_9[%13] : memref<?xindex>
    %16 = memref.load %reinterpret_cast[%13] : memref<?xf64>
    cf.br ^bb5(%c0 : index)
  ^bb5(%17: index):  // 2 preds: ^bb4, ^bb6
    %18 = arith.cmpi slt, %17, %c10 : index
    cf.cond_br %18, ^bb6, ^bb7
  ^bb6:  // pred: ^bb5
    %c-1 = arith.constant -1 : index
    %19 = arith.muli %17, %c-1 overflow<nsw> : index
    %c10_10 = arith.constant 10 : index
    %20 = arith.addi %19, %c10_10 : index
    %c4_11 = arith.constant 4 : index
    %21 = arith.minsi %20, %c4_11 : index
    %22 = vector.create_mask %21 : vector<4xi1>
    %23 = vector.maskedload %3[%8, %17], %22, %cst : memref<10x10xf64>, vector<4xi1>, vector<4xf64> into vector<4xf64>
    %24 = vector.broadcast %16 : f64 to vector<4xf64>
    %25 = vector.maskedload %2[%15, %17], %22, %cst : memref<10x10xf64>, vector<4xi1>, vector<4xf64> into vector<4xf64>
    %26 = arith.mulf %24, %25 : vector<4xf64>
    %27 = arith.addf %23, %26 : vector<4xf64>
    vector.maskedstore %3[%8, %17], %22, %27 : memref<10x10xf64>, vector<4xi1>, vector<4xf64>
    %28 = arith.addi %17, %c4 : index
    cf.br ^bb5(%28 : index)
  ^bb7:  // pred: ^bb5
    %29 = arith.addi %13, %c1 : index
    cf.br ^bb3(%29 : index)
  ^bb8:  // pred: ^bb3
    %30 = arith.addi %8, %c1 : index
    cf.br ^bb1(%30 : index)
  ^bb9:  // pred: ^bb1
    %31 = bufferization.to_tensor %3 : memref<10x10xf64> to tensor<10x10xf64>
    return %31 : tensor<10x10xf64>
  }
  func.func @main() -> i64 {
    %c9 = arith.constant 9 : index
    %c8 = arith.constant 8 : index
    %cst = arith.constant 0.000000e+00 : f64
    %c1 = arith.constant 1 : index
    %c10 = arith.constant 10 : index
    %c0 = arith.constant 0 : index
    %0 = memref.get_global @__constant_10x10xf64 : memref<10x10xf64>
    %1 = bufferization.to_tensor %0 : memref<10x10xf64> to tensor<10x10xf64>
    %2 = bufferization.alloc_tensor() : tensor<10x10xf64>
    %3:4 = call @assemble_sparse() : () -> (memref<?xindex>, memref<?xindex>, memref<?xf64>, !llvm.struct<(array<2 x i64>, array<3 x i64>)>)
    %4 = call @matmul(%3#0, %3#1, %3#2, %3#3, %1, %2) : (memref<?xindex>, memref<?xindex>, memref<?xf64>, !llvm.struct<(array<2 x i64>, array<3 x i64>)>, tensor<10x10xf64>, tensor<10x10xf64>) -> tensor<10x10xf64>
    cf.br ^bb1(%c0 : index)
  ^bb1(%5: index):  // 2 preds: ^bb0, ^bb7
    %6 = arith.cmpi slt, %5, %c10 : index
    cf.cond_br %6, ^bb2, ^bb8
  ^bb2:  // pred: ^bb1
    %7 = vector.transfer_read %4[%5, %c0], %cst {in_bounds = [true]} : tensor<10x10xf64>, vector<10xf64>
    vector.print punctuation <open>
    cf.br ^bb3(%c0 : index)
  ^bb3(%8: index):  // 2 preds: ^bb2, ^bb6
    %9 = arith.cmpi slt, %8, %c10 : index
    cf.cond_br %9, ^bb4, ^bb7
  ^bb4:  // pred: ^bb3
    %10 = vector.extractelement %7[%8 : index] : vector<10xf64>
    vector.print %10 : f64 punctuation <no_punctuation>
    %11 = arith.cmpi ult, %8, %c9 : index
    cf.cond_br %11, ^bb5, ^bb6
  ^bb5:  // pred: ^bb4
    vector.print punctuation <comma>
    cf.br ^bb6
  ^bb6:  // 2 preds: ^bb4, ^bb5
    %12 = arith.addi %8, %c1 : index
    cf.br ^bb3(%12 : index)
  ^bb7:  // pred: ^bb3
    vector.print punctuation <close>
    vector.print
    %13 = arith.addi %5, %c1 : index
    cf.br ^bb1(%13 : index)
  ^bb8:  // pred: ^bb1
    %extracted = tensor.extract %4[%c8, %c8] : tensor<10x10xf64>
    %14 = arith.fptosi %extracted : f64 to i64
    return %14 : i64
  }
  func.func @assemble_sparse() -> (memref<?xindex>, memref<?xindex>, memref<?xf64>, !llvm.struct<(array<2 x i64>, array<3 x i64>)>) {
    %c11_i64 = arith.constant 11 : i64
    %c10_i64 = arith.constant 10 : i64
    %c0_i64 = arith.constant 0 : i64
    %0 = llvm.mlir.poison : !llvm.struct<(array<2 x i64>, array<3 x i64>)>
    %c10 = arith.constant 10 : index
    %1 = memref.get_global @__constant_30xf64 : memref<30xf64>
    %2 = memref.get_global @__constant_11xindex : memref<11xindex>
    %3 = memref.get_global @__constant_30xindex : memref<30xindex>
    %cast = memref.cast %2 : memref<11xindex> to memref<?xindex>
    %cast_0 = memref.cast %3 : memref<30xindex> to memref<?xindex>
    %cast_1 = memref.cast %1 : memref<30xf64> to memref<?xf64>
    %4 = llvm.insertvalue %c0_i64, %0[1, 0] : !llvm.struct<(array<2 x i64>, array<3 x i64>)> 
    %5 = llvm.insertvalue %c0_i64, %4[1, 1] : !llvm.struct<(array<2 x i64>, array<3 x i64>)> 
    %6 = llvm.insertvalue %c0_i64, %5[1, 2] : !llvm.struct<(array<2 x i64>, array<3 x i64>)> 
    %7 = llvm.insertvalue %c10_i64, %6[0, 0] : !llvm.struct<(array<2 x i64>, array<3 x i64>)> 
    %8 = llvm.insertvalue %c10_i64, %7[0, 1] : !llvm.struct<(array<2 x i64>, array<3 x i64>)> 
    %9 = llvm.insertvalue %c11_i64, %8[1, 0] : !llvm.struct<(array<2 x i64>, array<3 x i64>)> 
    %10 = memref.load %2[%c10] : memref<11xindex>
    %11 = arith.index_cast %10 : index to i64
    %12 = llvm.insertvalue %11, %9[1, 1] : !llvm.struct<(array<2 x i64>, array<3 x i64>)> 
    %13 = arith.index_cast %10 : index to i64
    %14 = llvm.insertvalue %13, %12[1, 2] : !llvm.struct<(array<2 x i64>, array<3 x i64>)> 
    return %cast, %cast_0, %cast_1, %14 : memref<?xindex>, memref<?xindex>, memref<?xf64>, !llvm.struct<(array<2 x i64>, array<3 x i64>)>
  }
}


// -----// IR Dump After ConvertVectorToLLVMPass (convert-vector-to-llvm) //----- //
module {
  llvm.func @printNewline()
  llvm.func @printClose()
  llvm.func @printComma()
  llvm.func @printF64(f64)
  llvm.func @printOpen()
  memref.global "private" constant @__constant_30xindex : memref<30xindex> = dense<[8, 3, 4, 6, 9, 2, 4, 0, 1, 2, 3, 5, 7, 8, 3, 6, 2, 3, 4, 5, 8, 1, 5, 7, 8, 5, 9, 4, 7, 7]> {alignment = 64 : i64}
  memref.global "private" constant @__constant_11xindex : memref<11xindex> = dense<[0, 1, 5, 7, 14, 16, 21, 25, 27, 29, 30]> {alignment = 64 : i64}
  memref.global "private" constant @__constant_30xf64 : memref<30xf64> = dense<[4.7563469999999999, 2.102859, 5.4238689999999998, 5.577680e+00, 3.001240e-01, 4.8357549999999998, 8.8596050000000002, 1.592490e+00, 7.372070e+00, 7.2462879999999998, 5.9191609999999999, 5.9593920000000002, 4.6956530000000001, 6.328630e-01, 3.1591619999999998, 4.7083050000000002, 8.4356449999999992, 5.4309390000000004, 2.1190630000000001, 1.545420e-01, 2.595040e+00, 1.4655819999999999, 1.321259, 3.702925, 3.542246, 6.831162, 1.723510e+00, 7.8729019999999998, 6.0081550000000004, 1.047045]> {alignment = 64 : i64}
  memref.global "private" constant @__constant_10x10xf64 : memref<10x10xf64> = dense<[[5.0072820879405331, 2.1420497309468542, 8.4364357946217474, 3.3512684114489364, 4.8578737173077684, 6.5026873298607608, 4.481183080848961, 1.6018142840321781, 1.6482067031075565, 2.7697353449463433], [8.2796435610104453, 9.7956308688691446, 5.066309369035312, 1.0691978274975567, 7.2754747197326219, 7.4679216752662611, 1.8460472498040226, 1.7245060332115747, 9.828847678500983, 5.8523888503628294], [4.735129046344202, 0.21389279999051047, 9.9823910553584571, 0.22751442405574696, 4.3063298537464378, 1.0300462704374436, 7.1885192597496097, 1.7297134743393461, 7.4494154821665912, 8.2180913094628564], [0.55370097211729696, 7.0871105126860554, 7.7450498540614178, 4.2448327660994876, 1.2746000519648371, 9.4391729894286023, 6.1902689198805465, 6.0312877871821424, 8.7890699247898425, 3.1611885774377635], [8.9903796016343396, 3.4471256572948263, 8.4932841564173884, 9.9373309006088171, 2.6191045587156303, 0.77351004199567641, 1.4024547359632467, 7.454551829233095, 2.6194195569905077, 4.0298520046877577], [4.7641019675563543, 3.8129279818642861, 9.0747728919768225, 6.4920816381757511, 6.7882405668469881, 7.0063465072165911, 5.7386637585592792, 7.5230234961300599, 0.91592641387099771, 8.6646639602141899], [5.6862365678538973, 4.8755032417073192, 9.5859588536709328, 8.1186668576209513, 5.3811119011589454, 3.8280043169558411, 9.9983397606134918, 6.1835824149566241, 3.4201107815517515, 0.84968218962971687], [2.791270331453247, 2.9735813587818685, 3.0654358664150494, 5.4929582569491755, 3.9238922832952996, 9.2657934977933269, 5.0681592194030571, 9.6910348814034712, 2.0972430846802959, 0.96789458347651514], [3.1989914495545624, 3.7607248895716507, 5.5182323136835318, 2.4724154287944913, 7.2920674615977124, 9.7009225179758473, 9.9421519655410044, 2.6109645810252315, 9.0484630420475316, 3.6771724535825703], [6.305746358135309, 7.6948754823713771, 3.6012681436537397, 1.263350310992416, 3.8581878444772943, 7.1047027925517909, 2.1904752468927735, 0.32914734762647391, 3.1668377278172235, 2.0518472657841924]]> {alignment = 64 : i64}
  func.func @matmul(%arg0: memref<?xindex>, %arg1: memref<?xindex>, %arg2: memref<?xf64>, %arg3: !llvm.struct<(array<2 x i64>, array<3 x i64>)>, %arg4: tensor<10x10xf64>, %arg5: tensor<10x10xf64>) -> tensor<10x10xf64> {
    %cst = arith.constant dense<[0, 1, 2, 3]> : vector<4xi32>
    %c-1 = arith.constant -1 : index
    %cst_0 = arith.constant dense<0.000000e+00> : vector<4xf64>
    %c4 = arith.constant 4 : index
    %c1 = arith.constant 1 : index
    %c0 = arith.constant 0 : index
    %c10 = arith.constant 10 : index
    %0 = llvm.extractvalue %arg3[1, 2] : !llvm.struct<(array<2 x i64>, array<3 x i64>)> 
    %1 = arith.index_cast %0 : i64 to index
    %base_buffer, %offset, %sizes, %strides = memref.extract_strided_metadata %arg2 : memref<?xf64> -> memref<f64>, index, index, index
    %reinterpret_cast = memref.reinterpret_cast %base_buffer to offset: [0], sizes: [%1], strides: [1] : memref<f64> to memref<?xf64>
    %2 = bufferization.to_memref %arg4 : tensor<10x10xf64> to memref<10x10xf64>
    %3 = builtin.unrealized_conversion_cast %2 : memref<10x10xf64> to !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)>
    %4 = bufferization.to_memref %arg5 : tensor<10x10xf64> to memref<10x10xf64>
    %5 = builtin.unrealized_conversion_cast %4 : memref<10x10xf64> to !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)>
    %6 = llvm.extractvalue %arg3[1, 0] : !llvm.struct<(array<2 x i64>, array<3 x i64>)> 
    %7 = arith.index_cast %6 : i64 to index
    %base_buffer_1, %offset_2, %sizes_3, %strides_4 = memref.extract_strided_metadata %arg0 : memref<?xindex> -> memref<index>, index, index, index
    %reinterpret_cast_5 = memref.reinterpret_cast %base_buffer_1 to offset: [0], sizes: [%7], strides: [1] : memref<index> to memref<?xindex>
    %8 = llvm.extractvalue %arg3[1, 1] : !llvm.struct<(array<2 x i64>, array<3 x i64>)> 
    %9 = arith.index_cast %8 : i64 to index
    %base_buffer_6, %offset_7, %sizes_8, %strides_9 = memref.extract_strided_metadata %arg1 : memref<?xindex> -> memref<index>, index, index, index
    %reinterpret_cast_10 = memref.reinterpret_cast %base_buffer_6 to offset: [0], sizes: [%9], strides: [1] : memref<index> to memref<?xindex>
    cf.br ^bb1(%c0 : index)
  ^bb1(%10: index):  // 2 preds: ^bb0, ^bb8
    %11 = builtin.unrealized_conversion_cast %10 : index to i64
    %12 = arith.cmpi slt, %10, %c10 : index
    cf.cond_br %12, ^bb2, ^bb9
  ^bb2:  // pred: ^bb1
    %13 = memref.load %reinterpret_cast_5[%10] : memref<?xindex>
    %14 = arith.addi %10, %c1 : index
    %15 = memref.load %reinterpret_cast_5[%14] : memref<?xindex>
    cf.br ^bb3(%13 : index)
  ^bb3(%16: index):  // 2 preds: ^bb2, ^bb7
    %17 = arith.cmpi slt, %16, %15 : index
    cf.cond_br %17, ^bb4, ^bb8
  ^bb4:  // pred: ^bb3
    %18 = memref.load %reinterpret_cast_10[%16] : memref<?xindex>
    %19 = builtin.unrealized_conversion_cast %18 : index to i64
    %20 = memref.load %reinterpret_cast[%16] : memref<?xf64>
    cf.br ^bb5(%c0 : index)
  ^bb5(%21: index):  // 2 preds: ^bb4, ^bb6
    %22 = builtin.unrealized_conversion_cast %21 : index to i64
    %23 = arith.cmpi slt, %21, %c10 : index
    cf.cond_br %23, ^bb6, ^bb7
  ^bb6:  // pred: ^bb5
    %24 = arith.muli %21, %c-1 overflow<nsw> : index
    %25 = arith.addi %24, %c10 : index
    %26 = arith.minsi %25, %c4 : index
    %27 = arith.index_cast %26 : index to i32
    %28 = llvm.mlir.poison : vector<4xi32>
    %29 = llvm.mlir.constant(0 : i32) : i32
    %30 = llvm.insertelement %27, %28[%29 : i32] : vector<4xi32>
    %31 = llvm.shufflevector %30, %28 [0, 0, 0, 0] : vector<4xi32> 
    %32 = arith.cmpi sgt, %31, %cst : vector<4xi32>
    %33 = llvm.extractvalue %5[1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %34 = llvm.mlir.constant(10 : index) : i64
    %35 = llvm.mul %11, %34 : i64
    %36 = llvm.add %35, %22 : i64
    %37 = llvm.getelementptr %33[%36] : (!llvm.ptr, i64) -> !llvm.ptr, f64
    %38 = llvm.intr.masked.load %37, %32, %cst_0 {alignment = 8 : i32} : (!llvm.ptr, vector<4xi1>, vector<4xf64>) -> vector<4xf64>
    %39 = llvm.mlir.poison : vector<4xf64>
    %40 = llvm.mlir.constant(0 : i32) : i32
    %41 = llvm.insertelement %20, %39[%40 : i32] : vector<4xf64>
    %42 = llvm.shufflevector %41, %39 [0, 0, 0, 0] : vector<4xf64> 
    %43 = llvm.extractvalue %3[1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %44 = llvm.mlir.constant(10 : index) : i64
    %45 = llvm.mul %19, %44 : i64
    %46 = llvm.add %45, %22 : i64
    %47 = llvm.getelementptr %43[%46] : (!llvm.ptr, i64) -> !llvm.ptr, f64
    %48 = llvm.intr.masked.load %47, %32, %cst_0 {alignment = 8 : i32} : (!llvm.ptr, vector<4xi1>, vector<4xf64>) -> vector<4xf64>
    %49 = arith.mulf %42, %48 : vector<4xf64>
    %50 = arith.addf %38, %49 : vector<4xf64>
    %51 = llvm.extractvalue %5[1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %52 = llvm.mlir.constant(10 : index) : i64
    %53 = llvm.mul %11, %52 : i64
    %54 = llvm.add %53, %22 : i64
    %55 = llvm.getelementptr %51[%54] : (!llvm.ptr, i64) -> !llvm.ptr, f64
    llvm.intr.masked.store %50, %55, %32 {alignment = 8 : i32} : vector<4xf64>, vector<4xi1> into !llvm.ptr
    %56 = arith.addi %21, %c4 : index
    cf.br ^bb5(%56 : index)
  ^bb7:  // pred: ^bb5
    %57 = arith.addi %16, %c1 : index
    cf.br ^bb3(%57 : index)
  ^bb8:  // pred: ^bb3
    %58 = arith.addi %10, %c1 : index
    cf.br ^bb1(%58 : index)
  ^bb9:  // pred: ^bb1
    %59 = bufferization.to_tensor %4 : memref<10x10xf64> to tensor<10x10xf64>
    return %59 : tensor<10x10xf64>
  }
  func.func @main() -> i64 {
    %c9 = arith.constant 9 : index
    %c8 = arith.constant 8 : index
    %cst = arith.constant 0.000000e+00 : f64
    %c1 = arith.constant 1 : index
    %c10 = arith.constant 10 : index
    %c0 = arith.constant 0 : index
    %0 = memref.get_global @__constant_10x10xf64 : memref<10x10xf64>
    %1 = bufferization.to_tensor %0 : memref<10x10xf64> to tensor<10x10xf64>
    %2 = bufferization.alloc_tensor() : tensor<10x10xf64>
    %3:4 = call @assemble_sparse() : () -> (memref<?xindex>, memref<?xindex>, memref<?xf64>, !llvm.struct<(array<2 x i64>, array<3 x i64>)>)
    %4 = call @matmul(%3#0, %3#1, %3#2, %3#3, %1, %2) : (memref<?xindex>, memref<?xindex>, memref<?xf64>, !llvm.struct<(array<2 x i64>, array<3 x i64>)>, tensor<10x10xf64>, tensor<10x10xf64>) -> tensor<10x10xf64>
    cf.br ^bb1(%c0 : index)
  ^bb1(%5: index):  // 2 preds: ^bb0, ^bb7
    %6 = arith.cmpi slt, %5, %c10 : index
    cf.cond_br %6, ^bb2, ^bb8
  ^bb2:  // pred: ^bb1
    %7 = vector.transfer_read %4[%5, %c0], %cst {in_bounds = [true]} : tensor<10x10xf64>, vector<10xf64>
    llvm.call @printOpen() : () -> ()
    cf.br ^bb3(%c0 : index)
  ^bb3(%8: index):  // 2 preds: ^bb2, ^bb6
    %9 = builtin.unrealized_conversion_cast %8 : index to i64
    %10 = arith.cmpi slt, %8, %c10 : index
    cf.cond_br %10, ^bb4, ^bb7
  ^bb4:  // pred: ^bb3
    %11 = llvm.extractelement %7[%9 : i64] : vector<10xf64>
    llvm.call @printF64(%11) : (f64) -> ()
    %12 = arith.cmpi ult, %8, %c9 : index
    cf.cond_br %12, ^bb5, ^bb6
  ^bb5:  // pred: ^bb4
    llvm.call @printComma() : () -> ()
    cf.br ^bb6
  ^bb6:  // 2 preds: ^bb4, ^bb5
    %13 = arith.addi %8, %c1 : index
    cf.br ^bb3(%13 : index)
  ^bb7:  // pred: ^bb3
    llvm.call @printClose() : () -> ()
    llvm.call @printNewline() : () -> ()
    %14 = arith.addi %5, %c1 : index
    cf.br ^bb1(%14 : index)
  ^bb8:  // pred: ^bb1
    %extracted = tensor.extract %4[%c8, %c8] : tensor<10x10xf64>
    %15 = arith.fptosi %extracted : f64 to i64
    return %15 : i64
  }
  func.func @assemble_sparse() -> (memref<?xindex>, memref<?xindex>, memref<?xf64>, !llvm.struct<(array<2 x i64>, array<3 x i64>)>) {
    %c11_i64 = arith.constant 11 : i64
    %c10_i64 = arith.constant 10 : i64
    %c0_i64 = arith.constant 0 : i64
    %0 = llvm.mlir.poison : !llvm.struct<(array<2 x i64>, array<3 x i64>)>
    %c10 = arith.constant 10 : index
    %1 = memref.get_global @__constant_30xf64 : memref<30xf64>
    %2 = memref.get_global @__constant_11xindex : memref<11xindex>
    %3 = memref.get_global @__constant_30xindex : memref<30xindex>
    %cast = memref.cast %2 : memref<11xindex> to memref<?xindex>
    %cast_0 = memref.cast %3 : memref<30xindex> to memref<?xindex>
    %cast_1 = memref.cast %1 : memref<30xf64> to memref<?xf64>
    %4 = llvm.insertvalue %c0_i64, %0[1, 0] : !llvm.struct<(array<2 x i64>, array<3 x i64>)> 
    %5 = llvm.insertvalue %c0_i64, %4[1, 1] : !llvm.struct<(array<2 x i64>, array<3 x i64>)> 
    %6 = llvm.insertvalue %c0_i64, %5[1, 2] : !llvm.struct<(array<2 x i64>, array<3 x i64>)> 
    %7 = llvm.insertvalue %c10_i64, %6[0, 0] : !llvm.struct<(array<2 x i64>, array<3 x i64>)> 
    %8 = llvm.insertvalue %c10_i64, %7[0, 1] : !llvm.struct<(array<2 x i64>, array<3 x i64>)> 
    %9 = llvm.insertvalue %c11_i64, %8[1, 0] : !llvm.struct<(array<2 x i64>, array<3 x i64>)> 
    %10 = memref.load %2[%c10] : memref<11xindex>
    %11 = arith.index_cast %10 : index to i64
    %12 = llvm.insertvalue %11, %9[1, 1] : !llvm.struct<(array<2 x i64>, array<3 x i64>)> 
    %13 = arith.index_cast %10 : index to i64
    %14 = llvm.insertvalue %13, %12[1, 2] : !llvm.struct<(array<2 x i64>, array<3 x i64>)> 
    return %cast, %cast_0, %cast_1, %14 : memref<?xindex>, memref<?xindex>, memref<?xf64>, !llvm.struct<(array<2 x i64>, array<3 x i64>)>
  }
}


// -----// IR Dump After FinalizeMemRefToLLVMConversionPass (finalize-memref-to-llvm) //----- //
module {
  llvm.func @printNewline()
  llvm.func @printClose()
  llvm.func @printComma()
  llvm.func @printF64(f64)
  llvm.func @printOpen()
  llvm.mlir.global private constant @__constant_30xindex(dense<[8, 3, 4, 6, 9, 2, 4, 0, 1, 2, 3, 5, 7, 8, 3, 6, 2, 3, 4, 5, 8, 1, 5, 7, 8, 5, 9, 4, 7, 7]> : tensor<30xindex>) {addr_space = 0 : i32, alignment = 64 : i64} : !llvm.array<30 x i64>
  llvm.mlir.global private constant @__constant_11xindex(dense<[0, 1, 5, 7, 14, 16, 21, 25, 27, 29, 30]> : tensor<11xindex>) {addr_space = 0 : i32, alignment = 64 : i64} : !llvm.array<11 x i64>
  llvm.mlir.global private constant @__constant_30xf64(dense<[4.7563469999999999, 2.102859, 5.4238689999999998, 5.577680e+00, 3.001240e-01, 4.8357549999999998, 8.8596050000000002, 1.592490e+00, 7.372070e+00, 7.2462879999999998, 5.9191609999999999, 5.9593920000000002, 4.6956530000000001, 6.328630e-01, 3.1591619999999998, 4.7083050000000002, 8.4356449999999992, 5.4309390000000004, 2.1190630000000001, 1.545420e-01, 2.595040e+00, 1.4655819999999999, 1.321259, 3.702925, 3.542246, 6.831162, 1.723510e+00, 7.8729019999999998, 6.0081550000000004, 1.047045]> : tensor<30xf64>) {addr_space = 0 : i32, alignment = 64 : i64} : !llvm.array<30 x f64>
  llvm.mlir.global private constant @__constant_10x10xf64(dense<[[5.0072820879405331, 2.1420497309468542, 8.4364357946217474, 3.3512684114489364, 4.8578737173077684, 6.5026873298607608, 4.481183080848961, 1.6018142840321781, 1.6482067031075565, 2.7697353449463433], [8.2796435610104453, 9.7956308688691446, 5.066309369035312, 1.0691978274975567, 7.2754747197326219, 7.4679216752662611, 1.8460472498040226, 1.7245060332115747, 9.828847678500983, 5.8523888503628294], [4.735129046344202, 0.21389279999051047, 9.9823910553584571, 0.22751442405574696, 4.3063298537464378, 1.0300462704374436, 7.1885192597496097, 1.7297134743393461, 7.4494154821665912, 8.2180913094628564], [0.55370097211729696, 7.0871105126860554, 7.7450498540614178, 4.2448327660994876, 1.2746000519648371, 9.4391729894286023, 6.1902689198805465, 6.0312877871821424, 8.7890699247898425, 3.1611885774377635], [8.9903796016343396, 3.4471256572948263, 8.4932841564173884, 9.9373309006088171, 2.6191045587156303, 0.77351004199567641, 1.4024547359632467, 7.454551829233095, 2.6194195569905077, 4.0298520046877577], [4.7641019675563543, 3.8129279818642861, 9.0747728919768225, 6.4920816381757511, 6.7882405668469881, 7.0063465072165911, 5.7386637585592792, 7.5230234961300599, 0.91592641387099771, 8.6646639602141899], [5.6862365678538973, 4.8755032417073192, 9.5859588536709328, 8.1186668576209513, 5.3811119011589454, 3.8280043169558411, 9.9983397606134918, 6.1835824149566241, 3.4201107815517515, 0.84968218962971687], [2.791270331453247, 2.9735813587818685, 3.0654358664150494, 5.4929582569491755, 3.9238922832952996, 9.2657934977933269, 5.0681592194030571, 9.6910348814034712, 2.0972430846802959, 0.96789458347651514], [3.1989914495545624, 3.7607248895716507, 5.5182323136835318, 2.4724154287944913, 7.2920674615977124, 9.7009225179758473, 9.9421519655410044, 2.6109645810252315, 9.0484630420475316, 3.6771724535825703], [6.305746358135309, 7.6948754823713771, 3.6012681436537397, 1.263350310992416, 3.8581878444772943, 7.1047027925517909, 2.1904752468927735, 0.32914734762647391, 3.1668377278172235, 2.0518472657841924]]> : tensor<10x10xf64>) {addr_space = 0 : i32, alignment = 64 : i64} : !llvm.array<10 x array<10 x f64>>
  func.func @matmul(%arg0: memref<?xindex>, %arg1: memref<?xindex>, %arg2: memref<?xf64>, %arg3: !llvm.struct<(array<2 x i64>, array<3 x i64>)>, %arg4: tensor<10x10xf64>, %arg5: tensor<10x10xf64>) -> tensor<10x10xf64> {
    %0 = builtin.unrealized_conversion_cast %arg1 : memref<?xindex> to !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %1 = builtin.unrealized_conversion_cast %arg0 : memref<?xindex> to !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %2 = builtin.unrealized_conversion_cast %arg2 : memref<?xf64> to !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %cst = arith.constant dense<[0, 1, 2, 3]> : vector<4xi32>
    %c-1 = arith.constant -1 : index
    %cst_0 = arith.constant dense<0.000000e+00> : vector<4xf64>
    %c4 = arith.constant 4 : index
    %c1 = arith.constant 1 : index
    %c0 = arith.constant 0 : index
    %c10 = arith.constant 10 : index
    %3 = llvm.extractvalue %arg3[1, 2] : !llvm.struct<(array<2 x i64>, array<3 x i64>)> 
    %4 = arith.index_cast %3 : i64 to index
    %5 = builtin.unrealized_conversion_cast %4 : index to i64
    %6 = llvm.extractvalue %2[0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %7 = llvm.extractvalue %2[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %8 = llvm.mlir.poison : !llvm.struct<(ptr, ptr, i64)>
    %9 = llvm.insertvalue %6, %8[0] : !llvm.struct<(ptr, ptr, i64)> 
    %10 = llvm.insertvalue %7, %9[1] : !llvm.struct<(ptr, ptr, i64)> 
    %11 = llvm.mlir.constant(0 : index) : i64
    %12 = llvm.insertvalue %11, %10[2] : !llvm.struct<(ptr, ptr, i64)> 
    %13 = llvm.extractvalue %2[2] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %14 = llvm.extractvalue %2[3, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %15 = llvm.extractvalue %2[4, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %16 = llvm.mlir.poison : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %17 = llvm.extractvalue %12[0] : !llvm.struct<(ptr, ptr, i64)> 
    %18 = llvm.extractvalue %12[1] : !llvm.struct<(ptr, ptr, i64)> 
    %19 = llvm.insertvalue %17, %16[0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %20 = llvm.insertvalue %18, %19[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %21 = llvm.mlir.constant(0 : index) : i64
    %22 = llvm.insertvalue %21, %20[2] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %23 = llvm.insertvalue %5, %22[3, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %24 = llvm.mlir.constant(1 : index) : i64
    %25 = llvm.insertvalue %24, %23[4, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %26 = bufferization.to_memref %arg4 : tensor<10x10xf64> to memref<10x10xf64>
    %27 = builtin.unrealized_conversion_cast %26 : memref<10x10xf64> to !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)>
    %28 = bufferization.to_memref %arg5 : tensor<10x10xf64> to memref<10x10xf64>
    %29 = builtin.unrealized_conversion_cast %28 : memref<10x10xf64> to !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)>
    %30 = llvm.extractvalue %arg3[1, 0] : !llvm.struct<(array<2 x i64>, array<3 x i64>)> 
    %31 = arith.index_cast %30 : i64 to index
    %32 = builtin.unrealized_conversion_cast %31 : index to i64
    %33 = llvm.extractvalue %1[0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %34 = llvm.extractvalue %1[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %35 = llvm.mlir.poison : !llvm.struct<(ptr, ptr, i64)>
    %36 = llvm.insertvalue %33, %35[0] : !llvm.struct<(ptr, ptr, i64)> 
    %37 = llvm.insertvalue %34, %36[1] : !llvm.struct<(ptr, ptr, i64)> 
    %38 = llvm.mlir.constant(0 : index) : i64
    %39 = llvm.insertvalue %38, %37[2] : !llvm.struct<(ptr, ptr, i64)> 
    %40 = llvm.extractvalue %1[2] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %41 = llvm.extractvalue %1[3, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %42 = llvm.extractvalue %1[4, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %43 = llvm.mlir.poison : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %44 = llvm.extractvalue %39[0] : !llvm.struct<(ptr, ptr, i64)> 
    %45 = llvm.extractvalue %39[1] : !llvm.struct<(ptr, ptr, i64)> 
    %46 = llvm.insertvalue %44, %43[0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %47 = llvm.insertvalue %45, %46[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %48 = llvm.mlir.constant(0 : index) : i64
    %49 = llvm.insertvalue %48, %47[2] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %50 = llvm.insertvalue %32, %49[3, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %51 = llvm.mlir.constant(1 : index) : i64
    %52 = llvm.insertvalue %51, %50[4, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %53 = llvm.extractvalue %arg3[1, 1] : !llvm.struct<(array<2 x i64>, array<3 x i64>)> 
    %54 = arith.index_cast %53 : i64 to index
    %55 = builtin.unrealized_conversion_cast %54 : index to i64
    %56 = llvm.extractvalue %0[0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %57 = llvm.extractvalue %0[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %58 = llvm.mlir.poison : !llvm.struct<(ptr, ptr, i64)>
    %59 = llvm.insertvalue %56, %58[0] : !llvm.struct<(ptr, ptr, i64)> 
    %60 = llvm.insertvalue %57, %59[1] : !llvm.struct<(ptr, ptr, i64)> 
    %61 = llvm.mlir.constant(0 : index) : i64
    %62 = llvm.insertvalue %61, %60[2] : !llvm.struct<(ptr, ptr, i64)> 
    %63 = llvm.extractvalue %0[2] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %64 = llvm.extractvalue %0[3, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %65 = llvm.extractvalue %0[4, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %66 = llvm.mlir.poison : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %67 = llvm.extractvalue %62[0] : !llvm.struct<(ptr, ptr, i64)> 
    %68 = llvm.extractvalue %62[1] : !llvm.struct<(ptr, ptr, i64)> 
    %69 = llvm.insertvalue %67, %66[0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %70 = llvm.insertvalue %68, %69[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %71 = llvm.mlir.constant(0 : index) : i64
    %72 = llvm.insertvalue %71, %70[2] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %73 = llvm.insertvalue %55, %72[3, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %74 = llvm.mlir.constant(1 : index) : i64
    %75 = llvm.insertvalue %74, %73[4, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    cf.br ^bb1(%c0 : index)
  ^bb1(%76: index):  // 2 preds: ^bb0, ^bb8
    %77 = builtin.unrealized_conversion_cast %76 : index to i64
    %78 = builtin.unrealized_conversion_cast %76 : index to i64
    %79 = arith.cmpi slt, %76, %c10 : index
    cf.cond_br %79, ^bb2, ^bb9
  ^bb2:  // pred: ^bb1
    %80 = llvm.extractvalue %52[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %81 = llvm.getelementptr %80[%77] : (!llvm.ptr, i64) -> !llvm.ptr, i64
    %82 = llvm.load %81 : !llvm.ptr -> i64
    %83 = builtin.unrealized_conversion_cast %82 : i64 to index
    %84 = arith.addi %76, %c1 : index
    %85 = builtin.unrealized_conversion_cast %84 : index to i64
    %86 = llvm.extractvalue %52[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %87 = llvm.getelementptr %86[%85] : (!llvm.ptr, i64) -> !llvm.ptr, i64
    %88 = llvm.load %87 : !llvm.ptr -> i64
    %89 = builtin.unrealized_conversion_cast %88 : i64 to index
    cf.br ^bb3(%83 : index)
  ^bb3(%90: index):  // 2 preds: ^bb2, ^bb7
    %91 = builtin.unrealized_conversion_cast %90 : index to i64
    %92 = arith.cmpi slt, %90, %89 : index
    cf.cond_br %92, ^bb4, ^bb8
  ^bb4:  // pred: ^bb3
    %93 = llvm.extractvalue %75[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %94 = llvm.getelementptr %93[%91] : (!llvm.ptr, i64) -> !llvm.ptr, i64
    %95 = llvm.load %94 : !llvm.ptr -> i64
    %96 = builtin.unrealized_conversion_cast %95 : i64 to index
    %97 = builtin.unrealized_conversion_cast %96 : index to i64
    %98 = llvm.extractvalue %25[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %99 = llvm.getelementptr %98[%91] : (!llvm.ptr, i64) -> !llvm.ptr, f64
    %100 = llvm.load %99 : !llvm.ptr -> f64
    cf.br ^bb5(%c0 : index)
  ^bb5(%101: index):  // 2 preds: ^bb4, ^bb6
    %102 = builtin.unrealized_conversion_cast %101 : index to i64
    %103 = arith.cmpi slt, %101, %c10 : index
    cf.cond_br %103, ^bb6, ^bb7
  ^bb6:  // pred: ^bb5
    %104 = arith.muli %101, %c-1 overflow<nsw> : index
    %105 = arith.addi %104, %c10 : index
    %106 = arith.minsi %105, %c4 : index
    %107 = arith.index_cast %106 : index to i32
    %108 = llvm.mlir.poison : vector<4xi32>
    %109 = llvm.mlir.constant(0 : i32) : i32
    %110 = llvm.insertelement %107, %108[%109 : i32] : vector<4xi32>
    %111 = llvm.shufflevector %110, %108 [0, 0, 0, 0] : vector<4xi32> 
    %112 = arith.cmpi sgt, %111, %cst : vector<4xi32>
    %113 = llvm.extractvalue %29[1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %114 = llvm.mlir.constant(10 : index) : i64
    %115 = llvm.mul %78, %114 : i64
    %116 = llvm.add %115, %102 : i64
    %117 = llvm.getelementptr %113[%116] : (!llvm.ptr, i64) -> !llvm.ptr, f64
    %118 = llvm.intr.masked.load %117, %112, %cst_0 {alignment = 8 : i32} : (!llvm.ptr, vector<4xi1>, vector<4xf64>) -> vector<4xf64>
    %119 = llvm.mlir.poison : vector<4xf64>
    %120 = llvm.mlir.constant(0 : i32) : i32
    %121 = llvm.insertelement %100, %119[%120 : i32] : vector<4xf64>
    %122 = llvm.shufflevector %121, %119 [0, 0, 0, 0] : vector<4xf64> 
    %123 = llvm.extractvalue %27[1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %124 = llvm.mlir.constant(10 : index) : i64
    %125 = llvm.mul %97, %124 : i64
    %126 = llvm.add %125, %102 : i64
    %127 = llvm.getelementptr %123[%126] : (!llvm.ptr, i64) -> !llvm.ptr, f64
    %128 = llvm.intr.masked.load %127, %112, %cst_0 {alignment = 8 : i32} : (!llvm.ptr, vector<4xi1>, vector<4xf64>) -> vector<4xf64>
    %129 = arith.mulf %122, %128 : vector<4xf64>
    %130 = arith.addf %118, %129 : vector<4xf64>
    %131 = llvm.extractvalue %29[1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %132 = llvm.mlir.constant(10 : index) : i64
    %133 = llvm.mul %78, %132 : i64
    %134 = llvm.add %133, %102 : i64
    %135 = llvm.getelementptr %131[%134] : (!llvm.ptr, i64) -> !llvm.ptr, f64
    llvm.intr.masked.store %130, %135, %112 {alignment = 8 : i32} : vector<4xf64>, vector<4xi1> into !llvm.ptr
    %136 = arith.addi %101, %c4 : index
    cf.br ^bb5(%136 : index)
  ^bb7:  // pred: ^bb5
    %137 = arith.addi %90, %c1 : index
    cf.br ^bb3(%137 : index)
  ^bb8:  // pred: ^bb3
    %138 = arith.addi %76, %c1 : index
    cf.br ^bb1(%138 : index)
  ^bb9:  // pred: ^bb1
    %139 = bufferization.to_tensor %28 : memref<10x10xf64> to tensor<10x10xf64>
    return %139 : tensor<10x10xf64>
  }
  func.func @main() -> i64 {
    %c9 = arith.constant 9 : index
    %c8 = arith.constant 8 : index
    %cst = arith.constant 0.000000e+00 : f64
    %c1 = arith.constant 1 : index
    %c10 = arith.constant 10 : index
    %c0 = arith.constant 0 : index
    %0 = llvm.mlir.constant(10 : index) : i64
    %1 = llvm.mlir.constant(10 : index) : i64
    %2 = llvm.mlir.constant(1 : index) : i64
    %3 = llvm.mlir.constant(100 : index) : i64
    %4 = llvm.mlir.zero : !llvm.ptr
    %5 = llvm.getelementptr %4[%3] : (!llvm.ptr, i64) -> !llvm.ptr, f64
    %6 = llvm.ptrtoint %5 : !llvm.ptr to i64
    %7 = llvm.mlir.addressof @__constant_10x10xf64 : !llvm.ptr
    %8 = llvm.getelementptr %7[0, 0, 0] : (!llvm.ptr) -> !llvm.ptr, !llvm.array<10 x array<10 x f64>>
    %9 = llvm.mlir.constant(3735928559 : index) : i64
    %10 = llvm.inttoptr %9 : i64 to !llvm.ptr
    %11 = llvm.mlir.poison : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)>
    %12 = llvm.insertvalue %10, %11[0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %13 = llvm.insertvalue %8, %12[1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %14 = llvm.mlir.constant(0 : index) : i64
    %15 = llvm.insertvalue %14, %13[2] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %16 = llvm.insertvalue %0, %15[3, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %17 = llvm.insertvalue %1, %16[3, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %18 = llvm.insertvalue %1, %17[4, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %19 = llvm.insertvalue %2, %18[4, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %20 = builtin.unrealized_conversion_cast %19 : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> to memref<10x10xf64>
    %21 = bufferization.to_tensor %20 : memref<10x10xf64> to tensor<10x10xf64>
    %22 = bufferization.alloc_tensor() : tensor<10x10xf64>
    %23:4 = call @assemble_sparse() : () -> (memref<?xindex>, memref<?xindex>, memref<?xf64>, !llvm.struct<(array<2 x i64>, array<3 x i64>)>)
    %24 = call @matmul(%23#0, %23#1, %23#2, %23#3, %21, %22) : (memref<?xindex>, memref<?xindex>, memref<?xf64>, !llvm.struct<(array<2 x i64>, array<3 x i64>)>, tensor<10x10xf64>, tensor<10x10xf64>) -> tensor<10x10xf64>
    cf.br ^bb1(%c0 : index)
  ^bb1(%25: index):  // 2 preds: ^bb0, ^bb7
    %26 = arith.cmpi slt, %25, %c10 : index
    cf.cond_br %26, ^bb2, ^bb8
  ^bb2:  // pred: ^bb1
    %27 = vector.transfer_read %24[%25, %c0], %cst {in_bounds = [true]} : tensor<10x10xf64>, vector<10xf64>
    llvm.call @printOpen() : () -> ()
    cf.br ^bb3(%c0 : index)
  ^bb3(%28: index):  // 2 preds: ^bb2, ^bb6
    %29 = builtin.unrealized_conversion_cast %28 : index to i64
    %30 = arith.cmpi slt, %28, %c10 : index
    cf.cond_br %30, ^bb4, ^bb7
  ^bb4:  // pred: ^bb3
    %31 = llvm.extractelement %27[%29 : i64] : vector<10xf64>
    llvm.call @printF64(%31) : (f64) -> ()
    %32 = arith.cmpi ult, %28, %c9 : index
    cf.cond_br %32, ^bb5, ^bb6
  ^bb5:  // pred: ^bb4
    llvm.call @printComma() : () -> ()
    cf.br ^bb6
  ^bb6:  // 2 preds: ^bb4, ^bb5
    %33 = arith.addi %28, %c1 : index
    cf.br ^bb3(%33 : index)
  ^bb7:  // pred: ^bb3
    llvm.call @printClose() : () -> ()
    llvm.call @printNewline() : () -> ()
    %34 = arith.addi %25, %c1 : index
    cf.br ^bb1(%34 : index)
  ^bb8:  // pred: ^bb1
    %extracted = tensor.extract %24[%c8, %c8] : tensor<10x10xf64>
    %35 = arith.fptosi %extracted : f64 to i64
    return %35 : i64
  }
  func.func @assemble_sparse() -> (memref<?xindex>, memref<?xindex>, memref<?xf64>, !llvm.struct<(array<2 x i64>, array<3 x i64>)>) {
    %c11_i64 = arith.constant 11 : i64
    %c10_i64 = arith.constant 10 : i64
    %c0_i64 = arith.constant 0 : i64
    %0 = llvm.mlir.poison : !llvm.struct<(array<2 x i64>, array<3 x i64>)>
    %c10 = arith.constant 10 : index
    %1 = builtin.unrealized_conversion_cast %c10 : index to i64
    %2 = llvm.mlir.constant(30 : index) : i64
    %3 = llvm.mlir.constant(1 : index) : i64
    %4 = llvm.mlir.zero : !llvm.ptr
    %5 = llvm.getelementptr %4[%2] : (!llvm.ptr, i64) -> !llvm.ptr, f64
    %6 = llvm.ptrtoint %5 : !llvm.ptr to i64
    %7 = llvm.mlir.addressof @__constant_30xf64 : !llvm.ptr
    %8 = llvm.getelementptr %7[0, 0] : (!llvm.ptr) -> !llvm.ptr, !llvm.array<30 x f64>
    %9 = llvm.mlir.constant(3735928559 : index) : i64
    %10 = llvm.inttoptr %9 : i64 to !llvm.ptr
    %11 = llvm.mlir.poison : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %12 = llvm.insertvalue %10, %11[0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %13 = llvm.insertvalue %8, %12[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %14 = llvm.mlir.constant(0 : index) : i64
    %15 = llvm.insertvalue %14, %13[2] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %16 = llvm.insertvalue %2, %15[3, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %17 = llvm.insertvalue %3, %16[4, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %18 = builtin.unrealized_conversion_cast %17 : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> to memref<?xf64>
    %19 = llvm.mlir.constant(11 : index) : i64
    %20 = llvm.mlir.constant(1 : index) : i64
    %21 = llvm.mlir.zero : !llvm.ptr
    %22 = llvm.getelementptr %21[%19] : (!llvm.ptr, i64) -> !llvm.ptr, i64
    %23 = llvm.ptrtoint %22 : !llvm.ptr to i64
    %24 = llvm.mlir.addressof @__constant_11xindex : !llvm.ptr
    %25 = llvm.getelementptr %24[0, 0] : (!llvm.ptr) -> !llvm.ptr, !llvm.array<11 x i64>
    %26 = llvm.mlir.constant(3735928559 : index) : i64
    %27 = llvm.inttoptr %26 : i64 to !llvm.ptr
    %28 = llvm.mlir.poison : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %29 = llvm.insertvalue %27, %28[0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %30 = llvm.insertvalue %25, %29[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %31 = llvm.mlir.constant(0 : index) : i64
    %32 = llvm.insertvalue %31, %30[2] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %33 = llvm.insertvalue %19, %32[3, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %34 = llvm.insertvalue %20, %33[4, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %35 = builtin.unrealized_conversion_cast %34 : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> to memref<?xindex>
    %36 = llvm.mlir.constant(30 : index) : i64
    %37 = llvm.mlir.constant(1 : index) : i64
    %38 = llvm.mlir.zero : !llvm.ptr
    %39 = llvm.getelementptr %38[%36] : (!llvm.ptr, i64) -> !llvm.ptr, i64
    %40 = llvm.ptrtoint %39 : !llvm.ptr to i64
    %41 = llvm.mlir.addressof @__constant_30xindex : !llvm.ptr
    %42 = llvm.getelementptr %41[0, 0] : (!llvm.ptr) -> !llvm.ptr, !llvm.array<30 x i64>
    %43 = llvm.mlir.constant(3735928559 : index) : i64
    %44 = llvm.inttoptr %43 : i64 to !llvm.ptr
    %45 = llvm.mlir.poison : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %46 = llvm.insertvalue %44, %45[0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %47 = llvm.insertvalue %42, %46[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %48 = llvm.mlir.constant(0 : index) : i64
    %49 = llvm.insertvalue %48, %47[2] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %50 = llvm.insertvalue %36, %49[3, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %51 = llvm.insertvalue %37, %50[4, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %52 = builtin.unrealized_conversion_cast %51 : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> to memref<?xindex>
    %53 = llvm.insertvalue %c0_i64, %0[1, 0] : !llvm.struct<(array<2 x i64>, array<3 x i64>)> 
    %54 = llvm.insertvalue %c0_i64, %53[1, 1] : !llvm.struct<(array<2 x i64>, array<3 x i64>)> 
    %55 = llvm.insertvalue %c0_i64, %54[1, 2] : !llvm.struct<(array<2 x i64>, array<3 x i64>)> 
    %56 = llvm.insertvalue %c10_i64, %55[0, 0] : !llvm.struct<(array<2 x i64>, array<3 x i64>)> 
    %57 = llvm.insertvalue %c10_i64, %56[0, 1] : !llvm.struct<(array<2 x i64>, array<3 x i64>)> 
    %58 = llvm.insertvalue %c11_i64, %57[1, 0] : !llvm.struct<(array<2 x i64>, array<3 x i64>)> 
    %59 = llvm.extractvalue %34[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %60 = llvm.getelementptr %59[%1] : (!llvm.ptr, i64) -> !llvm.ptr, i64
    %61 = llvm.load %60 : !llvm.ptr -> i64
    %62 = builtin.unrealized_conversion_cast %61 : i64 to index
    %63 = arith.index_cast %62 : index to i64
    %64 = llvm.insertvalue %63, %58[1, 1] : !llvm.struct<(array<2 x i64>, array<3 x i64>)> 
    %65 = arith.index_cast %62 : index to i64
    %66 = llvm.insertvalue %65, %64[1, 2] : !llvm.struct<(array<2 x i64>, array<3 x i64>)> 
    return %35, %52, %18, %66 : memref<?xindex>, memref<?xindex>, memref<?xf64>, !llvm.struct<(array<2 x i64>, array<3 x i64>)>
  }
}


// -----// IR Dump After ConvertComplexToStandardPass (convert-complex-to-standard) //----- //
module {
  llvm.func @printNewline()
  llvm.func @printClose()
  llvm.func @printComma()
  llvm.func @printF64(f64)
  llvm.func @printOpen()
  llvm.mlir.global private constant @__constant_30xindex(dense<[8, 3, 4, 6, 9, 2, 4, 0, 1, 2, 3, 5, 7, 8, 3, 6, 2, 3, 4, 5, 8, 1, 5, 7, 8, 5, 9, 4, 7, 7]> : tensor<30xindex>) {addr_space = 0 : i32, alignment = 64 : i64} : !llvm.array<30 x i64>
  llvm.mlir.global private constant @__constant_11xindex(dense<[0, 1, 5, 7, 14, 16, 21, 25, 27, 29, 30]> : tensor<11xindex>) {addr_space = 0 : i32, alignment = 64 : i64} : !llvm.array<11 x i64>
  llvm.mlir.global private constant @__constant_30xf64(dense<[4.7563469999999999, 2.102859, 5.4238689999999998, 5.577680e+00, 3.001240e-01, 4.8357549999999998, 8.8596050000000002, 1.592490e+00, 7.372070e+00, 7.2462879999999998, 5.9191609999999999, 5.9593920000000002, 4.6956530000000001, 6.328630e-01, 3.1591619999999998, 4.7083050000000002, 8.4356449999999992, 5.4309390000000004, 2.1190630000000001, 1.545420e-01, 2.595040e+00, 1.4655819999999999, 1.321259, 3.702925, 3.542246, 6.831162, 1.723510e+00, 7.8729019999999998, 6.0081550000000004, 1.047045]> : tensor<30xf64>) {addr_space = 0 : i32, alignment = 64 : i64} : !llvm.array<30 x f64>
  llvm.mlir.global private constant @__constant_10x10xf64(dense<[[5.0072820879405331, 2.1420497309468542, 8.4364357946217474, 3.3512684114489364, 4.8578737173077684, 6.5026873298607608, 4.481183080848961, 1.6018142840321781, 1.6482067031075565, 2.7697353449463433], [8.2796435610104453, 9.7956308688691446, 5.066309369035312, 1.0691978274975567, 7.2754747197326219, 7.4679216752662611, 1.8460472498040226, 1.7245060332115747, 9.828847678500983, 5.8523888503628294], [4.735129046344202, 0.21389279999051047, 9.9823910553584571, 0.22751442405574696, 4.3063298537464378, 1.0300462704374436, 7.1885192597496097, 1.7297134743393461, 7.4494154821665912, 8.2180913094628564], [0.55370097211729696, 7.0871105126860554, 7.7450498540614178, 4.2448327660994876, 1.2746000519648371, 9.4391729894286023, 6.1902689198805465, 6.0312877871821424, 8.7890699247898425, 3.1611885774377635], [8.9903796016343396, 3.4471256572948263, 8.4932841564173884, 9.9373309006088171, 2.6191045587156303, 0.77351004199567641, 1.4024547359632467, 7.454551829233095, 2.6194195569905077, 4.0298520046877577], [4.7641019675563543, 3.8129279818642861, 9.0747728919768225, 6.4920816381757511, 6.7882405668469881, 7.0063465072165911, 5.7386637585592792, 7.5230234961300599, 0.91592641387099771, 8.6646639602141899], [5.6862365678538973, 4.8755032417073192, 9.5859588536709328, 8.1186668576209513, 5.3811119011589454, 3.8280043169558411, 9.9983397606134918, 6.1835824149566241, 3.4201107815517515, 0.84968218962971687], [2.791270331453247, 2.9735813587818685, 3.0654358664150494, 5.4929582569491755, 3.9238922832952996, 9.2657934977933269, 5.0681592194030571, 9.6910348814034712, 2.0972430846802959, 0.96789458347651514], [3.1989914495545624, 3.7607248895716507, 5.5182323136835318, 2.4724154287944913, 7.2920674615977124, 9.7009225179758473, 9.9421519655410044, 2.6109645810252315, 9.0484630420475316, 3.6771724535825703], [6.305746358135309, 7.6948754823713771, 3.6012681436537397, 1.263350310992416, 3.8581878444772943, 7.1047027925517909, 2.1904752468927735, 0.32914734762647391, 3.1668377278172235, 2.0518472657841924]]> : tensor<10x10xf64>) {addr_space = 0 : i32, alignment = 64 : i64} : !llvm.array<10 x array<10 x f64>>
  func.func @matmul(%arg0: memref<?xindex>, %arg1: memref<?xindex>, %arg2: memref<?xf64>, %arg3: !llvm.struct<(array<2 x i64>, array<3 x i64>)>, %arg4: tensor<10x10xf64>, %arg5: tensor<10x10xf64>) -> tensor<10x10xf64> {
    %0 = builtin.unrealized_conversion_cast %arg1 : memref<?xindex> to !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %1 = builtin.unrealized_conversion_cast %arg0 : memref<?xindex> to !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %2 = builtin.unrealized_conversion_cast %arg2 : memref<?xf64> to !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %cst = arith.constant dense<[0, 1, 2, 3]> : vector<4xi32>
    %c-1 = arith.constant -1 : index
    %cst_0 = arith.constant dense<0.000000e+00> : vector<4xf64>
    %c4 = arith.constant 4 : index
    %c1 = arith.constant 1 : index
    %c0 = arith.constant 0 : index
    %c10 = arith.constant 10 : index
    %3 = llvm.extractvalue %arg3[1, 2] : !llvm.struct<(array<2 x i64>, array<3 x i64>)> 
    %4 = arith.index_cast %3 : i64 to index
    %5 = builtin.unrealized_conversion_cast %4 : index to i64
    %6 = llvm.extractvalue %2[0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %7 = llvm.extractvalue %2[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %8 = llvm.mlir.poison : !llvm.struct<(ptr, ptr, i64)>
    %9 = llvm.insertvalue %6, %8[0] : !llvm.struct<(ptr, ptr, i64)> 
    %10 = llvm.insertvalue %7, %9[1] : !llvm.struct<(ptr, ptr, i64)> 
    %11 = llvm.mlir.constant(0 : index) : i64
    %12 = llvm.insertvalue %11, %10[2] : !llvm.struct<(ptr, ptr, i64)> 
    %13 = llvm.extractvalue %2[2] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %14 = llvm.extractvalue %2[3, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %15 = llvm.extractvalue %2[4, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %16 = llvm.mlir.poison : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %17 = llvm.insertvalue %6, %16[0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %18 = llvm.insertvalue %7, %17[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %19 = llvm.mlir.constant(0 : index) : i64
    %20 = llvm.insertvalue %19, %18[2] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %21 = llvm.insertvalue %5, %20[3, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %22 = llvm.mlir.constant(1 : index) : i64
    %23 = llvm.insertvalue %22, %21[4, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %24 = bufferization.to_memref %arg4 : tensor<10x10xf64> to memref<10x10xf64>
    %25 = builtin.unrealized_conversion_cast %24 : memref<10x10xf64> to !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)>
    %26 = bufferization.to_memref %arg5 : tensor<10x10xf64> to memref<10x10xf64>
    %27 = builtin.unrealized_conversion_cast %26 : memref<10x10xf64> to !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)>
    %28 = llvm.extractvalue %arg3[1, 0] : !llvm.struct<(array<2 x i64>, array<3 x i64>)> 
    %29 = arith.index_cast %28 : i64 to index
    %30 = builtin.unrealized_conversion_cast %29 : index to i64
    %31 = llvm.extractvalue %1[0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %32 = llvm.extractvalue %1[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %33 = llvm.mlir.poison : !llvm.struct<(ptr, ptr, i64)>
    %34 = llvm.insertvalue %31, %33[0] : !llvm.struct<(ptr, ptr, i64)> 
    %35 = llvm.insertvalue %32, %34[1] : !llvm.struct<(ptr, ptr, i64)> 
    %36 = llvm.mlir.constant(0 : index) : i64
    %37 = llvm.insertvalue %36, %35[2] : !llvm.struct<(ptr, ptr, i64)> 
    %38 = llvm.extractvalue %1[2] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %39 = llvm.extractvalue %1[3, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %40 = llvm.extractvalue %1[4, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %41 = llvm.mlir.poison : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %42 = llvm.insertvalue %31, %41[0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %43 = llvm.insertvalue %32, %42[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %44 = llvm.mlir.constant(0 : index) : i64
    %45 = llvm.insertvalue %44, %43[2] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %46 = llvm.insertvalue %30, %45[3, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %47 = llvm.mlir.constant(1 : index) : i64
    %48 = llvm.insertvalue %47, %46[4, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %49 = llvm.extractvalue %arg3[1, 1] : !llvm.struct<(array<2 x i64>, array<3 x i64>)> 
    %50 = arith.index_cast %49 : i64 to index
    %51 = builtin.unrealized_conversion_cast %50 : index to i64
    %52 = llvm.extractvalue %0[0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %53 = llvm.extractvalue %0[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %54 = llvm.mlir.poison : !llvm.struct<(ptr, ptr, i64)>
    %55 = llvm.insertvalue %52, %54[0] : !llvm.struct<(ptr, ptr, i64)> 
    %56 = llvm.insertvalue %53, %55[1] : !llvm.struct<(ptr, ptr, i64)> 
    %57 = llvm.mlir.constant(0 : index) : i64
    %58 = llvm.insertvalue %57, %56[2] : !llvm.struct<(ptr, ptr, i64)> 
    %59 = llvm.extractvalue %0[2] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %60 = llvm.extractvalue %0[3, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %61 = llvm.extractvalue %0[4, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %62 = llvm.mlir.poison : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %63 = llvm.insertvalue %52, %62[0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %64 = llvm.insertvalue %53, %63[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %65 = llvm.mlir.constant(0 : index) : i64
    %66 = llvm.insertvalue %65, %64[2] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %67 = llvm.insertvalue %51, %66[3, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %68 = llvm.mlir.constant(1 : index) : i64
    %69 = llvm.insertvalue %68, %67[4, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    cf.br ^bb1(%c0 : index)
  ^bb1(%70: index):  // 2 preds: ^bb0, ^bb8
    %71 = builtin.unrealized_conversion_cast %70 : index to i64
    %72 = builtin.unrealized_conversion_cast %70 : index to i64
    %73 = arith.cmpi slt, %70, %c10 : index
    cf.cond_br %73, ^bb2, ^bb9
  ^bb2:  // pred: ^bb1
    %74 = llvm.getelementptr %32[%71] : (!llvm.ptr, i64) -> !llvm.ptr, i64
    %75 = llvm.load %74 : !llvm.ptr -> i64
    %76 = builtin.unrealized_conversion_cast %75 : i64 to index
    %77 = arith.addi %70, %c1 : index
    %78 = builtin.unrealized_conversion_cast %77 : index to i64
    %79 = llvm.getelementptr %32[%78] : (!llvm.ptr, i64) -> !llvm.ptr, i64
    %80 = llvm.load %79 : !llvm.ptr -> i64
    %81 = builtin.unrealized_conversion_cast %80 : i64 to index
    cf.br ^bb3(%76 : index)
  ^bb3(%82: index):  // 2 preds: ^bb2, ^bb7
    %83 = builtin.unrealized_conversion_cast %82 : index to i64
    %84 = arith.cmpi slt, %82, %81 : index
    cf.cond_br %84, ^bb4, ^bb8
  ^bb4:  // pred: ^bb3
    %85 = llvm.getelementptr %53[%83] : (!llvm.ptr, i64) -> !llvm.ptr, i64
    %86 = llvm.load %85 : !llvm.ptr -> i64
    %87 = builtin.unrealized_conversion_cast %86 : i64 to index
    %88 = llvm.getelementptr %7[%83] : (!llvm.ptr, i64) -> !llvm.ptr, f64
    %89 = llvm.load %88 : !llvm.ptr -> f64
    cf.br ^bb5(%c0 : index)
  ^bb5(%90: index):  // 2 preds: ^bb4, ^bb6
    %91 = builtin.unrealized_conversion_cast %90 : index to i64
    %92 = arith.cmpi slt, %90, %c10 : index
    cf.cond_br %92, ^bb6, ^bb7
  ^bb6:  // pred: ^bb5
    %93 = arith.muli %90, %c-1 overflow<nsw> : index
    %94 = arith.addi %93, %c10 : index
    %95 = arith.minsi %94, %c4 : index
    %96 = arith.index_cast %95 : index to i32
    %97 = llvm.mlir.poison : vector<4xi32>
    %98 = llvm.mlir.constant(0 : i32) : i32
    %99 = llvm.insertelement %96, %97[%98 : i32] : vector<4xi32>
    %100 = llvm.shufflevector %99, %97 [0, 0, 0, 0] : vector<4xi32> 
    %101 = arith.cmpi sgt, %100, %cst : vector<4xi32>
    %102 = llvm.extractvalue %27[1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %103 = llvm.mlir.constant(10 : index) : i64
    %104 = llvm.mul %72, %103 : i64
    %105 = llvm.add %104, %91 : i64
    %106 = llvm.getelementptr %102[%105] : (!llvm.ptr, i64) -> !llvm.ptr, f64
    %107 = llvm.intr.masked.load %106, %101, %cst_0 {alignment = 8 : i32} : (!llvm.ptr, vector<4xi1>, vector<4xf64>) -> vector<4xf64>
    %108 = llvm.mlir.poison : vector<4xf64>
    %109 = llvm.mlir.constant(0 : i32) : i32
    %110 = llvm.insertelement %89, %108[%109 : i32] : vector<4xf64>
    %111 = llvm.shufflevector %110, %108 [0, 0, 0, 0] : vector<4xf64> 
    %112 = llvm.extractvalue %25[1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %113 = llvm.mlir.constant(10 : index) : i64
    %114 = llvm.mul %86, %113 : i64
    %115 = llvm.add %114, %91 : i64
    %116 = llvm.getelementptr %112[%115] : (!llvm.ptr, i64) -> !llvm.ptr, f64
    %117 = llvm.intr.masked.load %116, %101, %cst_0 {alignment = 8 : i32} : (!llvm.ptr, vector<4xi1>, vector<4xf64>) -> vector<4xf64>
    %118 = arith.mulf %111, %117 : vector<4xf64>
    %119 = arith.addf %107, %118 : vector<4xf64>
    %120 = llvm.extractvalue %27[1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %121 = llvm.mlir.constant(10 : index) : i64
    %122 = llvm.mul %72, %121 : i64
    %123 = llvm.add %122, %91 : i64
    %124 = llvm.getelementptr %120[%123] : (!llvm.ptr, i64) -> !llvm.ptr, f64
    llvm.intr.masked.store %119, %124, %101 {alignment = 8 : i32} : vector<4xf64>, vector<4xi1> into !llvm.ptr
    %125 = arith.addi %90, %c4 : index
    cf.br ^bb5(%125 : index)
  ^bb7:  // pred: ^bb5
    %126 = arith.addi %82, %c1 : index
    cf.br ^bb3(%126 : index)
  ^bb8:  // pred: ^bb3
    %127 = arith.addi %70, %c1 : index
    cf.br ^bb1(%127 : index)
  ^bb9:  // pred: ^bb1
    %128 = bufferization.to_tensor %26 : memref<10x10xf64> to tensor<10x10xf64>
    return %128 : tensor<10x10xf64>
  }
  func.func @main() -> i64 {
    %c9 = arith.constant 9 : index
    %c8 = arith.constant 8 : index
    %cst = arith.constant 0.000000e+00 : f64
    %c1 = arith.constant 1 : index
    %c10 = arith.constant 10 : index
    %c0 = arith.constant 0 : index
    %0 = llvm.mlir.constant(10 : index) : i64
    %1 = llvm.mlir.constant(10 : index) : i64
    %2 = llvm.mlir.constant(1 : index) : i64
    %3 = llvm.mlir.constant(100 : index) : i64
    %4 = llvm.mlir.zero : !llvm.ptr
    %5 = llvm.getelementptr %4[100] : (!llvm.ptr) -> !llvm.ptr, f64
    %6 = llvm.ptrtoint %5 : !llvm.ptr to i64
    %7 = llvm.mlir.addressof @__constant_10x10xf64 : !llvm.ptr
    %8 = llvm.getelementptr %7[0, 0, 0] : (!llvm.ptr) -> !llvm.ptr, !llvm.array<10 x array<10 x f64>>
    %9 = llvm.mlir.constant(3735928559 : index) : i64
    %10 = llvm.inttoptr %9 : i64 to !llvm.ptr
    %11 = llvm.mlir.poison : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)>
    %12 = llvm.insertvalue %10, %11[0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %13 = llvm.insertvalue %8, %12[1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %14 = llvm.mlir.constant(0 : index) : i64
    %15 = llvm.insertvalue %14, %13[2] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %16 = llvm.insertvalue %0, %15[3, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %17 = llvm.insertvalue %1, %16[3, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %18 = llvm.insertvalue %1, %17[4, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %19 = llvm.insertvalue %2, %18[4, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %20 = builtin.unrealized_conversion_cast %19 : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> to memref<10x10xf64>
    %21 = bufferization.to_tensor %20 : memref<10x10xf64> to tensor<10x10xf64>
    %22 = bufferization.alloc_tensor() : tensor<10x10xf64>
    %23:4 = call @assemble_sparse() : () -> (memref<?xindex>, memref<?xindex>, memref<?xf64>, !llvm.struct<(array<2 x i64>, array<3 x i64>)>)
    %24 = call @matmul(%23#0, %23#1, %23#2, %23#3, %21, %22) : (memref<?xindex>, memref<?xindex>, memref<?xf64>, !llvm.struct<(array<2 x i64>, array<3 x i64>)>, tensor<10x10xf64>, tensor<10x10xf64>) -> tensor<10x10xf64>
    cf.br ^bb1(%c0 : index)
  ^bb1(%25: index):  // 2 preds: ^bb0, ^bb7
    %26 = arith.cmpi slt, %25, %c10 : index
    cf.cond_br %26, ^bb2, ^bb8
  ^bb2:  // pred: ^bb1
    %27 = vector.transfer_read %24[%25, %c0], %cst {in_bounds = [true]} : tensor<10x10xf64>, vector<10xf64>
    llvm.call @printOpen() : () -> ()
    cf.br ^bb3(%c0 : index)
  ^bb3(%28: index):  // 2 preds: ^bb2, ^bb6
    %29 = builtin.unrealized_conversion_cast %28 : index to i64
    %30 = arith.cmpi slt, %28, %c10 : index
    cf.cond_br %30, ^bb4, ^bb7
  ^bb4:  // pred: ^bb3
    %31 = llvm.extractelement %27[%29 : i64] : vector<10xf64>
    llvm.call @printF64(%31) : (f64) -> ()
    %32 = arith.cmpi ult, %28, %c9 : index
    cf.cond_br %32, ^bb5, ^bb6
  ^bb5:  // pred: ^bb4
    llvm.call @printComma() : () -> ()
    cf.br ^bb6
  ^bb6:  // 2 preds: ^bb4, ^bb5
    %33 = arith.addi %28, %c1 : index
    cf.br ^bb3(%33 : index)
  ^bb7:  // pred: ^bb3
    llvm.call @printClose() : () -> ()
    llvm.call @printNewline() : () -> ()
    %34 = arith.addi %25, %c1 : index
    cf.br ^bb1(%34 : index)
  ^bb8:  // pred: ^bb1
    %extracted = tensor.extract %24[%c8, %c8] : tensor<10x10xf64>
    %35 = arith.fptosi %extracted : f64 to i64
    return %35 : i64
  }
  func.func @assemble_sparse() -> (memref<?xindex>, memref<?xindex>, memref<?xf64>, !llvm.struct<(array<2 x i64>, array<3 x i64>)>) {
    %c11_i64 = arith.constant 11 : i64
    %c10_i64 = arith.constant 10 : i64
    %c0_i64 = arith.constant 0 : i64
    %0 = llvm.mlir.poison : !llvm.struct<(array<2 x i64>, array<3 x i64>)>
    %c10 = arith.constant 10 : index
    %1 = builtin.unrealized_conversion_cast %c10 : index to i64
    %2 = llvm.mlir.constant(30 : index) : i64
    %3 = llvm.mlir.constant(1 : index) : i64
    %4 = llvm.mlir.zero : !llvm.ptr
    %5 = llvm.getelementptr %4[30] : (!llvm.ptr) -> !llvm.ptr, f64
    %6 = llvm.ptrtoint %5 : !llvm.ptr to i64
    %7 = llvm.mlir.addressof @__constant_30xf64 : !llvm.ptr
    %8 = llvm.getelementptr %7[0, 0] : (!llvm.ptr) -> !llvm.ptr, !llvm.array<30 x f64>
    %9 = llvm.mlir.constant(3735928559 : index) : i64
    %10 = llvm.inttoptr %9 : i64 to !llvm.ptr
    %11 = llvm.mlir.poison : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %12 = llvm.insertvalue %10, %11[0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %13 = llvm.insertvalue %8, %12[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %14 = llvm.mlir.constant(0 : index) : i64
    %15 = llvm.insertvalue %14, %13[2] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %16 = llvm.insertvalue %2, %15[3, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %17 = llvm.insertvalue %3, %16[4, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %18 = builtin.unrealized_conversion_cast %17 : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> to memref<?xf64>
    %19 = llvm.mlir.constant(11 : index) : i64
    %20 = llvm.mlir.constant(1 : index) : i64
    %21 = llvm.mlir.zero : !llvm.ptr
    %22 = llvm.getelementptr %21[11] : (!llvm.ptr) -> !llvm.ptr, i64
    %23 = llvm.ptrtoint %22 : !llvm.ptr to i64
    %24 = llvm.mlir.addressof @__constant_11xindex : !llvm.ptr
    %25 = llvm.getelementptr %24[0, 0] : (!llvm.ptr) -> !llvm.ptr, !llvm.array<11 x i64>
    %26 = llvm.mlir.constant(3735928559 : index) : i64
    %27 = llvm.inttoptr %26 : i64 to !llvm.ptr
    %28 = llvm.mlir.poison : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %29 = llvm.insertvalue %27, %28[0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %30 = llvm.insertvalue %25, %29[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %31 = llvm.mlir.constant(0 : index) : i64
    %32 = llvm.insertvalue %31, %30[2] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %33 = llvm.insertvalue %19, %32[3, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %34 = llvm.insertvalue %20, %33[4, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %35 = builtin.unrealized_conversion_cast %34 : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> to memref<?xindex>
    %36 = llvm.mlir.constant(30 : index) : i64
    %37 = llvm.mlir.constant(1 : index) : i64
    %38 = llvm.mlir.zero : !llvm.ptr
    %39 = llvm.getelementptr %38[30] : (!llvm.ptr) -> !llvm.ptr, i64
    %40 = llvm.ptrtoint %39 : !llvm.ptr to i64
    %41 = llvm.mlir.addressof @__constant_30xindex : !llvm.ptr
    %42 = llvm.getelementptr %41[0, 0] : (!llvm.ptr) -> !llvm.ptr, !llvm.array<30 x i64>
    %43 = llvm.mlir.constant(3735928559 : index) : i64
    %44 = llvm.inttoptr %43 : i64 to !llvm.ptr
    %45 = llvm.mlir.poison : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %46 = llvm.insertvalue %44, %45[0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %47 = llvm.insertvalue %42, %46[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %48 = llvm.mlir.constant(0 : index) : i64
    %49 = llvm.insertvalue %48, %47[2] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %50 = llvm.insertvalue %36, %49[3, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %51 = llvm.insertvalue %37, %50[4, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %52 = builtin.unrealized_conversion_cast %51 : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> to memref<?xindex>
    %53 = llvm.insertvalue %c0_i64, %0[1, 0] : !llvm.struct<(array<2 x i64>, array<3 x i64>)> 
    %54 = llvm.insertvalue %c0_i64, %53[1, 1] : !llvm.struct<(array<2 x i64>, array<3 x i64>)> 
    %55 = llvm.insertvalue %c0_i64, %54[1, 2] : !llvm.struct<(array<2 x i64>, array<3 x i64>)> 
    %56 = llvm.insertvalue %c10_i64, %55[0, 0] : !llvm.struct<(array<2 x i64>, array<3 x i64>)> 
    %57 = llvm.insertvalue %c10_i64, %56[0, 1] : !llvm.struct<(array<2 x i64>, array<3 x i64>)> 
    %58 = llvm.insertvalue %c11_i64, %57[1, 0] : !llvm.struct<(array<2 x i64>, array<3 x i64>)> 
    %59 = llvm.getelementptr %25[%1] : (!llvm.ptr, i64) -> !llvm.ptr, i64
    %60 = llvm.load %59 : !llvm.ptr -> i64
    %61 = builtin.unrealized_conversion_cast %60 : i64 to index
    %62 = arith.index_cast %61 : index to i64
    %63 = llvm.insertvalue %62, %58[1, 1] : !llvm.struct<(array<2 x i64>, array<3 x i64>)> 
    %64 = arith.index_cast %61 : index to i64
    %65 = llvm.insertvalue %64, %63[1, 2] : !llvm.struct<(array<2 x i64>, array<3 x i64>)> 
    return %35, %52, %18, %65 : memref<?xindex>, memref<?xindex>, memref<?xf64>, !llvm.struct<(array<2 x i64>, array<3 x i64>)>
  }
}


// -----// IR Dump After ArithExpandOpsPass (arith-expand) //----- //
module {
  llvm.func @printNewline()
  llvm.func @printClose()
  llvm.func @printComma()
  llvm.func @printF64(f64)
  llvm.func @printOpen()
  llvm.mlir.global private constant @__constant_30xindex(dense<[8, 3, 4, 6, 9, 2, 4, 0, 1, 2, 3, 5, 7, 8, 3, 6, 2, 3, 4, 5, 8, 1, 5, 7, 8, 5, 9, 4, 7, 7]> : tensor<30xindex>) {addr_space = 0 : i32, alignment = 64 : i64} : !llvm.array<30 x i64>
  llvm.mlir.global private constant @__constant_11xindex(dense<[0, 1, 5, 7, 14, 16, 21, 25, 27, 29, 30]> : tensor<11xindex>) {addr_space = 0 : i32, alignment = 64 : i64} : !llvm.array<11 x i64>
  llvm.mlir.global private constant @__constant_30xf64(dense<[4.7563469999999999, 2.102859, 5.4238689999999998, 5.577680e+00, 3.001240e-01, 4.8357549999999998, 8.8596050000000002, 1.592490e+00, 7.372070e+00, 7.2462879999999998, 5.9191609999999999, 5.9593920000000002, 4.6956530000000001, 6.328630e-01, 3.1591619999999998, 4.7083050000000002, 8.4356449999999992, 5.4309390000000004, 2.1190630000000001, 1.545420e-01, 2.595040e+00, 1.4655819999999999, 1.321259, 3.702925, 3.542246, 6.831162, 1.723510e+00, 7.8729019999999998, 6.0081550000000004, 1.047045]> : tensor<30xf64>) {addr_space = 0 : i32, alignment = 64 : i64} : !llvm.array<30 x f64>
  llvm.mlir.global private constant @__constant_10x10xf64(dense<[[5.0072820879405331, 2.1420497309468542, 8.4364357946217474, 3.3512684114489364, 4.8578737173077684, 6.5026873298607608, 4.481183080848961, 1.6018142840321781, 1.6482067031075565, 2.7697353449463433], [8.2796435610104453, 9.7956308688691446, 5.066309369035312, 1.0691978274975567, 7.2754747197326219, 7.4679216752662611, 1.8460472498040226, 1.7245060332115747, 9.828847678500983, 5.8523888503628294], [4.735129046344202, 0.21389279999051047, 9.9823910553584571, 0.22751442405574696, 4.3063298537464378, 1.0300462704374436, 7.1885192597496097, 1.7297134743393461, 7.4494154821665912, 8.2180913094628564], [0.55370097211729696, 7.0871105126860554, 7.7450498540614178, 4.2448327660994876, 1.2746000519648371, 9.4391729894286023, 6.1902689198805465, 6.0312877871821424, 8.7890699247898425, 3.1611885774377635], [8.9903796016343396, 3.4471256572948263, 8.4932841564173884, 9.9373309006088171, 2.6191045587156303, 0.77351004199567641, 1.4024547359632467, 7.454551829233095, 2.6194195569905077, 4.0298520046877577], [4.7641019675563543, 3.8129279818642861, 9.0747728919768225, 6.4920816381757511, 6.7882405668469881, 7.0063465072165911, 5.7386637585592792, 7.5230234961300599, 0.91592641387099771, 8.6646639602141899], [5.6862365678538973, 4.8755032417073192, 9.5859588536709328, 8.1186668576209513, 5.3811119011589454, 3.8280043169558411, 9.9983397606134918, 6.1835824149566241, 3.4201107815517515, 0.84968218962971687], [2.791270331453247, 2.9735813587818685, 3.0654358664150494, 5.4929582569491755, 3.9238922832952996, 9.2657934977933269, 5.0681592194030571, 9.6910348814034712, 2.0972430846802959, 0.96789458347651514], [3.1989914495545624, 3.7607248895716507, 5.5182323136835318, 2.4724154287944913, 7.2920674615977124, 9.7009225179758473, 9.9421519655410044, 2.6109645810252315, 9.0484630420475316, 3.6771724535825703], [6.305746358135309, 7.6948754823713771, 3.6012681436537397, 1.263350310992416, 3.8581878444772943, 7.1047027925517909, 2.1904752468927735, 0.32914734762647391, 3.1668377278172235, 2.0518472657841924]]> : tensor<10x10xf64>) {addr_space = 0 : i32, alignment = 64 : i64} : !llvm.array<10 x array<10 x f64>>
  func.func @matmul(%arg0: memref<?xindex>, %arg1: memref<?xindex>, %arg2: memref<?xf64>, %arg3: !llvm.struct<(array<2 x i64>, array<3 x i64>)>, %arg4: tensor<10x10xf64>, %arg5: tensor<10x10xf64>) -> tensor<10x10xf64> {
    %0 = builtin.unrealized_conversion_cast %arg1 : memref<?xindex> to !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %1 = builtin.unrealized_conversion_cast %arg0 : memref<?xindex> to !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %2 = builtin.unrealized_conversion_cast %arg2 : memref<?xf64> to !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %cst = arith.constant dense<[0, 1, 2, 3]> : vector<4xi32>
    %c-1 = arith.constant -1 : index
    %cst_0 = arith.constant dense<0.000000e+00> : vector<4xf64>
    %c4 = arith.constant 4 : index
    %c1 = arith.constant 1 : index
    %c0 = arith.constant 0 : index
    %c10 = arith.constant 10 : index
    %3 = llvm.extractvalue %arg3[1, 2] : !llvm.struct<(array<2 x i64>, array<3 x i64>)> 
    %4 = arith.index_cast %3 : i64 to index
    %5 = builtin.unrealized_conversion_cast %4 : index to i64
    %6 = llvm.extractvalue %2[0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %7 = llvm.extractvalue %2[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %8 = llvm.mlir.poison : !llvm.struct<(ptr, ptr, i64)>
    %9 = llvm.insertvalue %6, %8[0] : !llvm.struct<(ptr, ptr, i64)> 
    %10 = llvm.insertvalue %7, %9[1] : !llvm.struct<(ptr, ptr, i64)> 
    %11 = llvm.mlir.constant(0 : index) : i64
    %12 = llvm.insertvalue %11, %10[2] : !llvm.struct<(ptr, ptr, i64)> 
    %13 = llvm.extractvalue %2[2] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %14 = llvm.extractvalue %2[3, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %15 = llvm.extractvalue %2[4, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %16 = llvm.mlir.poison : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %17 = llvm.insertvalue %6, %16[0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %18 = llvm.insertvalue %7, %17[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %19 = llvm.mlir.constant(0 : index) : i64
    %20 = llvm.insertvalue %19, %18[2] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %21 = llvm.insertvalue %5, %20[3, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %22 = llvm.mlir.constant(1 : index) : i64
    %23 = llvm.insertvalue %22, %21[4, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %24 = bufferization.to_memref %arg4 : tensor<10x10xf64> to memref<10x10xf64>
    %25 = builtin.unrealized_conversion_cast %24 : memref<10x10xf64> to !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)>
    %26 = bufferization.to_memref %arg5 : tensor<10x10xf64> to memref<10x10xf64>
    %27 = builtin.unrealized_conversion_cast %26 : memref<10x10xf64> to !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)>
    %28 = llvm.extractvalue %arg3[1, 0] : !llvm.struct<(array<2 x i64>, array<3 x i64>)> 
    %29 = arith.index_cast %28 : i64 to index
    %30 = builtin.unrealized_conversion_cast %29 : index to i64
    %31 = llvm.extractvalue %1[0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %32 = llvm.extractvalue %1[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %33 = llvm.mlir.poison : !llvm.struct<(ptr, ptr, i64)>
    %34 = llvm.insertvalue %31, %33[0] : !llvm.struct<(ptr, ptr, i64)> 
    %35 = llvm.insertvalue %32, %34[1] : !llvm.struct<(ptr, ptr, i64)> 
    %36 = llvm.mlir.constant(0 : index) : i64
    %37 = llvm.insertvalue %36, %35[2] : !llvm.struct<(ptr, ptr, i64)> 
    %38 = llvm.extractvalue %1[2] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %39 = llvm.extractvalue %1[3, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %40 = llvm.extractvalue %1[4, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %41 = llvm.mlir.poison : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %42 = llvm.insertvalue %31, %41[0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %43 = llvm.insertvalue %32, %42[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %44 = llvm.mlir.constant(0 : index) : i64
    %45 = llvm.insertvalue %44, %43[2] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %46 = llvm.insertvalue %30, %45[3, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %47 = llvm.mlir.constant(1 : index) : i64
    %48 = llvm.insertvalue %47, %46[4, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %49 = llvm.extractvalue %arg3[1, 1] : !llvm.struct<(array<2 x i64>, array<3 x i64>)> 
    %50 = arith.index_cast %49 : i64 to index
    %51 = builtin.unrealized_conversion_cast %50 : index to i64
    %52 = llvm.extractvalue %0[0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %53 = llvm.extractvalue %0[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %54 = llvm.mlir.poison : !llvm.struct<(ptr, ptr, i64)>
    %55 = llvm.insertvalue %52, %54[0] : !llvm.struct<(ptr, ptr, i64)> 
    %56 = llvm.insertvalue %53, %55[1] : !llvm.struct<(ptr, ptr, i64)> 
    %57 = llvm.mlir.constant(0 : index) : i64
    %58 = llvm.insertvalue %57, %56[2] : !llvm.struct<(ptr, ptr, i64)> 
    %59 = llvm.extractvalue %0[2] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %60 = llvm.extractvalue %0[3, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %61 = llvm.extractvalue %0[4, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %62 = llvm.mlir.poison : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %63 = llvm.insertvalue %52, %62[0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %64 = llvm.insertvalue %53, %63[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %65 = llvm.mlir.constant(0 : index) : i64
    %66 = llvm.insertvalue %65, %64[2] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %67 = llvm.insertvalue %51, %66[3, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %68 = llvm.mlir.constant(1 : index) : i64
    %69 = llvm.insertvalue %68, %67[4, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    cf.br ^bb1(%c0 : index)
  ^bb1(%70: index):  // 2 preds: ^bb0, ^bb8
    %71 = builtin.unrealized_conversion_cast %70 : index to i64
    %72 = builtin.unrealized_conversion_cast %70 : index to i64
    %73 = arith.cmpi slt, %70, %c10 : index
    cf.cond_br %73, ^bb2, ^bb9
  ^bb2:  // pred: ^bb1
    %74 = llvm.getelementptr %32[%71] : (!llvm.ptr, i64) -> !llvm.ptr, i64
    %75 = llvm.load %74 : !llvm.ptr -> i64
    %76 = builtin.unrealized_conversion_cast %75 : i64 to index
    %77 = arith.addi %70, %c1 : index
    %78 = builtin.unrealized_conversion_cast %77 : index to i64
    %79 = llvm.getelementptr %32[%78] : (!llvm.ptr, i64) -> !llvm.ptr, i64
    %80 = llvm.load %79 : !llvm.ptr -> i64
    %81 = builtin.unrealized_conversion_cast %80 : i64 to index
    cf.br ^bb3(%76 : index)
  ^bb3(%82: index):  // 2 preds: ^bb2, ^bb7
    %83 = builtin.unrealized_conversion_cast %82 : index to i64
    %84 = arith.cmpi slt, %82, %81 : index
    cf.cond_br %84, ^bb4, ^bb8
  ^bb4:  // pred: ^bb3
    %85 = llvm.getelementptr %53[%83] : (!llvm.ptr, i64) -> !llvm.ptr, i64
    %86 = llvm.load %85 : !llvm.ptr -> i64
    %87 = builtin.unrealized_conversion_cast %86 : i64 to index
    %88 = llvm.getelementptr %7[%83] : (!llvm.ptr, i64) -> !llvm.ptr, f64
    %89 = llvm.load %88 : !llvm.ptr -> f64
    cf.br ^bb5(%c0 : index)
  ^bb5(%90: index):  // 2 preds: ^bb4, ^bb6
    %91 = builtin.unrealized_conversion_cast %90 : index to i64
    %92 = arith.cmpi slt, %90, %c10 : index
    cf.cond_br %92, ^bb6, ^bb7
  ^bb6:  // pred: ^bb5
    %93 = arith.muli %90, %c-1 overflow<nsw> : index
    %94 = arith.addi %93, %c10 : index
    %95 = arith.cmpi slt, %94, %c4 : index
    %96 = arith.select %95, %94, %c4 : index
    %97 = arith.index_cast %96 : index to i32
    %98 = llvm.mlir.poison : vector<4xi32>
    %99 = llvm.mlir.constant(0 : i32) : i32
    %100 = llvm.insertelement %97, %98[%99 : i32] : vector<4xi32>
    %101 = llvm.shufflevector %100, %98 [0, 0, 0, 0] : vector<4xi32> 
    %102 = arith.cmpi sgt, %101, %cst : vector<4xi32>
    %103 = llvm.extractvalue %27[1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %104 = llvm.mlir.constant(10 : index) : i64
    %105 = llvm.mul %72, %104 : i64
    %106 = llvm.add %105, %91 : i64
    %107 = llvm.getelementptr %103[%106] : (!llvm.ptr, i64) -> !llvm.ptr, f64
    %108 = llvm.intr.masked.load %107, %102, %cst_0 {alignment = 8 : i32} : (!llvm.ptr, vector<4xi1>, vector<4xf64>) -> vector<4xf64>
    %109 = llvm.mlir.poison : vector<4xf64>
    %110 = llvm.mlir.constant(0 : i32) : i32
    %111 = llvm.insertelement %89, %109[%110 : i32] : vector<4xf64>
    %112 = llvm.shufflevector %111, %109 [0, 0, 0, 0] : vector<4xf64> 
    %113 = llvm.extractvalue %25[1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %114 = llvm.mlir.constant(10 : index) : i64
    %115 = llvm.mul %86, %114 : i64
    %116 = llvm.add %115, %91 : i64
    %117 = llvm.getelementptr %113[%116] : (!llvm.ptr, i64) -> !llvm.ptr, f64
    %118 = llvm.intr.masked.load %117, %102, %cst_0 {alignment = 8 : i32} : (!llvm.ptr, vector<4xi1>, vector<4xf64>) -> vector<4xf64>
    %119 = arith.mulf %112, %118 : vector<4xf64>
    %120 = arith.addf %108, %119 : vector<4xf64>
    %121 = llvm.extractvalue %27[1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %122 = llvm.mlir.constant(10 : index) : i64
    %123 = llvm.mul %72, %122 : i64
    %124 = llvm.add %123, %91 : i64
    %125 = llvm.getelementptr %121[%124] : (!llvm.ptr, i64) -> !llvm.ptr, f64
    llvm.intr.masked.store %120, %125, %102 {alignment = 8 : i32} : vector<4xf64>, vector<4xi1> into !llvm.ptr
    %126 = arith.addi %90, %c4 : index
    cf.br ^bb5(%126 : index)
  ^bb7:  // pred: ^bb5
    %127 = arith.addi %82, %c1 : index
    cf.br ^bb3(%127 : index)
  ^bb8:  // pred: ^bb3
    %128 = arith.addi %70, %c1 : index
    cf.br ^bb1(%128 : index)
  ^bb9:  // pred: ^bb1
    %129 = bufferization.to_tensor %26 : memref<10x10xf64> to tensor<10x10xf64>
    return %129 : tensor<10x10xf64>
  }
  func.func @main() -> i64 {
    %c9 = arith.constant 9 : index
    %c8 = arith.constant 8 : index
    %cst = arith.constant 0.000000e+00 : f64
    %c1 = arith.constant 1 : index
    %c10 = arith.constant 10 : index
    %c0 = arith.constant 0 : index
    %0 = llvm.mlir.constant(10 : index) : i64
    %1 = llvm.mlir.constant(10 : index) : i64
    %2 = llvm.mlir.constant(1 : index) : i64
    %3 = llvm.mlir.constant(100 : index) : i64
    %4 = llvm.mlir.zero : !llvm.ptr
    %5 = llvm.getelementptr %4[100] : (!llvm.ptr) -> !llvm.ptr, f64
    %6 = llvm.ptrtoint %5 : !llvm.ptr to i64
    %7 = llvm.mlir.addressof @__constant_10x10xf64 : !llvm.ptr
    %8 = llvm.getelementptr %7[0, 0, 0] : (!llvm.ptr) -> !llvm.ptr, !llvm.array<10 x array<10 x f64>>
    %9 = llvm.mlir.constant(3735928559 : index) : i64
    %10 = llvm.inttoptr %9 : i64 to !llvm.ptr
    %11 = llvm.mlir.poison : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)>
    %12 = llvm.insertvalue %10, %11[0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %13 = llvm.insertvalue %8, %12[1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %14 = llvm.mlir.constant(0 : index) : i64
    %15 = llvm.insertvalue %14, %13[2] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %16 = llvm.insertvalue %0, %15[3, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %17 = llvm.insertvalue %1, %16[3, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %18 = llvm.insertvalue %1, %17[4, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %19 = llvm.insertvalue %2, %18[4, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %20 = builtin.unrealized_conversion_cast %19 : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> to memref<10x10xf64>
    %21 = bufferization.to_tensor %20 : memref<10x10xf64> to tensor<10x10xf64>
    %22 = bufferization.alloc_tensor() : tensor<10x10xf64>
    %23:4 = call @assemble_sparse() : () -> (memref<?xindex>, memref<?xindex>, memref<?xf64>, !llvm.struct<(array<2 x i64>, array<3 x i64>)>)
    %24 = call @matmul(%23#0, %23#1, %23#2, %23#3, %21, %22) : (memref<?xindex>, memref<?xindex>, memref<?xf64>, !llvm.struct<(array<2 x i64>, array<3 x i64>)>, tensor<10x10xf64>, tensor<10x10xf64>) -> tensor<10x10xf64>
    cf.br ^bb1(%c0 : index)
  ^bb1(%25: index):  // 2 preds: ^bb0, ^bb7
    %26 = arith.cmpi slt, %25, %c10 : index
    cf.cond_br %26, ^bb2, ^bb8
  ^bb2:  // pred: ^bb1
    %27 = vector.transfer_read %24[%25, %c0], %cst {in_bounds = [true]} : tensor<10x10xf64>, vector<10xf64>
    llvm.call @printOpen() : () -> ()
    cf.br ^bb3(%c0 : index)
  ^bb3(%28: index):  // 2 preds: ^bb2, ^bb6
    %29 = builtin.unrealized_conversion_cast %28 : index to i64
    %30 = arith.cmpi slt, %28, %c10 : index
    cf.cond_br %30, ^bb4, ^bb7
  ^bb4:  // pred: ^bb3
    %31 = llvm.extractelement %27[%29 : i64] : vector<10xf64>
    llvm.call @printF64(%31) : (f64) -> ()
    %32 = arith.cmpi ult, %28, %c9 : index
    cf.cond_br %32, ^bb5, ^bb6
  ^bb5:  // pred: ^bb4
    llvm.call @printComma() : () -> ()
    cf.br ^bb6
  ^bb6:  // 2 preds: ^bb4, ^bb5
    %33 = arith.addi %28, %c1 : index
    cf.br ^bb3(%33 : index)
  ^bb7:  // pred: ^bb3
    llvm.call @printClose() : () -> ()
    llvm.call @printNewline() : () -> ()
    %34 = arith.addi %25, %c1 : index
    cf.br ^bb1(%34 : index)
  ^bb8:  // pred: ^bb1
    %extracted = tensor.extract %24[%c8, %c8] : tensor<10x10xf64>
    %35 = arith.fptosi %extracted : f64 to i64
    return %35 : i64
  }
  func.func @assemble_sparse() -> (memref<?xindex>, memref<?xindex>, memref<?xf64>, !llvm.struct<(array<2 x i64>, array<3 x i64>)>) {
    %c11_i64 = arith.constant 11 : i64
    %c10_i64 = arith.constant 10 : i64
    %c0_i64 = arith.constant 0 : i64
    %0 = llvm.mlir.poison : !llvm.struct<(array<2 x i64>, array<3 x i64>)>
    %c10 = arith.constant 10 : index
    %1 = builtin.unrealized_conversion_cast %c10 : index to i64
    %2 = llvm.mlir.constant(30 : index) : i64
    %3 = llvm.mlir.constant(1 : index) : i64
    %4 = llvm.mlir.zero : !llvm.ptr
    %5 = llvm.getelementptr %4[30] : (!llvm.ptr) -> !llvm.ptr, f64
    %6 = llvm.ptrtoint %5 : !llvm.ptr to i64
    %7 = llvm.mlir.addressof @__constant_30xf64 : !llvm.ptr
    %8 = llvm.getelementptr %7[0, 0] : (!llvm.ptr) -> !llvm.ptr, !llvm.array<30 x f64>
    %9 = llvm.mlir.constant(3735928559 : index) : i64
    %10 = llvm.inttoptr %9 : i64 to !llvm.ptr
    %11 = llvm.mlir.poison : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %12 = llvm.insertvalue %10, %11[0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %13 = llvm.insertvalue %8, %12[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %14 = llvm.mlir.constant(0 : index) : i64
    %15 = llvm.insertvalue %14, %13[2] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %16 = llvm.insertvalue %2, %15[3, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %17 = llvm.insertvalue %3, %16[4, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %18 = builtin.unrealized_conversion_cast %17 : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> to memref<?xf64>
    %19 = llvm.mlir.constant(11 : index) : i64
    %20 = llvm.mlir.constant(1 : index) : i64
    %21 = llvm.mlir.zero : !llvm.ptr
    %22 = llvm.getelementptr %21[11] : (!llvm.ptr) -> !llvm.ptr, i64
    %23 = llvm.ptrtoint %22 : !llvm.ptr to i64
    %24 = llvm.mlir.addressof @__constant_11xindex : !llvm.ptr
    %25 = llvm.getelementptr %24[0, 0] : (!llvm.ptr) -> !llvm.ptr, !llvm.array<11 x i64>
    %26 = llvm.mlir.constant(3735928559 : index) : i64
    %27 = llvm.inttoptr %26 : i64 to !llvm.ptr
    %28 = llvm.mlir.poison : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %29 = llvm.insertvalue %27, %28[0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %30 = llvm.insertvalue %25, %29[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %31 = llvm.mlir.constant(0 : index) : i64
    %32 = llvm.insertvalue %31, %30[2] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %33 = llvm.insertvalue %19, %32[3, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %34 = llvm.insertvalue %20, %33[4, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %35 = builtin.unrealized_conversion_cast %34 : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> to memref<?xindex>
    %36 = llvm.mlir.constant(30 : index) : i64
    %37 = llvm.mlir.constant(1 : index) : i64
    %38 = llvm.mlir.zero : !llvm.ptr
    %39 = llvm.getelementptr %38[30] : (!llvm.ptr) -> !llvm.ptr, i64
    %40 = llvm.ptrtoint %39 : !llvm.ptr to i64
    %41 = llvm.mlir.addressof @__constant_30xindex : !llvm.ptr
    %42 = llvm.getelementptr %41[0, 0] : (!llvm.ptr) -> !llvm.ptr, !llvm.array<30 x i64>
    %43 = llvm.mlir.constant(3735928559 : index) : i64
    %44 = llvm.inttoptr %43 : i64 to !llvm.ptr
    %45 = llvm.mlir.poison : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %46 = llvm.insertvalue %44, %45[0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %47 = llvm.insertvalue %42, %46[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %48 = llvm.mlir.constant(0 : index) : i64
    %49 = llvm.insertvalue %48, %47[2] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %50 = llvm.insertvalue %36, %49[3, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %51 = llvm.insertvalue %37, %50[4, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %52 = builtin.unrealized_conversion_cast %51 : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> to memref<?xindex>
    %53 = llvm.insertvalue %c0_i64, %0[1, 0] : !llvm.struct<(array<2 x i64>, array<3 x i64>)> 
    %54 = llvm.insertvalue %c0_i64, %53[1, 1] : !llvm.struct<(array<2 x i64>, array<3 x i64>)> 
    %55 = llvm.insertvalue %c0_i64, %54[1, 2] : !llvm.struct<(array<2 x i64>, array<3 x i64>)> 
    %56 = llvm.insertvalue %c10_i64, %55[0, 0] : !llvm.struct<(array<2 x i64>, array<3 x i64>)> 
    %57 = llvm.insertvalue %c10_i64, %56[0, 1] : !llvm.struct<(array<2 x i64>, array<3 x i64>)> 
    %58 = llvm.insertvalue %c11_i64, %57[1, 0] : !llvm.struct<(array<2 x i64>, array<3 x i64>)> 
    %59 = llvm.getelementptr %25[%1] : (!llvm.ptr, i64) -> !llvm.ptr, i64
    %60 = llvm.load %59 : !llvm.ptr -> i64
    %61 = builtin.unrealized_conversion_cast %60 : i64 to index
    %62 = arith.index_cast %61 : index to i64
    %63 = llvm.insertvalue %62, %58[1, 1] : !llvm.struct<(array<2 x i64>, array<3 x i64>)> 
    %64 = arith.index_cast %61 : index to i64
    %65 = llvm.insertvalue %64, %63[1, 2] : !llvm.struct<(array<2 x i64>, array<3 x i64>)> 
    return %35, %52, %18, %65 : memref<?xindex>, memref<?xindex>, memref<?xf64>, !llvm.struct<(array<2 x i64>, array<3 x i64>)>
  }
}


// -----// IR Dump After ConvertMathToLLVMPass (convert-math-to-llvm) //----- //
module {
  llvm.func @printNewline()
  llvm.func @printClose()
  llvm.func @printComma()
  llvm.func @printF64(f64)
  llvm.func @printOpen()
  llvm.mlir.global private constant @__constant_30xindex(dense<[8, 3, 4, 6, 9, 2, 4, 0, 1, 2, 3, 5, 7, 8, 3, 6, 2, 3, 4, 5, 8, 1, 5, 7, 8, 5, 9, 4, 7, 7]> : tensor<30xindex>) {addr_space = 0 : i32, alignment = 64 : i64} : !llvm.array<30 x i64>
  llvm.mlir.global private constant @__constant_11xindex(dense<[0, 1, 5, 7, 14, 16, 21, 25, 27, 29, 30]> : tensor<11xindex>) {addr_space = 0 : i32, alignment = 64 : i64} : !llvm.array<11 x i64>
  llvm.mlir.global private constant @__constant_30xf64(dense<[4.7563469999999999, 2.102859, 5.4238689999999998, 5.577680e+00, 3.001240e-01, 4.8357549999999998, 8.8596050000000002, 1.592490e+00, 7.372070e+00, 7.2462879999999998, 5.9191609999999999, 5.9593920000000002, 4.6956530000000001, 6.328630e-01, 3.1591619999999998, 4.7083050000000002, 8.4356449999999992, 5.4309390000000004, 2.1190630000000001, 1.545420e-01, 2.595040e+00, 1.4655819999999999, 1.321259, 3.702925, 3.542246, 6.831162, 1.723510e+00, 7.8729019999999998, 6.0081550000000004, 1.047045]> : tensor<30xf64>) {addr_space = 0 : i32, alignment = 64 : i64} : !llvm.array<30 x f64>
  llvm.mlir.global private constant @__constant_10x10xf64(dense<[[5.0072820879405331, 2.1420497309468542, 8.4364357946217474, 3.3512684114489364, 4.8578737173077684, 6.5026873298607608, 4.481183080848961, 1.6018142840321781, 1.6482067031075565, 2.7697353449463433], [8.2796435610104453, 9.7956308688691446, 5.066309369035312, 1.0691978274975567, 7.2754747197326219, 7.4679216752662611, 1.8460472498040226, 1.7245060332115747, 9.828847678500983, 5.8523888503628294], [4.735129046344202, 0.21389279999051047, 9.9823910553584571, 0.22751442405574696, 4.3063298537464378, 1.0300462704374436, 7.1885192597496097, 1.7297134743393461, 7.4494154821665912, 8.2180913094628564], [0.55370097211729696, 7.0871105126860554, 7.7450498540614178, 4.2448327660994876, 1.2746000519648371, 9.4391729894286023, 6.1902689198805465, 6.0312877871821424, 8.7890699247898425, 3.1611885774377635], [8.9903796016343396, 3.4471256572948263, 8.4932841564173884, 9.9373309006088171, 2.6191045587156303, 0.77351004199567641, 1.4024547359632467, 7.454551829233095, 2.6194195569905077, 4.0298520046877577], [4.7641019675563543, 3.8129279818642861, 9.0747728919768225, 6.4920816381757511, 6.7882405668469881, 7.0063465072165911, 5.7386637585592792, 7.5230234961300599, 0.91592641387099771, 8.6646639602141899], [5.6862365678538973, 4.8755032417073192, 9.5859588536709328, 8.1186668576209513, 5.3811119011589454, 3.8280043169558411, 9.9983397606134918, 6.1835824149566241, 3.4201107815517515, 0.84968218962971687], [2.791270331453247, 2.9735813587818685, 3.0654358664150494, 5.4929582569491755, 3.9238922832952996, 9.2657934977933269, 5.0681592194030571, 9.6910348814034712, 2.0972430846802959, 0.96789458347651514], [3.1989914495545624, 3.7607248895716507, 5.5182323136835318, 2.4724154287944913, 7.2920674615977124, 9.7009225179758473, 9.9421519655410044, 2.6109645810252315, 9.0484630420475316, 3.6771724535825703], [6.305746358135309, 7.6948754823713771, 3.6012681436537397, 1.263350310992416, 3.8581878444772943, 7.1047027925517909, 2.1904752468927735, 0.32914734762647391, 3.1668377278172235, 2.0518472657841924]]> : tensor<10x10xf64>) {addr_space = 0 : i32, alignment = 64 : i64} : !llvm.array<10 x array<10 x f64>>
  func.func @matmul(%arg0: memref<?xindex>, %arg1: memref<?xindex>, %arg2: memref<?xf64>, %arg3: !llvm.struct<(array<2 x i64>, array<3 x i64>)>, %arg4: tensor<10x10xf64>, %arg5: tensor<10x10xf64>) -> tensor<10x10xf64> {
    %0 = builtin.unrealized_conversion_cast %arg1 : memref<?xindex> to !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %1 = builtin.unrealized_conversion_cast %arg0 : memref<?xindex> to !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %2 = builtin.unrealized_conversion_cast %arg2 : memref<?xf64> to !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %cst = arith.constant dense<[0, 1, 2, 3]> : vector<4xi32>
    %c-1 = arith.constant -1 : index
    %cst_0 = arith.constant dense<0.000000e+00> : vector<4xf64>
    %c4 = arith.constant 4 : index
    %c1 = arith.constant 1 : index
    %c0 = arith.constant 0 : index
    %c10 = arith.constant 10 : index
    %3 = llvm.extractvalue %arg3[1, 2] : !llvm.struct<(array<2 x i64>, array<3 x i64>)> 
    %4 = arith.index_cast %3 : i64 to index
    %5 = builtin.unrealized_conversion_cast %4 : index to i64
    %6 = llvm.extractvalue %2[0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %7 = llvm.extractvalue %2[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %8 = llvm.mlir.poison : !llvm.struct<(ptr, ptr, i64)>
    %9 = llvm.insertvalue %6, %8[0] : !llvm.struct<(ptr, ptr, i64)> 
    %10 = llvm.insertvalue %7, %9[1] : !llvm.struct<(ptr, ptr, i64)> 
    %11 = llvm.mlir.constant(0 : index) : i64
    %12 = llvm.insertvalue %11, %10[2] : !llvm.struct<(ptr, ptr, i64)> 
    %13 = llvm.extractvalue %2[2] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %14 = llvm.extractvalue %2[3, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %15 = llvm.extractvalue %2[4, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %16 = llvm.mlir.poison : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %17 = llvm.insertvalue %6, %16[0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %18 = llvm.insertvalue %7, %17[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %19 = llvm.mlir.constant(0 : index) : i64
    %20 = llvm.insertvalue %19, %18[2] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %21 = llvm.insertvalue %5, %20[3, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %22 = llvm.mlir.constant(1 : index) : i64
    %23 = llvm.insertvalue %22, %21[4, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %24 = bufferization.to_memref %arg4 : tensor<10x10xf64> to memref<10x10xf64>
    %25 = builtin.unrealized_conversion_cast %24 : memref<10x10xf64> to !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)>
    %26 = bufferization.to_memref %arg5 : tensor<10x10xf64> to memref<10x10xf64>
    %27 = builtin.unrealized_conversion_cast %26 : memref<10x10xf64> to !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)>
    %28 = llvm.extractvalue %arg3[1, 0] : !llvm.struct<(array<2 x i64>, array<3 x i64>)> 
    %29 = arith.index_cast %28 : i64 to index
    %30 = builtin.unrealized_conversion_cast %29 : index to i64
    %31 = llvm.extractvalue %1[0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %32 = llvm.extractvalue %1[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %33 = llvm.mlir.poison : !llvm.struct<(ptr, ptr, i64)>
    %34 = llvm.insertvalue %31, %33[0] : !llvm.struct<(ptr, ptr, i64)> 
    %35 = llvm.insertvalue %32, %34[1] : !llvm.struct<(ptr, ptr, i64)> 
    %36 = llvm.mlir.constant(0 : index) : i64
    %37 = llvm.insertvalue %36, %35[2] : !llvm.struct<(ptr, ptr, i64)> 
    %38 = llvm.extractvalue %1[2] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %39 = llvm.extractvalue %1[3, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %40 = llvm.extractvalue %1[4, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %41 = llvm.mlir.poison : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %42 = llvm.insertvalue %31, %41[0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %43 = llvm.insertvalue %32, %42[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %44 = llvm.mlir.constant(0 : index) : i64
    %45 = llvm.insertvalue %44, %43[2] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %46 = llvm.insertvalue %30, %45[3, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %47 = llvm.mlir.constant(1 : index) : i64
    %48 = llvm.insertvalue %47, %46[4, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %49 = llvm.extractvalue %arg3[1, 1] : !llvm.struct<(array<2 x i64>, array<3 x i64>)> 
    %50 = arith.index_cast %49 : i64 to index
    %51 = builtin.unrealized_conversion_cast %50 : index to i64
    %52 = llvm.extractvalue %0[0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %53 = llvm.extractvalue %0[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %54 = llvm.mlir.poison : !llvm.struct<(ptr, ptr, i64)>
    %55 = llvm.insertvalue %52, %54[0] : !llvm.struct<(ptr, ptr, i64)> 
    %56 = llvm.insertvalue %53, %55[1] : !llvm.struct<(ptr, ptr, i64)> 
    %57 = llvm.mlir.constant(0 : index) : i64
    %58 = llvm.insertvalue %57, %56[2] : !llvm.struct<(ptr, ptr, i64)> 
    %59 = llvm.extractvalue %0[2] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %60 = llvm.extractvalue %0[3, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %61 = llvm.extractvalue %0[4, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %62 = llvm.mlir.poison : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %63 = llvm.insertvalue %52, %62[0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %64 = llvm.insertvalue %53, %63[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %65 = llvm.mlir.constant(0 : index) : i64
    %66 = llvm.insertvalue %65, %64[2] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %67 = llvm.insertvalue %51, %66[3, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %68 = llvm.mlir.constant(1 : index) : i64
    %69 = llvm.insertvalue %68, %67[4, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    cf.br ^bb1(%c0 : index)
  ^bb1(%70: index):  // 2 preds: ^bb0, ^bb8
    %71 = builtin.unrealized_conversion_cast %70 : index to i64
    %72 = builtin.unrealized_conversion_cast %70 : index to i64
    %73 = arith.cmpi slt, %70, %c10 : index
    cf.cond_br %73, ^bb2, ^bb9
  ^bb2:  // pred: ^bb1
    %74 = llvm.getelementptr %32[%71] : (!llvm.ptr, i64) -> !llvm.ptr, i64
    %75 = llvm.load %74 : !llvm.ptr -> i64
    %76 = builtin.unrealized_conversion_cast %75 : i64 to index
    %77 = arith.addi %70, %c1 : index
    %78 = builtin.unrealized_conversion_cast %77 : index to i64
    %79 = llvm.getelementptr %32[%78] : (!llvm.ptr, i64) -> !llvm.ptr, i64
    %80 = llvm.load %79 : !llvm.ptr -> i64
    %81 = builtin.unrealized_conversion_cast %80 : i64 to index
    cf.br ^bb3(%76 : index)
  ^bb3(%82: index):  // 2 preds: ^bb2, ^bb7
    %83 = builtin.unrealized_conversion_cast %82 : index to i64
    %84 = arith.cmpi slt, %82, %81 : index
    cf.cond_br %84, ^bb4, ^bb8
  ^bb4:  // pred: ^bb3
    %85 = llvm.getelementptr %53[%83] : (!llvm.ptr, i64) -> !llvm.ptr, i64
    %86 = llvm.load %85 : !llvm.ptr -> i64
    %87 = builtin.unrealized_conversion_cast %86 : i64 to index
    %88 = llvm.getelementptr %7[%83] : (!llvm.ptr, i64) -> !llvm.ptr, f64
    %89 = llvm.load %88 : !llvm.ptr -> f64
    cf.br ^bb5(%c0 : index)
  ^bb5(%90: index):  // 2 preds: ^bb4, ^bb6
    %91 = builtin.unrealized_conversion_cast %90 : index to i64
    %92 = arith.cmpi slt, %90, %c10 : index
    cf.cond_br %92, ^bb6, ^bb7
  ^bb6:  // pred: ^bb5
    %93 = arith.muli %90, %c-1 overflow<nsw> : index
    %94 = arith.addi %93, %c10 : index
    %95 = arith.cmpi slt, %94, %c4 : index
    %96 = arith.select %95, %94, %c4 : index
    %97 = arith.index_cast %96 : index to i32
    %98 = llvm.mlir.poison : vector<4xi32>
    %99 = llvm.mlir.constant(0 : i32) : i32
    %100 = llvm.insertelement %97, %98[%99 : i32] : vector<4xi32>
    %101 = llvm.shufflevector %100, %98 [0, 0, 0, 0] : vector<4xi32> 
    %102 = arith.cmpi sgt, %101, %cst : vector<4xi32>
    %103 = llvm.extractvalue %27[1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %104 = llvm.mlir.constant(10 : index) : i64
    %105 = llvm.mul %72, %104 : i64
    %106 = llvm.add %105, %91 : i64
    %107 = llvm.getelementptr %103[%106] : (!llvm.ptr, i64) -> !llvm.ptr, f64
    %108 = llvm.intr.masked.load %107, %102, %cst_0 {alignment = 8 : i32} : (!llvm.ptr, vector<4xi1>, vector<4xf64>) -> vector<4xf64>
    %109 = llvm.mlir.poison : vector<4xf64>
    %110 = llvm.mlir.constant(0 : i32) : i32
    %111 = llvm.insertelement %89, %109[%110 : i32] : vector<4xf64>
    %112 = llvm.shufflevector %111, %109 [0, 0, 0, 0] : vector<4xf64> 
    %113 = llvm.extractvalue %25[1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %114 = llvm.mlir.constant(10 : index) : i64
    %115 = llvm.mul %86, %114 : i64
    %116 = llvm.add %115, %91 : i64
    %117 = llvm.getelementptr %113[%116] : (!llvm.ptr, i64) -> !llvm.ptr, f64
    %118 = llvm.intr.masked.load %117, %102, %cst_0 {alignment = 8 : i32} : (!llvm.ptr, vector<4xi1>, vector<4xf64>) -> vector<4xf64>
    %119 = arith.mulf %112, %118 : vector<4xf64>
    %120 = arith.addf %108, %119 : vector<4xf64>
    %121 = llvm.extractvalue %27[1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %122 = llvm.mlir.constant(10 : index) : i64
    %123 = llvm.mul %72, %122 : i64
    %124 = llvm.add %123, %91 : i64
    %125 = llvm.getelementptr %121[%124] : (!llvm.ptr, i64) -> !llvm.ptr, f64
    llvm.intr.masked.store %120, %125, %102 {alignment = 8 : i32} : vector<4xf64>, vector<4xi1> into !llvm.ptr
    %126 = arith.addi %90, %c4 : index
    cf.br ^bb5(%126 : index)
  ^bb7:  // pred: ^bb5
    %127 = arith.addi %82, %c1 : index
    cf.br ^bb3(%127 : index)
  ^bb8:  // pred: ^bb3
    %128 = arith.addi %70, %c1 : index
    cf.br ^bb1(%128 : index)
  ^bb9:  // pred: ^bb1
    %129 = bufferization.to_tensor %26 : memref<10x10xf64> to tensor<10x10xf64>
    return %129 : tensor<10x10xf64>
  }
  func.func @main() -> i64 {
    %c9 = arith.constant 9 : index
    %c8 = arith.constant 8 : index
    %cst = arith.constant 0.000000e+00 : f64
    %c1 = arith.constant 1 : index
    %c10 = arith.constant 10 : index
    %c0 = arith.constant 0 : index
    %0 = llvm.mlir.constant(10 : index) : i64
    %1 = llvm.mlir.constant(10 : index) : i64
    %2 = llvm.mlir.constant(1 : index) : i64
    %3 = llvm.mlir.constant(100 : index) : i64
    %4 = llvm.mlir.zero : !llvm.ptr
    %5 = llvm.getelementptr %4[100] : (!llvm.ptr) -> !llvm.ptr, f64
    %6 = llvm.ptrtoint %5 : !llvm.ptr to i64
    %7 = llvm.mlir.addressof @__constant_10x10xf64 : !llvm.ptr
    %8 = llvm.getelementptr %7[0, 0, 0] : (!llvm.ptr) -> !llvm.ptr, !llvm.array<10 x array<10 x f64>>
    %9 = llvm.mlir.constant(3735928559 : index) : i64
    %10 = llvm.inttoptr %9 : i64 to !llvm.ptr
    %11 = llvm.mlir.poison : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)>
    %12 = llvm.insertvalue %10, %11[0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %13 = llvm.insertvalue %8, %12[1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %14 = llvm.mlir.constant(0 : index) : i64
    %15 = llvm.insertvalue %14, %13[2] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %16 = llvm.insertvalue %0, %15[3, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %17 = llvm.insertvalue %1, %16[3, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %18 = llvm.insertvalue %1, %17[4, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %19 = llvm.insertvalue %2, %18[4, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %20 = builtin.unrealized_conversion_cast %19 : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> to memref<10x10xf64>
    %21 = bufferization.to_tensor %20 : memref<10x10xf64> to tensor<10x10xf64>
    %22 = bufferization.alloc_tensor() : tensor<10x10xf64>
    %23:4 = call @assemble_sparse() : () -> (memref<?xindex>, memref<?xindex>, memref<?xf64>, !llvm.struct<(array<2 x i64>, array<3 x i64>)>)
    %24 = call @matmul(%23#0, %23#1, %23#2, %23#3, %21, %22) : (memref<?xindex>, memref<?xindex>, memref<?xf64>, !llvm.struct<(array<2 x i64>, array<3 x i64>)>, tensor<10x10xf64>, tensor<10x10xf64>) -> tensor<10x10xf64>
    cf.br ^bb1(%c0 : index)
  ^bb1(%25: index):  // 2 preds: ^bb0, ^bb7
    %26 = arith.cmpi slt, %25, %c10 : index
    cf.cond_br %26, ^bb2, ^bb8
  ^bb2:  // pred: ^bb1
    %27 = vector.transfer_read %24[%25, %c0], %cst {in_bounds = [true]} : tensor<10x10xf64>, vector<10xf64>
    llvm.call @printOpen() : () -> ()
    cf.br ^bb3(%c0 : index)
  ^bb3(%28: index):  // 2 preds: ^bb2, ^bb6
    %29 = builtin.unrealized_conversion_cast %28 : index to i64
    %30 = arith.cmpi slt, %28, %c10 : index
    cf.cond_br %30, ^bb4, ^bb7
  ^bb4:  // pred: ^bb3
    %31 = llvm.extractelement %27[%29 : i64] : vector<10xf64>
    llvm.call @printF64(%31) : (f64) -> ()
    %32 = arith.cmpi ult, %28, %c9 : index
    cf.cond_br %32, ^bb5, ^bb6
  ^bb5:  // pred: ^bb4
    llvm.call @printComma() : () -> ()
    cf.br ^bb6
  ^bb6:  // 2 preds: ^bb4, ^bb5
    %33 = arith.addi %28, %c1 : index
    cf.br ^bb3(%33 : index)
  ^bb7:  // pred: ^bb3
    llvm.call @printClose() : () -> ()
    llvm.call @printNewline() : () -> ()
    %34 = arith.addi %25, %c1 : index
    cf.br ^bb1(%34 : index)
  ^bb8:  // pred: ^bb1
    %extracted = tensor.extract %24[%c8, %c8] : tensor<10x10xf64>
    %35 = arith.fptosi %extracted : f64 to i64
    return %35 : i64
  }
  func.func @assemble_sparse() -> (memref<?xindex>, memref<?xindex>, memref<?xf64>, !llvm.struct<(array<2 x i64>, array<3 x i64>)>) {
    %c11_i64 = arith.constant 11 : i64
    %c10_i64 = arith.constant 10 : i64
    %c0_i64 = arith.constant 0 : i64
    %0 = llvm.mlir.poison : !llvm.struct<(array<2 x i64>, array<3 x i64>)>
    %c10 = arith.constant 10 : index
    %1 = builtin.unrealized_conversion_cast %c10 : index to i64
    %2 = llvm.mlir.constant(30 : index) : i64
    %3 = llvm.mlir.constant(1 : index) : i64
    %4 = llvm.mlir.zero : !llvm.ptr
    %5 = llvm.getelementptr %4[30] : (!llvm.ptr) -> !llvm.ptr, f64
    %6 = llvm.ptrtoint %5 : !llvm.ptr to i64
    %7 = llvm.mlir.addressof @__constant_30xf64 : !llvm.ptr
    %8 = llvm.getelementptr %7[0, 0] : (!llvm.ptr) -> !llvm.ptr, !llvm.array<30 x f64>
    %9 = llvm.mlir.constant(3735928559 : index) : i64
    %10 = llvm.inttoptr %9 : i64 to !llvm.ptr
    %11 = llvm.mlir.poison : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %12 = llvm.insertvalue %10, %11[0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %13 = llvm.insertvalue %8, %12[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %14 = llvm.mlir.constant(0 : index) : i64
    %15 = llvm.insertvalue %14, %13[2] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %16 = llvm.insertvalue %2, %15[3, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %17 = llvm.insertvalue %3, %16[4, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %18 = builtin.unrealized_conversion_cast %17 : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> to memref<?xf64>
    %19 = llvm.mlir.constant(11 : index) : i64
    %20 = llvm.mlir.constant(1 : index) : i64
    %21 = llvm.mlir.zero : !llvm.ptr
    %22 = llvm.getelementptr %21[11] : (!llvm.ptr) -> !llvm.ptr, i64
    %23 = llvm.ptrtoint %22 : !llvm.ptr to i64
    %24 = llvm.mlir.addressof @__constant_11xindex : !llvm.ptr
    %25 = llvm.getelementptr %24[0, 0] : (!llvm.ptr) -> !llvm.ptr, !llvm.array<11 x i64>
    %26 = llvm.mlir.constant(3735928559 : index) : i64
    %27 = llvm.inttoptr %26 : i64 to !llvm.ptr
    %28 = llvm.mlir.poison : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %29 = llvm.insertvalue %27, %28[0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %30 = llvm.insertvalue %25, %29[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %31 = llvm.mlir.constant(0 : index) : i64
    %32 = llvm.insertvalue %31, %30[2] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %33 = llvm.insertvalue %19, %32[3, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %34 = llvm.insertvalue %20, %33[4, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %35 = builtin.unrealized_conversion_cast %34 : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> to memref<?xindex>
    %36 = llvm.mlir.constant(30 : index) : i64
    %37 = llvm.mlir.constant(1 : index) : i64
    %38 = llvm.mlir.zero : !llvm.ptr
    %39 = llvm.getelementptr %38[30] : (!llvm.ptr) -> !llvm.ptr, i64
    %40 = llvm.ptrtoint %39 : !llvm.ptr to i64
    %41 = llvm.mlir.addressof @__constant_30xindex : !llvm.ptr
    %42 = llvm.getelementptr %41[0, 0] : (!llvm.ptr) -> !llvm.ptr, !llvm.array<30 x i64>
    %43 = llvm.mlir.constant(3735928559 : index) : i64
    %44 = llvm.inttoptr %43 : i64 to !llvm.ptr
    %45 = llvm.mlir.poison : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %46 = llvm.insertvalue %44, %45[0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %47 = llvm.insertvalue %42, %46[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %48 = llvm.mlir.constant(0 : index) : i64
    %49 = llvm.insertvalue %48, %47[2] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %50 = llvm.insertvalue %36, %49[3, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %51 = llvm.insertvalue %37, %50[4, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %52 = builtin.unrealized_conversion_cast %51 : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> to memref<?xindex>
    %53 = llvm.insertvalue %c0_i64, %0[1, 0] : !llvm.struct<(array<2 x i64>, array<3 x i64>)> 
    %54 = llvm.insertvalue %c0_i64, %53[1, 1] : !llvm.struct<(array<2 x i64>, array<3 x i64>)> 
    %55 = llvm.insertvalue %c0_i64, %54[1, 2] : !llvm.struct<(array<2 x i64>, array<3 x i64>)> 
    %56 = llvm.insertvalue %c10_i64, %55[0, 0] : !llvm.struct<(array<2 x i64>, array<3 x i64>)> 
    %57 = llvm.insertvalue %c10_i64, %56[0, 1] : !llvm.struct<(array<2 x i64>, array<3 x i64>)> 
    %58 = llvm.insertvalue %c11_i64, %57[1, 0] : !llvm.struct<(array<2 x i64>, array<3 x i64>)> 
    %59 = llvm.getelementptr %25[%1] : (!llvm.ptr, i64) -> !llvm.ptr, i64
    %60 = llvm.load %59 : !llvm.ptr -> i64
    %61 = builtin.unrealized_conversion_cast %60 : i64 to index
    %62 = arith.index_cast %61 : index to i64
    %63 = llvm.insertvalue %62, %58[1, 1] : !llvm.struct<(array<2 x i64>, array<3 x i64>)> 
    %64 = arith.index_cast %61 : index to i64
    %65 = llvm.insertvalue %64, %63[1, 2] : !llvm.struct<(array<2 x i64>, array<3 x i64>)> 
    return %35, %52, %18, %65 : memref<?xindex>, memref<?xindex>, memref<?xf64>, !llvm.struct<(array<2 x i64>, array<3 x i64>)>
  }
}


// -----// IR Dump After ConvertMathToLibmPass (convert-math-to-libm) //----- //
module {
  llvm.func @printNewline()
  llvm.func @printClose()
  llvm.func @printComma()
  llvm.func @printF64(f64)
  llvm.func @printOpen()
  llvm.mlir.global private constant @__constant_30xindex(dense<[8, 3, 4, 6, 9, 2, 4, 0, 1, 2, 3, 5, 7, 8, 3, 6, 2, 3, 4, 5, 8, 1, 5, 7, 8, 5, 9, 4, 7, 7]> : tensor<30xindex>) {addr_space = 0 : i32, alignment = 64 : i64} : !llvm.array<30 x i64>
  llvm.mlir.global private constant @__constant_11xindex(dense<[0, 1, 5, 7, 14, 16, 21, 25, 27, 29, 30]> : tensor<11xindex>) {addr_space = 0 : i32, alignment = 64 : i64} : !llvm.array<11 x i64>
  llvm.mlir.global private constant @__constant_30xf64(dense<[4.7563469999999999, 2.102859, 5.4238689999999998, 5.577680e+00, 3.001240e-01, 4.8357549999999998, 8.8596050000000002, 1.592490e+00, 7.372070e+00, 7.2462879999999998, 5.9191609999999999, 5.9593920000000002, 4.6956530000000001, 6.328630e-01, 3.1591619999999998, 4.7083050000000002, 8.4356449999999992, 5.4309390000000004, 2.1190630000000001, 1.545420e-01, 2.595040e+00, 1.4655819999999999, 1.321259, 3.702925, 3.542246, 6.831162, 1.723510e+00, 7.8729019999999998, 6.0081550000000004, 1.047045]> : tensor<30xf64>) {addr_space = 0 : i32, alignment = 64 : i64} : !llvm.array<30 x f64>
  llvm.mlir.global private constant @__constant_10x10xf64(dense<[[5.0072820879405331, 2.1420497309468542, 8.4364357946217474, 3.3512684114489364, 4.8578737173077684, 6.5026873298607608, 4.481183080848961, 1.6018142840321781, 1.6482067031075565, 2.7697353449463433], [8.2796435610104453, 9.7956308688691446, 5.066309369035312, 1.0691978274975567, 7.2754747197326219, 7.4679216752662611, 1.8460472498040226, 1.7245060332115747, 9.828847678500983, 5.8523888503628294], [4.735129046344202, 0.21389279999051047, 9.9823910553584571, 0.22751442405574696, 4.3063298537464378, 1.0300462704374436, 7.1885192597496097, 1.7297134743393461, 7.4494154821665912, 8.2180913094628564], [0.55370097211729696, 7.0871105126860554, 7.7450498540614178, 4.2448327660994876, 1.2746000519648371, 9.4391729894286023, 6.1902689198805465, 6.0312877871821424, 8.7890699247898425, 3.1611885774377635], [8.9903796016343396, 3.4471256572948263, 8.4932841564173884, 9.9373309006088171, 2.6191045587156303, 0.77351004199567641, 1.4024547359632467, 7.454551829233095, 2.6194195569905077, 4.0298520046877577], [4.7641019675563543, 3.8129279818642861, 9.0747728919768225, 6.4920816381757511, 6.7882405668469881, 7.0063465072165911, 5.7386637585592792, 7.5230234961300599, 0.91592641387099771, 8.6646639602141899], [5.6862365678538973, 4.8755032417073192, 9.5859588536709328, 8.1186668576209513, 5.3811119011589454, 3.8280043169558411, 9.9983397606134918, 6.1835824149566241, 3.4201107815517515, 0.84968218962971687], [2.791270331453247, 2.9735813587818685, 3.0654358664150494, 5.4929582569491755, 3.9238922832952996, 9.2657934977933269, 5.0681592194030571, 9.6910348814034712, 2.0972430846802959, 0.96789458347651514], [3.1989914495545624, 3.7607248895716507, 5.5182323136835318, 2.4724154287944913, 7.2920674615977124, 9.7009225179758473, 9.9421519655410044, 2.6109645810252315, 9.0484630420475316, 3.6771724535825703], [6.305746358135309, 7.6948754823713771, 3.6012681436537397, 1.263350310992416, 3.8581878444772943, 7.1047027925517909, 2.1904752468927735, 0.32914734762647391, 3.1668377278172235, 2.0518472657841924]]> : tensor<10x10xf64>) {addr_space = 0 : i32, alignment = 64 : i64} : !llvm.array<10 x array<10 x f64>>
  func.func @matmul(%arg0: memref<?xindex>, %arg1: memref<?xindex>, %arg2: memref<?xf64>, %arg3: !llvm.struct<(array<2 x i64>, array<3 x i64>)>, %arg4: tensor<10x10xf64>, %arg5: tensor<10x10xf64>) -> tensor<10x10xf64> {
    %0 = builtin.unrealized_conversion_cast %arg1 : memref<?xindex> to !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %1 = builtin.unrealized_conversion_cast %arg0 : memref<?xindex> to !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %2 = builtin.unrealized_conversion_cast %arg2 : memref<?xf64> to !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %cst = arith.constant dense<[0, 1, 2, 3]> : vector<4xi32>
    %c-1 = arith.constant -1 : index
    %cst_0 = arith.constant dense<0.000000e+00> : vector<4xf64>
    %c4 = arith.constant 4 : index
    %c1 = arith.constant 1 : index
    %c0 = arith.constant 0 : index
    %c10 = arith.constant 10 : index
    %3 = llvm.extractvalue %arg3[1, 2] : !llvm.struct<(array<2 x i64>, array<3 x i64>)> 
    %4 = arith.index_cast %3 : i64 to index
    %5 = builtin.unrealized_conversion_cast %4 : index to i64
    %6 = llvm.extractvalue %2[0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %7 = llvm.extractvalue %2[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %8 = llvm.mlir.poison : !llvm.struct<(ptr, ptr, i64)>
    %9 = llvm.insertvalue %6, %8[0] : !llvm.struct<(ptr, ptr, i64)> 
    %10 = llvm.insertvalue %7, %9[1] : !llvm.struct<(ptr, ptr, i64)> 
    %11 = llvm.mlir.constant(0 : index) : i64
    %12 = llvm.insertvalue %11, %10[2] : !llvm.struct<(ptr, ptr, i64)> 
    %13 = llvm.extractvalue %2[2] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %14 = llvm.extractvalue %2[3, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %15 = llvm.extractvalue %2[4, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %16 = llvm.mlir.poison : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %17 = llvm.insertvalue %6, %16[0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %18 = llvm.insertvalue %7, %17[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %19 = llvm.mlir.constant(0 : index) : i64
    %20 = llvm.insertvalue %19, %18[2] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %21 = llvm.insertvalue %5, %20[3, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %22 = llvm.mlir.constant(1 : index) : i64
    %23 = llvm.insertvalue %22, %21[4, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %24 = bufferization.to_memref %arg4 : tensor<10x10xf64> to memref<10x10xf64>
    %25 = builtin.unrealized_conversion_cast %24 : memref<10x10xf64> to !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)>
    %26 = bufferization.to_memref %arg5 : tensor<10x10xf64> to memref<10x10xf64>
    %27 = builtin.unrealized_conversion_cast %26 : memref<10x10xf64> to !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)>
    %28 = llvm.extractvalue %arg3[1, 0] : !llvm.struct<(array<2 x i64>, array<3 x i64>)> 
    %29 = arith.index_cast %28 : i64 to index
    %30 = builtin.unrealized_conversion_cast %29 : index to i64
    %31 = llvm.extractvalue %1[0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %32 = llvm.extractvalue %1[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %33 = llvm.mlir.poison : !llvm.struct<(ptr, ptr, i64)>
    %34 = llvm.insertvalue %31, %33[0] : !llvm.struct<(ptr, ptr, i64)> 
    %35 = llvm.insertvalue %32, %34[1] : !llvm.struct<(ptr, ptr, i64)> 
    %36 = llvm.mlir.constant(0 : index) : i64
    %37 = llvm.insertvalue %36, %35[2] : !llvm.struct<(ptr, ptr, i64)> 
    %38 = llvm.extractvalue %1[2] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %39 = llvm.extractvalue %1[3, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %40 = llvm.extractvalue %1[4, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %41 = llvm.mlir.poison : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %42 = llvm.insertvalue %31, %41[0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %43 = llvm.insertvalue %32, %42[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %44 = llvm.mlir.constant(0 : index) : i64
    %45 = llvm.insertvalue %44, %43[2] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %46 = llvm.insertvalue %30, %45[3, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %47 = llvm.mlir.constant(1 : index) : i64
    %48 = llvm.insertvalue %47, %46[4, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %49 = llvm.extractvalue %arg3[1, 1] : !llvm.struct<(array<2 x i64>, array<3 x i64>)> 
    %50 = arith.index_cast %49 : i64 to index
    %51 = builtin.unrealized_conversion_cast %50 : index to i64
    %52 = llvm.extractvalue %0[0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %53 = llvm.extractvalue %0[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %54 = llvm.mlir.poison : !llvm.struct<(ptr, ptr, i64)>
    %55 = llvm.insertvalue %52, %54[0] : !llvm.struct<(ptr, ptr, i64)> 
    %56 = llvm.insertvalue %53, %55[1] : !llvm.struct<(ptr, ptr, i64)> 
    %57 = llvm.mlir.constant(0 : index) : i64
    %58 = llvm.insertvalue %57, %56[2] : !llvm.struct<(ptr, ptr, i64)> 
    %59 = llvm.extractvalue %0[2] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %60 = llvm.extractvalue %0[3, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %61 = llvm.extractvalue %0[4, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %62 = llvm.mlir.poison : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %63 = llvm.insertvalue %52, %62[0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %64 = llvm.insertvalue %53, %63[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %65 = llvm.mlir.constant(0 : index) : i64
    %66 = llvm.insertvalue %65, %64[2] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %67 = llvm.insertvalue %51, %66[3, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %68 = llvm.mlir.constant(1 : index) : i64
    %69 = llvm.insertvalue %68, %67[4, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    cf.br ^bb1(%c0 : index)
  ^bb1(%70: index):  // 2 preds: ^bb0, ^bb8
    %71 = builtin.unrealized_conversion_cast %70 : index to i64
    %72 = builtin.unrealized_conversion_cast %70 : index to i64
    %73 = arith.cmpi slt, %70, %c10 : index
    cf.cond_br %73, ^bb2, ^bb9
  ^bb2:  // pred: ^bb1
    %74 = llvm.getelementptr %32[%71] : (!llvm.ptr, i64) -> !llvm.ptr, i64
    %75 = llvm.load %74 : !llvm.ptr -> i64
    %76 = builtin.unrealized_conversion_cast %75 : i64 to index
    %77 = arith.addi %70, %c1 : index
    %78 = builtin.unrealized_conversion_cast %77 : index to i64
    %79 = llvm.getelementptr %32[%78] : (!llvm.ptr, i64) -> !llvm.ptr, i64
    %80 = llvm.load %79 : !llvm.ptr -> i64
    %81 = builtin.unrealized_conversion_cast %80 : i64 to index
    cf.br ^bb3(%76 : index)
  ^bb3(%82: index):  // 2 preds: ^bb2, ^bb7
    %83 = builtin.unrealized_conversion_cast %82 : index to i64
    %84 = arith.cmpi slt, %82, %81 : index
    cf.cond_br %84, ^bb4, ^bb8
  ^bb4:  // pred: ^bb3
    %85 = llvm.getelementptr %53[%83] : (!llvm.ptr, i64) -> !llvm.ptr, i64
    %86 = llvm.load %85 : !llvm.ptr -> i64
    %87 = builtin.unrealized_conversion_cast %86 : i64 to index
    %88 = llvm.getelementptr %7[%83] : (!llvm.ptr, i64) -> !llvm.ptr, f64
    %89 = llvm.load %88 : !llvm.ptr -> f64
    cf.br ^bb5(%c0 : index)
  ^bb5(%90: index):  // 2 preds: ^bb4, ^bb6
    %91 = builtin.unrealized_conversion_cast %90 : index to i64
    %92 = arith.cmpi slt, %90, %c10 : index
    cf.cond_br %92, ^bb6, ^bb7
  ^bb6:  // pred: ^bb5
    %93 = arith.muli %90, %c-1 overflow<nsw> : index
    %94 = arith.addi %93, %c10 : index
    %95 = arith.cmpi slt, %94, %c4 : index
    %96 = arith.select %95, %94, %c4 : index
    %97 = arith.index_cast %96 : index to i32
    %98 = llvm.mlir.poison : vector<4xi32>
    %99 = llvm.mlir.constant(0 : i32) : i32
    %100 = llvm.insertelement %97, %98[%99 : i32] : vector<4xi32>
    %101 = llvm.shufflevector %100, %98 [0, 0, 0, 0] : vector<4xi32> 
    %102 = arith.cmpi sgt, %101, %cst : vector<4xi32>
    %103 = llvm.extractvalue %27[1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %104 = llvm.mlir.constant(10 : index) : i64
    %105 = llvm.mul %72, %104 : i64
    %106 = llvm.add %105, %91 : i64
    %107 = llvm.getelementptr %103[%106] : (!llvm.ptr, i64) -> !llvm.ptr, f64
    %108 = llvm.intr.masked.load %107, %102, %cst_0 {alignment = 8 : i32} : (!llvm.ptr, vector<4xi1>, vector<4xf64>) -> vector<4xf64>
    %109 = llvm.mlir.poison : vector<4xf64>
    %110 = llvm.mlir.constant(0 : i32) : i32
    %111 = llvm.insertelement %89, %109[%110 : i32] : vector<4xf64>
    %112 = llvm.shufflevector %111, %109 [0, 0, 0, 0] : vector<4xf64> 
    %113 = llvm.extractvalue %25[1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %114 = llvm.mlir.constant(10 : index) : i64
    %115 = llvm.mul %86, %114 : i64
    %116 = llvm.add %115, %91 : i64
    %117 = llvm.getelementptr %113[%116] : (!llvm.ptr, i64) -> !llvm.ptr, f64
    %118 = llvm.intr.masked.load %117, %102, %cst_0 {alignment = 8 : i32} : (!llvm.ptr, vector<4xi1>, vector<4xf64>) -> vector<4xf64>
    %119 = arith.mulf %112, %118 : vector<4xf64>
    %120 = arith.addf %108, %119 : vector<4xf64>
    %121 = llvm.extractvalue %27[1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %122 = llvm.mlir.constant(10 : index) : i64
    %123 = llvm.mul %72, %122 : i64
    %124 = llvm.add %123, %91 : i64
    %125 = llvm.getelementptr %121[%124] : (!llvm.ptr, i64) -> !llvm.ptr, f64
    llvm.intr.masked.store %120, %125, %102 {alignment = 8 : i32} : vector<4xf64>, vector<4xi1> into !llvm.ptr
    %126 = arith.addi %90, %c4 : index
    cf.br ^bb5(%126 : index)
  ^bb7:  // pred: ^bb5
    %127 = arith.addi %82, %c1 : index
    cf.br ^bb3(%127 : index)
  ^bb8:  // pred: ^bb3
    %128 = arith.addi %70, %c1 : index
    cf.br ^bb1(%128 : index)
  ^bb9:  // pred: ^bb1
    %129 = bufferization.to_tensor %26 : memref<10x10xf64> to tensor<10x10xf64>
    return %129 : tensor<10x10xf64>
  }
  func.func @main() -> i64 {
    %c9 = arith.constant 9 : index
    %c8 = arith.constant 8 : index
    %cst = arith.constant 0.000000e+00 : f64
    %c1 = arith.constant 1 : index
    %c10 = arith.constant 10 : index
    %c0 = arith.constant 0 : index
    %0 = llvm.mlir.constant(10 : index) : i64
    %1 = llvm.mlir.constant(10 : index) : i64
    %2 = llvm.mlir.constant(1 : index) : i64
    %3 = llvm.mlir.constant(100 : index) : i64
    %4 = llvm.mlir.zero : !llvm.ptr
    %5 = llvm.getelementptr %4[100] : (!llvm.ptr) -> !llvm.ptr, f64
    %6 = llvm.ptrtoint %5 : !llvm.ptr to i64
    %7 = llvm.mlir.addressof @__constant_10x10xf64 : !llvm.ptr
    %8 = llvm.getelementptr %7[0, 0, 0] : (!llvm.ptr) -> !llvm.ptr, !llvm.array<10 x array<10 x f64>>
    %9 = llvm.mlir.constant(3735928559 : index) : i64
    %10 = llvm.inttoptr %9 : i64 to !llvm.ptr
    %11 = llvm.mlir.poison : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)>
    %12 = llvm.insertvalue %10, %11[0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %13 = llvm.insertvalue %8, %12[1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %14 = llvm.mlir.constant(0 : index) : i64
    %15 = llvm.insertvalue %14, %13[2] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %16 = llvm.insertvalue %0, %15[3, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %17 = llvm.insertvalue %1, %16[3, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %18 = llvm.insertvalue %1, %17[4, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %19 = llvm.insertvalue %2, %18[4, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %20 = builtin.unrealized_conversion_cast %19 : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> to memref<10x10xf64>
    %21 = bufferization.to_tensor %20 : memref<10x10xf64> to tensor<10x10xf64>
    %22 = bufferization.alloc_tensor() : tensor<10x10xf64>
    %23:4 = call @assemble_sparse() : () -> (memref<?xindex>, memref<?xindex>, memref<?xf64>, !llvm.struct<(array<2 x i64>, array<3 x i64>)>)
    %24 = call @matmul(%23#0, %23#1, %23#2, %23#3, %21, %22) : (memref<?xindex>, memref<?xindex>, memref<?xf64>, !llvm.struct<(array<2 x i64>, array<3 x i64>)>, tensor<10x10xf64>, tensor<10x10xf64>) -> tensor<10x10xf64>
    cf.br ^bb1(%c0 : index)
  ^bb1(%25: index):  // 2 preds: ^bb0, ^bb7
    %26 = arith.cmpi slt, %25, %c10 : index
    cf.cond_br %26, ^bb2, ^bb8
  ^bb2:  // pred: ^bb1
    %27 = vector.transfer_read %24[%25, %c0], %cst {in_bounds = [true]} : tensor<10x10xf64>, vector<10xf64>
    llvm.call @printOpen() : () -> ()
    cf.br ^bb3(%c0 : index)
  ^bb3(%28: index):  // 2 preds: ^bb2, ^bb6
    %29 = builtin.unrealized_conversion_cast %28 : index to i64
    %30 = arith.cmpi slt, %28, %c10 : index
    cf.cond_br %30, ^bb4, ^bb7
  ^bb4:  // pred: ^bb3
    %31 = llvm.extractelement %27[%29 : i64] : vector<10xf64>
    llvm.call @printF64(%31) : (f64) -> ()
    %32 = arith.cmpi ult, %28, %c9 : index
    cf.cond_br %32, ^bb5, ^bb6
  ^bb5:  // pred: ^bb4
    llvm.call @printComma() : () -> ()
    cf.br ^bb6
  ^bb6:  // 2 preds: ^bb4, ^bb5
    %33 = arith.addi %28, %c1 : index
    cf.br ^bb3(%33 : index)
  ^bb7:  // pred: ^bb3
    llvm.call @printClose() : () -> ()
    llvm.call @printNewline() : () -> ()
    %34 = arith.addi %25, %c1 : index
    cf.br ^bb1(%34 : index)
  ^bb8:  // pred: ^bb1
    %extracted = tensor.extract %24[%c8, %c8] : tensor<10x10xf64>
    %35 = arith.fptosi %extracted : f64 to i64
    return %35 : i64
  }
  func.func @assemble_sparse() -> (memref<?xindex>, memref<?xindex>, memref<?xf64>, !llvm.struct<(array<2 x i64>, array<3 x i64>)>) {
    %c11_i64 = arith.constant 11 : i64
    %c10_i64 = arith.constant 10 : i64
    %c0_i64 = arith.constant 0 : i64
    %0 = llvm.mlir.poison : !llvm.struct<(array<2 x i64>, array<3 x i64>)>
    %c10 = arith.constant 10 : index
    %1 = builtin.unrealized_conversion_cast %c10 : index to i64
    %2 = llvm.mlir.constant(30 : index) : i64
    %3 = llvm.mlir.constant(1 : index) : i64
    %4 = llvm.mlir.zero : !llvm.ptr
    %5 = llvm.getelementptr %4[30] : (!llvm.ptr) -> !llvm.ptr, f64
    %6 = llvm.ptrtoint %5 : !llvm.ptr to i64
    %7 = llvm.mlir.addressof @__constant_30xf64 : !llvm.ptr
    %8 = llvm.getelementptr %7[0, 0] : (!llvm.ptr) -> !llvm.ptr, !llvm.array<30 x f64>
    %9 = llvm.mlir.constant(3735928559 : index) : i64
    %10 = llvm.inttoptr %9 : i64 to !llvm.ptr
    %11 = llvm.mlir.poison : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %12 = llvm.insertvalue %10, %11[0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %13 = llvm.insertvalue %8, %12[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %14 = llvm.mlir.constant(0 : index) : i64
    %15 = llvm.insertvalue %14, %13[2] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %16 = llvm.insertvalue %2, %15[3, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %17 = llvm.insertvalue %3, %16[4, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %18 = builtin.unrealized_conversion_cast %17 : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> to memref<?xf64>
    %19 = llvm.mlir.constant(11 : index) : i64
    %20 = llvm.mlir.constant(1 : index) : i64
    %21 = llvm.mlir.zero : !llvm.ptr
    %22 = llvm.getelementptr %21[11] : (!llvm.ptr) -> !llvm.ptr, i64
    %23 = llvm.ptrtoint %22 : !llvm.ptr to i64
    %24 = llvm.mlir.addressof @__constant_11xindex : !llvm.ptr
    %25 = llvm.getelementptr %24[0, 0] : (!llvm.ptr) -> !llvm.ptr, !llvm.array<11 x i64>
    %26 = llvm.mlir.constant(3735928559 : index) : i64
    %27 = llvm.inttoptr %26 : i64 to !llvm.ptr
    %28 = llvm.mlir.poison : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %29 = llvm.insertvalue %27, %28[0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %30 = llvm.insertvalue %25, %29[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %31 = llvm.mlir.constant(0 : index) : i64
    %32 = llvm.insertvalue %31, %30[2] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %33 = llvm.insertvalue %19, %32[3, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %34 = llvm.insertvalue %20, %33[4, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %35 = builtin.unrealized_conversion_cast %34 : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> to memref<?xindex>
    %36 = llvm.mlir.constant(30 : index) : i64
    %37 = llvm.mlir.constant(1 : index) : i64
    %38 = llvm.mlir.zero : !llvm.ptr
    %39 = llvm.getelementptr %38[30] : (!llvm.ptr) -> !llvm.ptr, i64
    %40 = llvm.ptrtoint %39 : !llvm.ptr to i64
    %41 = llvm.mlir.addressof @__constant_30xindex : !llvm.ptr
    %42 = llvm.getelementptr %41[0, 0] : (!llvm.ptr) -> !llvm.ptr, !llvm.array<30 x i64>
    %43 = llvm.mlir.constant(3735928559 : index) : i64
    %44 = llvm.inttoptr %43 : i64 to !llvm.ptr
    %45 = llvm.mlir.poison : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %46 = llvm.insertvalue %44, %45[0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %47 = llvm.insertvalue %42, %46[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %48 = llvm.mlir.constant(0 : index) : i64
    %49 = llvm.insertvalue %48, %47[2] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %50 = llvm.insertvalue %36, %49[3, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %51 = llvm.insertvalue %37, %50[4, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %52 = builtin.unrealized_conversion_cast %51 : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> to memref<?xindex>
    %53 = llvm.insertvalue %c0_i64, %0[1, 0] : !llvm.struct<(array<2 x i64>, array<3 x i64>)> 
    %54 = llvm.insertvalue %c0_i64, %53[1, 1] : !llvm.struct<(array<2 x i64>, array<3 x i64>)> 
    %55 = llvm.insertvalue %c0_i64, %54[1, 2] : !llvm.struct<(array<2 x i64>, array<3 x i64>)> 
    %56 = llvm.insertvalue %c10_i64, %55[0, 0] : !llvm.struct<(array<2 x i64>, array<3 x i64>)> 
    %57 = llvm.insertvalue %c10_i64, %56[0, 1] : !llvm.struct<(array<2 x i64>, array<3 x i64>)> 
    %58 = llvm.insertvalue %c11_i64, %57[1, 0] : !llvm.struct<(array<2 x i64>, array<3 x i64>)> 
    %59 = llvm.getelementptr %25[%1] : (!llvm.ptr, i64) -> !llvm.ptr, i64
    %60 = llvm.load %59 : !llvm.ptr -> i64
    %61 = builtin.unrealized_conversion_cast %60 : i64 to index
    %62 = arith.index_cast %61 : index to i64
    %63 = llvm.insertvalue %62, %58[1, 1] : !llvm.struct<(array<2 x i64>, array<3 x i64>)> 
    %64 = arith.index_cast %61 : index to i64
    %65 = llvm.insertvalue %64, %63[1, 2] : !llvm.struct<(array<2 x i64>, array<3 x i64>)> 
    return %35, %52, %18, %65 : memref<?xindex>, memref<?xindex>, memref<?xf64>, !llvm.struct<(array<2 x i64>, array<3 x i64>)>
  }
}


// -----// IR Dump After ConvertComplexToLibm (convert-complex-to-libm) //----- //
module {
  llvm.func @printNewline()
  llvm.func @printClose()
  llvm.func @printComma()
  llvm.func @printF64(f64)
  llvm.func @printOpen()
  llvm.mlir.global private constant @__constant_30xindex(dense<[8, 3, 4, 6, 9, 2, 4, 0, 1, 2, 3, 5, 7, 8, 3, 6, 2, 3, 4, 5, 8, 1, 5, 7, 8, 5, 9, 4, 7, 7]> : tensor<30xindex>) {addr_space = 0 : i32, alignment = 64 : i64} : !llvm.array<30 x i64>
  llvm.mlir.global private constant @__constant_11xindex(dense<[0, 1, 5, 7, 14, 16, 21, 25, 27, 29, 30]> : tensor<11xindex>) {addr_space = 0 : i32, alignment = 64 : i64} : !llvm.array<11 x i64>
  llvm.mlir.global private constant @__constant_30xf64(dense<[4.7563469999999999, 2.102859, 5.4238689999999998, 5.577680e+00, 3.001240e-01, 4.8357549999999998, 8.8596050000000002, 1.592490e+00, 7.372070e+00, 7.2462879999999998, 5.9191609999999999, 5.9593920000000002, 4.6956530000000001, 6.328630e-01, 3.1591619999999998, 4.7083050000000002, 8.4356449999999992, 5.4309390000000004, 2.1190630000000001, 1.545420e-01, 2.595040e+00, 1.4655819999999999, 1.321259, 3.702925, 3.542246, 6.831162, 1.723510e+00, 7.8729019999999998, 6.0081550000000004, 1.047045]> : tensor<30xf64>) {addr_space = 0 : i32, alignment = 64 : i64} : !llvm.array<30 x f64>
  llvm.mlir.global private constant @__constant_10x10xf64(dense<[[5.0072820879405331, 2.1420497309468542, 8.4364357946217474, 3.3512684114489364, 4.8578737173077684, 6.5026873298607608, 4.481183080848961, 1.6018142840321781, 1.6482067031075565, 2.7697353449463433], [8.2796435610104453, 9.7956308688691446, 5.066309369035312, 1.0691978274975567, 7.2754747197326219, 7.4679216752662611, 1.8460472498040226, 1.7245060332115747, 9.828847678500983, 5.8523888503628294], [4.735129046344202, 0.21389279999051047, 9.9823910553584571, 0.22751442405574696, 4.3063298537464378, 1.0300462704374436, 7.1885192597496097, 1.7297134743393461, 7.4494154821665912, 8.2180913094628564], [0.55370097211729696, 7.0871105126860554, 7.7450498540614178, 4.2448327660994876, 1.2746000519648371, 9.4391729894286023, 6.1902689198805465, 6.0312877871821424, 8.7890699247898425, 3.1611885774377635], [8.9903796016343396, 3.4471256572948263, 8.4932841564173884, 9.9373309006088171, 2.6191045587156303, 0.77351004199567641, 1.4024547359632467, 7.454551829233095, 2.6194195569905077, 4.0298520046877577], [4.7641019675563543, 3.8129279818642861, 9.0747728919768225, 6.4920816381757511, 6.7882405668469881, 7.0063465072165911, 5.7386637585592792, 7.5230234961300599, 0.91592641387099771, 8.6646639602141899], [5.6862365678538973, 4.8755032417073192, 9.5859588536709328, 8.1186668576209513, 5.3811119011589454, 3.8280043169558411, 9.9983397606134918, 6.1835824149566241, 3.4201107815517515, 0.84968218962971687], [2.791270331453247, 2.9735813587818685, 3.0654358664150494, 5.4929582569491755, 3.9238922832952996, 9.2657934977933269, 5.0681592194030571, 9.6910348814034712, 2.0972430846802959, 0.96789458347651514], [3.1989914495545624, 3.7607248895716507, 5.5182323136835318, 2.4724154287944913, 7.2920674615977124, 9.7009225179758473, 9.9421519655410044, 2.6109645810252315, 9.0484630420475316, 3.6771724535825703], [6.305746358135309, 7.6948754823713771, 3.6012681436537397, 1.263350310992416, 3.8581878444772943, 7.1047027925517909, 2.1904752468927735, 0.32914734762647391, 3.1668377278172235, 2.0518472657841924]]> : tensor<10x10xf64>) {addr_space = 0 : i32, alignment = 64 : i64} : !llvm.array<10 x array<10 x f64>>
  func.func @matmul(%arg0: memref<?xindex>, %arg1: memref<?xindex>, %arg2: memref<?xf64>, %arg3: !llvm.struct<(array<2 x i64>, array<3 x i64>)>, %arg4: tensor<10x10xf64>, %arg5: tensor<10x10xf64>) -> tensor<10x10xf64> {
    %0 = builtin.unrealized_conversion_cast %arg1 : memref<?xindex> to !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %1 = builtin.unrealized_conversion_cast %arg0 : memref<?xindex> to !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %2 = builtin.unrealized_conversion_cast %arg2 : memref<?xf64> to !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %cst = arith.constant dense<[0, 1, 2, 3]> : vector<4xi32>
    %c-1 = arith.constant -1 : index
    %cst_0 = arith.constant dense<0.000000e+00> : vector<4xf64>
    %c4 = arith.constant 4 : index
    %c1 = arith.constant 1 : index
    %c0 = arith.constant 0 : index
    %c10 = arith.constant 10 : index
    %3 = llvm.extractvalue %arg3[1, 2] : !llvm.struct<(array<2 x i64>, array<3 x i64>)> 
    %4 = arith.index_cast %3 : i64 to index
    %5 = builtin.unrealized_conversion_cast %4 : index to i64
    %6 = llvm.extractvalue %2[0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %7 = llvm.extractvalue %2[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %8 = llvm.mlir.poison : !llvm.struct<(ptr, ptr, i64)>
    %9 = llvm.insertvalue %6, %8[0] : !llvm.struct<(ptr, ptr, i64)> 
    %10 = llvm.insertvalue %7, %9[1] : !llvm.struct<(ptr, ptr, i64)> 
    %11 = llvm.mlir.constant(0 : index) : i64
    %12 = llvm.insertvalue %11, %10[2] : !llvm.struct<(ptr, ptr, i64)> 
    %13 = llvm.extractvalue %2[2] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %14 = llvm.extractvalue %2[3, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %15 = llvm.extractvalue %2[4, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %16 = llvm.mlir.poison : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %17 = llvm.insertvalue %6, %16[0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %18 = llvm.insertvalue %7, %17[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %19 = llvm.mlir.constant(0 : index) : i64
    %20 = llvm.insertvalue %19, %18[2] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %21 = llvm.insertvalue %5, %20[3, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %22 = llvm.mlir.constant(1 : index) : i64
    %23 = llvm.insertvalue %22, %21[4, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %24 = bufferization.to_memref %arg4 : tensor<10x10xf64> to memref<10x10xf64>
    %25 = builtin.unrealized_conversion_cast %24 : memref<10x10xf64> to !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)>
    %26 = bufferization.to_memref %arg5 : tensor<10x10xf64> to memref<10x10xf64>
    %27 = builtin.unrealized_conversion_cast %26 : memref<10x10xf64> to !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)>
    %28 = llvm.extractvalue %arg3[1, 0] : !llvm.struct<(array<2 x i64>, array<3 x i64>)> 
    %29 = arith.index_cast %28 : i64 to index
    %30 = builtin.unrealized_conversion_cast %29 : index to i64
    %31 = llvm.extractvalue %1[0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %32 = llvm.extractvalue %1[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %33 = llvm.mlir.poison : !llvm.struct<(ptr, ptr, i64)>
    %34 = llvm.insertvalue %31, %33[0] : !llvm.struct<(ptr, ptr, i64)> 
    %35 = llvm.insertvalue %32, %34[1] : !llvm.struct<(ptr, ptr, i64)> 
    %36 = llvm.mlir.constant(0 : index) : i64
    %37 = llvm.insertvalue %36, %35[2] : !llvm.struct<(ptr, ptr, i64)> 
    %38 = llvm.extractvalue %1[2] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %39 = llvm.extractvalue %1[3, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %40 = llvm.extractvalue %1[4, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %41 = llvm.mlir.poison : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %42 = llvm.insertvalue %31, %41[0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %43 = llvm.insertvalue %32, %42[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %44 = llvm.mlir.constant(0 : index) : i64
    %45 = llvm.insertvalue %44, %43[2] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %46 = llvm.insertvalue %30, %45[3, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %47 = llvm.mlir.constant(1 : index) : i64
    %48 = llvm.insertvalue %47, %46[4, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %49 = llvm.extractvalue %arg3[1, 1] : !llvm.struct<(array<2 x i64>, array<3 x i64>)> 
    %50 = arith.index_cast %49 : i64 to index
    %51 = builtin.unrealized_conversion_cast %50 : index to i64
    %52 = llvm.extractvalue %0[0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %53 = llvm.extractvalue %0[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %54 = llvm.mlir.poison : !llvm.struct<(ptr, ptr, i64)>
    %55 = llvm.insertvalue %52, %54[0] : !llvm.struct<(ptr, ptr, i64)> 
    %56 = llvm.insertvalue %53, %55[1] : !llvm.struct<(ptr, ptr, i64)> 
    %57 = llvm.mlir.constant(0 : index) : i64
    %58 = llvm.insertvalue %57, %56[2] : !llvm.struct<(ptr, ptr, i64)> 
    %59 = llvm.extractvalue %0[2] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %60 = llvm.extractvalue %0[3, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %61 = llvm.extractvalue %0[4, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %62 = llvm.mlir.poison : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %63 = llvm.insertvalue %52, %62[0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %64 = llvm.insertvalue %53, %63[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %65 = llvm.mlir.constant(0 : index) : i64
    %66 = llvm.insertvalue %65, %64[2] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %67 = llvm.insertvalue %51, %66[3, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %68 = llvm.mlir.constant(1 : index) : i64
    %69 = llvm.insertvalue %68, %67[4, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    cf.br ^bb1(%c0 : index)
  ^bb1(%70: index):  // 2 preds: ^bb0, ^bb8
    %71 = builtin.unrealized_conversion_cast %70 : index to i64
    %72 = builtin.unrealized_conversion_cast %70 : index to i64
    %73 = arith.cmpi slt, %70, %c10 : index
    cf.cond_br %73, ^bb2, ^bb9
  ^bb2:  // pred: ^bb1
    %74 = llvm.getelementptr %32[%71] : (!llvm.ptr, i64) -> !llvm.ptr, i64
    %75 = llvm.load %74 : !llvm.ptr -> i64
    %76 = builtin.unrealized_conversion_cast %75 : i64 to index
    %77 = arith.addi %70, %c1 : index
    %78 = builtin.unrealized_conversion_cast %77 : index to i64
    %79 = llvm.getelementptr %32[%78] : (!llvm.ptr, i64) -> !llvm.ptr, i64
    %80 = llvm.load %79 : !llvm.ptr -> i64
    %81 = builtin.unrealized_conversion_cast %80 : i64 to index
    cf.br ^bb3(%76 : index)
  ^bb3(%82: index):  // 2 preds: ^bb2, ^bb7
    %83 = builtin.unrealized_conversion_cast %82 : index to i64
    %84 = arith.cmpi slt, %82, %81 : index
    cf.cond_br %84, ^bb4, ^bb8
  ^bb4:  // pred: ^bb3
    %85 = llvm.getelementptr %53[%83] : (!llvm.ptr, i64) -> !llvm.ptr, i64
    %86 = llvm.load %85 : !llvm.ptr -> i64
    %87 = builtin.unrealized_conversion_cast %86 : i64 to index
    %88 = llvm.getelementptr %7[%83] : (!llvm.ptr, i64) -> !llvm.ptr, f64
    %89 = llvm.load %88 : !llvm.ptr -> f64
    cf.br ^bb5(%c0 : index)
  ^bb5(%90: index):  // 2 preds: ^bb4, ^bb6
    %91 = builtin.unrealized_conversion_cast %90 : index to i64
    %92 = arith.cmpi slt, %90, %c10 : index
    cf.cond_br %92, ^bb6, ^bb7
  ^bb6:  // pred: ^bb5
    %93 = arith.muli %90, %c-1 overflow<nsw> : index
    %94 = arith.addi %93, %c10 : index
    %95 = arith.cmpi slt, %94, %c4 : index
    %96 = arith.select %95, %94, %c4 : index
    %97 = arith.index_cast %96 : index to i32
    %98 = llvm.mlir.poison : vector<4xi32>
    %99 = llvm.mlir.constant(0 : i32) : i32
    %100 = llvm.insertelement %97, %98[%99 : i32] : vector<4xi32>
    %101 = llvm.shufflevector %100, %98 [0, 0, 0, 0] : vector<4xi32> 
    %102 = arith.cmpi sgt, %101, %cst : vector<4xi32>
    %103 = llvm.extractvalue %27[1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %104 = llvm.mlir.constant(10 : index) : i64
    %105 = llvm.mul %72, %104 : i64
    %106 = llvm.add %105, %91 : i64
    %107 = llvm.getelementptr %103[%106] : (!llvm.ptr, i64) -> !llvm.ptr, f64
    %108 = llvm.intr.masked.load %107, %102, %cst_0 {alignment = 8 : i32} : (!llvm.ptr, vector<4xi1>, vector<4xf64>) -> vector<4xf64>
    %109 = llvm.mlir.poison : vector<4xf64>
    %110 = llvm.mlir.constant(0 : i32) : i32
    %111 = llvm.insertelement %89, %109[%110 : i32] : vector<4xf64>
    %112 = llvm.shufflevector %111, %109 [0, 0, 0, 0] : vector<4xf64> 
    %113 = llvm.extractvalue %25[1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %114 = llvm.mlir.constant(10 : index) : i64
    %115 = llvm.mul %86, %114 : i64
    %116 = llvm.add %115, %91 : i64
    %117 = llvm.getelementptr %113[%116] : (!llvm.ptr, i64) -> !llvm.ptr, f64
    %118 = llvm.intr.masked.load %117, %102, %cst_0 {alignment = 8 : i32} : (!llvm.ptr, vector<4xi1>, vector<4xf64>) -> vector<4xf64>
    %119 = arith.mulf %112, %118 : vector<4xf64>
    %120 = arith.addf %108, %119 : vector<4xf64>
    %121 = llvm.extractvalue %27[1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %122 = llvm.mlir.constant(10 : index) : i64
    %123 = llvm.mul %72, %122 : i64
    %124 = llvm.add %123, %91 : i64
    %125 = llvm.getelementptr %121[%124] : (!llvm.ptr, i64) -> !llvm.ptr, f64
    llvm.intr.masked.store %120, %125, %102 {alignment = 8 : i32} : vector<4xf64>, vector<4xi1> into !llvm.ptr
    %126 = arith.addi %90, %c4 : index
    cf.br ^bb5(%126 : index)
  ^bb7:  // pred: ^bb5
    %127 = arith.addi %82, %c1 : index
    cf.br ^bb3(%127 : index)
  ^bb8:  // pred: ^bb3
    %128 = arith.addi %70, %c1 : index
    cf.br ^bb1(%128 : index)
  ^bb9:  // pred: ^bb1
    %129 = bufferization.to_tensor %26 : memref<10x10xf64> to tensor<10x10xf64>
    return %129 : tensor<10x10xf64>
  }
  func.func @main() -> i64 {
    %c9 = arith.constant 9 : index
    %c8 = arith.constant 8 : index
    %cst = arith.constant 0.000000e+00 : f64
    %c1 = arith.constant 1 : index
    %c10 = arith.constant 10 : index
    %c0 = arith.constant 0 : index
    %0 = llvm.mlir.constant(10 : index) : i64
    %1 = llvm.mlir.constant(10 : index) : i64
    %2 = llvm.mlir.constant(1 : index) : i64
    %3 = llvm.mlir.constant(100 : index) : i64
    %4 = llvm.mlir.zero : !llvm.ptr
    %5 = llvm.getelementptr %4[100] : (!llvm.ptr) -> !llvm.ptr, f64
    %6 = llvm.ptrtoint %5 : !llvm.ptr to i64
    %7 = llvm.mlir.addressof @__constant_10x10xf64 : !llvm.ptr
    %8 = llvm.getelementptr %7[0, 0, 0] : (!llvm.ptr) -> !llvm.ptr, !llvm.array<10 x array<10 x f64>>
    %9 = llvm.mlir.constant(3735928559 : index) : i64
    %10 = llvm.inttoptr %9 : i64 to !llvm.ptr
    %11 = llvm.mlir.poison : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)>
    %12 = llvm.insertvalue %10, %11[0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %13 = llvm.insertvalue %8, %12[1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %14 = llvm.mlir.constant(0 : index) : i64
    %15 = llvm.insertvalue %14, %13[2] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %16 = llvm.insertvalue %0, %15[3, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %17 = llvm.insertvalue %1, %16[3, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %18 = llvm.insertvalue %1, %17[4, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %19 = llvm.insertvalue %2, %18[4, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %20 = builtin.unrealized_conversion_cast %19 : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> to memref<10x10xf64>
    %21 = bufferization.to_tensor %20 : memref<10x10xf64> to tensor<10x10xf64>
    %22 = bufferization.alloc_tensor() : tensor<10x10xf64>
    %23:4 = call @assemble_sparse() : () -> (memref<?xindex>, memref<?xindex>, memref<?xf64>, !llvm.struct<(array<2 x i64>, array<3 x i64>)>)
    %24 = call @matmul(%23#0, %23#1, %23#2, %23#3, %21, %22) : (memref<?xindex>, memref<?xindex>, memref<?xf64>, !llvm.struct<(array<2 x i64>, array<3 x i64>)>, tensor<10x10xf64>, tensor<10x10xf64>) -> tensor<10x10xf64>
    cf.br ^bb1(%c0 : index)
  ^bb1(%25: index):  // 2 preds: ^bb0, ^bb7
    %26 = arith.cmpi slt, %25, %c10 : index
    cf.cond_br %26, ^bb2, ^bb8
  ^bb2:  // pred: ^bb1
    %27 = vector.transfer_read %24[%25, %c0], %cst {in_bounds = [true]} : tensor<10x10xf64>, vector<10xf64>
    llvm.call @printOpen() : () -> ()
    cf.br ^bb3(%c0 : index)
  ^bb3(%28: index):  // 2 preds: ^bb2, ^bb6
    %29 = builtin.unrealized_conversion_cast %28 : index to i64
    %30 = arith.cmpi slt, %28, %c10 : index
    cf.cond_br %30, ^bb4, ^bb7
  ^bb4:  // pred: ^bb3
    %31 = llvm.extractelement %27[%29 : i64] : vector<10xf64>
    llvm.call @printF64(%31) : (f64) -> ()
    %32 = arith.cmpi ult, %28, %c9 : index
    cf.cond_br %32, ^bb5, ^bb6
  ^bb5:  // pred: ^bb4
    llvm.call @printComma() : () -> ()
    cf.br ^bb6
  ^bb6:  // 2 preds: ^bb4, ^bb5
    %33 = arith.addi %28, %c1 : index
    cf.br ^bb3(%33 : index)
  ^bb7:  // pred: ^bb3
    llvm.call @printClose() : () -> ()
    llvm.call @printNewline() : () -> ()
    %34 = arith.addi %25, %c1 : index
    cf.br ^bb1(%34 : index)
  ^bb8:  // pred: ^bb1
    %extracted = tensor.extract %24[%c8, %c8] : tensor<10x10xf64>
    %35 = arith.fptosi %extracted : f64 to i64
    return %35 : i64
  }
  func.func @assemble_sparse() -> (memref<?xindex>, memref<?xindex>, memref<?xf64>, !llvm.struct<(array<2 x i64>, array<3 x i64>)>) {
    %c11_i64 = arith.constant 11 : i64
    %c10_i64 = arith.constant 10 : i64
    %c0_i64 = arith.constant 0 : i64
    %0 = llvm.mlir.poison : !llvm.struct<(array<2 x i64>, array<3 x i64>)>
    %c10 = arith.constant 10 : index
    %1 = builtin.unrealized_conversion_cast %c10 : index to i64
    %2 = llvm.mlir.constant(30 : index) : i64
    %3 = llvm.mlir.constant(1 : index) : i64
    %4 = llvm.mlir.zero : !llvm.ptr
    %5 = llvm.getelementptr %4[30] : (!llvm.ptr) -> !llvm.ptr, f64
    %6 = llvm.ptrtoint %5 : !llvm.ptr to i64
    %7 = llvm.mlir.addressof @__constant_30xf64 : !llvm.ptr
    %8 = llvm.getelementptr %7[0, 0] : (!llvm.ptr) -> !llvm.ptr, !llvm.array<30 x f64>
    %9 = llvm.mlir.constant(3735928559 : index) : i64
    %10 = llvm.inttoptr %9 : i64 to !llvm.ptr
    %11 = llvm.mlir.poison : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %12 = llvm.insertvalue %10, %11[0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %13 = llvm.insertvalue %8, %12[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %14 = llvm.mlir.constant(0 : index) : i64
    %15 = llvm.insertvalue %14, %13[2] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %16 = llvm.insertvalue %2, %15[3, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %17 = llvm.insertvalue %3, %16[4, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %18 = builtin.unrealized_conversion_cast %17 : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> to memref<?xf64>
    %19 = llvm.mlir.constant(11 : index) : i64
    %20 = llvm.mlir.constant(1 : index) : i64
    %21 = llvm.mlir.zero : !llvm.ptr
    %22 = llvm.getelementptr %21[11] : (!llvm.ptr) -> !llvm.ptr, i64
    %23 = llvm.ptrtoint %22 : !llvm.ptr to i64
    %24 = llvm.mlir.addressof @__constant_11xindex : !llvm.ptr
    %25 = llvm.getelementptr %24[0, 0] : (!llvm.ptr) -> !llvm.ptr, !llvm.array<11 x i64>
    %26 = llvm.mlir.constant(3735928559 : index) : i64
    %27 = llvm.inttoptr %26 : i64 to !llvm.ptr
    %28 = llvm.mlir.poison : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %29 = llvm.insertvalue %27, %28[0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %30 = llvm.insertvalue %25, %29[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %31 = llvm.mlir.constant(0 : index) : i64
    %32 = llvm.insertvalue %31, %30[2] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %33 = llvm.insertvalue %19, %32[3, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %34 = llvm.insertvalue %20, %33[4, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %35 = builtin.unrealized_conversion_cast %34 : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> to memref<?xindex>
    %36 = llvm.mlir.constant(30 : index) : i64
    %37 = llvm.mlir.constant(1 : index) : i64
    %38 = llvm.mlir.zero : !llvm.ptr
    %39 = llvm.getelementptr %38[30] : (!llvm.ptr) -> !llvm.ptr, i64
    %40 = llvm.ptrtoint %39 : !llvm.ptr to i64
    %41 = llvm.mlir.addressof @__constant_30xindex : !llvm.ptr
    %42 = llvm.getelementptr %41[0, 0] : (!llvm.ptr) -> !llvm.ptr, !llvm.array<30 x i64>
    %43 = llvm.mlir.constant(3735928559 : index) : i64
    %44 = llvm.inttoptr %43 : i64 to !llvm.ptr
    %45 = llvm.mlir.poison : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %46 = llvm.insertvalue %44, %45[0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %47 = llvm.insertvalue %42, %46[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %48 = llvm.mlir.constant(0 : index) : i64
    %49 = llvm.insertvalue %48, %47[2] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %50 = llvm.insertvalue %36, %49[3, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %51 = llvm.insertvalue %37, %50[4, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %52 = builtin.unrealized_conversion_cast %51 : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> to memref<?xindex>
    %53 = llvm.insertvalue %c0_i64, %0[1, 0] : !llvm.struct<(array<2 x i64>, array<3 x i64>)> 
    %54 = llvm.insertvalue %c0_i64, %53[1, 1] : !llvm.struct<(array<2 x i64>, array<3 x i64>)> 
    %55 = llvm.insertvalue %c0_i64, %54[1, 2] : !llvm.struct<(array<2 x i64>, array<3 x i64>)> 
    %56 = llvm.insertvalue %c10_i64, %55[0, 0] : !llvm.struct<(array<2 x i64>, array<3 x i64>)> 
    %57 = llvm.insertvalue %c10_i64, %56[0, 1] : !llvm.struct<(array<2 x i64>, array<3 x i64>)> 
    %58 = llvm.insertvalue %c11_i64, %57[1, 0] : !llvm.struct<(array<2 x i64>, array<3 x i64>)> 
    %59 = llvm.getelementptr %25[%1] : (!llvm.ptr, i64) -> !llvm.ptr, i64
    %60 = llvm.load %59 : !llvm.ptr -> i64
    %61 = builtin.unrealized_conversion_cast %60 : i64 to index
    %62 = arith.index_cast %61 : index to i64
    %63 = llvm.insertvalue %62, %58[1, 1] : !llvm.struct<(array<2 x i64>, array<3 x i64>)> 
    %64 = arith.index_cast %61 : index to i64
    %65 = llvm.insertvalue %64, %63[1, 2] : !llvm.struct<(array<2 x i64>, array<3 x i64>)> 
    return %35, %52, %18, %65 : memref<?xindex>, memref<?xindex>, memref<?xf64>, !llvm.struct<(array<2 x i64>, array<3 x i64>)>
  }
}


// -----// IR Dump After ConvertVectorToLLVMPass (convert-vector-to-llvm) //----- //
module {
  llvm.func @printNewline()
  llvm.func @printClose()
  llvm.func @printComma()
  llvm.func @printF64(f64)
  llvm.func @printOpen()
  llvm.mlir.global private constant @__constant_30xindex(dense<[8, 3, 4, 6, 9, 2, 4, 0, 1, 2, 3, 5, 7, 8, 3, 6, 2, 3, 4, 5, 8, 1, 5, 7, 8, 5, 9, 4, 7, 7]> : tensor<30xindex>) {addr_space = 0 : i32, alignment = 64 : i64} : !llvm.array<30 x i64>
  llvm.mlir.global private constant @__constant_11xindex(dense<[0, 1, 5, 7, 14, 16, 21, 25, 27, 29, 30]> : tensor<11xindex>) {addr_space = 0 : i32, alignment = 64 : i64} : !llvm.array<11 x i64>
  llvm.mlir.global private constant @__constant_30xf64(dense<[4.7563469999999999, 2.102859, 5.4238689999999998, 5.577680e+00, 3.001240e-01, 4.8357549999999998, 8.8596050000000002, 1.592490e+00, 7.372070e+00, 7.2462879999999998, 5.9191609999999999, 5.9593920000000002, 4.6956530000000001, 6.328630e-01, 3.1591619999999998, 4.7083050000000002, 8.4356449999999992, 5.4309390000000004, 2.1190630000000001, 1.545420e-01, 2.595040e+00, 1.4655819999999999, 1.321259, 3.702925, 3.542246, 6.831162, 1.723510e+00, 7.8729019999999998, 6.0081550000000004, 1.047045]> : tensor<30xf64>) {addr_space = 0 : i32, alignment = 64 : i64} : !llvm.array<30 x f64>
  llvm.mlir.global private constant @__constant_10x10xf64(dense<[[5.0072820879405331, 2.1420497309468542, 8.4364357946217474, 3.3512684114489364, 4.8578737173077684, 6.5026873298607608, 4.481183080848961, 1.6018142840321781, 1.6482067031075565, 2.7697353449463433], [8.2796435610104453, 9.7956308688691446, 5.066309369035312, 1.0691978274975567, 7.2754747197326219, 7.4679216752662611, 1.8460472498040226, 1.7245060332115747, 9.828847678500983, 5.8523888503628294], [4.735129046344202, 0.21389279999051047, 9.9823910553584571, 0.22751442405574696, 4.3063298537464378, 1.0300462704374436, 7.1885192597496097, 1.7297134743393461, 7.4494154821665912, 8.2180913094628564], [0.55370097211729696, 7.0871105126860554, 7.7450498540614178, 4.2448327660994876, 1.2746000519648371, 9.4391729894286023, 6.1902689198805465, 6.0312877871821424, 8.7890699247898425, 3.1611885774377635], [8.9903796016343396, 3.4471256572948263, 8.4932841564173884, 9.9373309006088171, 2.6191045587156303, 0.77351004199567641, 1.4024547359632467, 7.454551829233095, 2.6194195569905077, 4.0298520046877577], [4.7641019675563543, 3.8129279818642861, 9.0747728919768225, 6.4920816381757511, 6.7882405668469881, 7.0063465072165911, 5.7386637585592792, 7.5230234961300599, 0.91592641387099771, 8.6646639602141899], [5.6862365678538973, 4.8755032417073192, 9.5859588536709328, 8.1186668576209513, 5.3811119011589454, 3.8280043169558411, 9.9983397606134918, 6.1835824149566241, 3.4201107815517515, 0.84968218962971687], [2.791270331453247, 2.9735813587818685, 3.0654358664150494, 5.4929582569491755, 3.9238922832952996, 9.2657934977933269, 5.0681592194030571, 9.6910348814034712, 2.0972430846802959, 0.96789458347651514], [3.1989914495545624, 3.7607248895716507, 5.5182323136835318, 2.4724154287944913, 7.2920674615977124, 9.7009225179758473, 9.9421519655410044, 2.6109645810252315, 9.0484630420475316, 3.6771724535825703], [6.305746358135309, 7.6948754823713771, 3.6012681436537397, 1.263350310992416, 3.8581878444772943, 7.1047027925517909, 2.1904752468927735, 0.32914734762647391, 3.1668377278172235, 2.0518472657841924]]> : tensor<10x10xf64>) {addr_space = 0 : i32, alignment = 64 : i64} : !llvm.array<10 x array<10 x f64>>
  func.func @matmul(%arg0: memref<?xindex>, %arg1: memref<?xindex>, %arg2: memref<?xf64>, %arg3: !llvm.struct<(array<2 x i64>, array<3 x i64>)>, %arg4: tensor<10x10xf64>, %arg5: tensor<10x10xf64>) -> tensor<10x10xf64> {
    %0 = llvm.mlir.poison : vector<4xf64>
    %1 = llvm.mlir.constant(10 : index) : i64
    %2 = llvm.mlir.constant(0 : i32) : i32
    %3 = llvm.mlir.poison : vector<4xi32>
    %c10 = arith.constant 10 : index
    %c0 = arith.constant 0 : index
    %c1 = arith.constant 1 : index
    %c4 = arith.constant 4 : index
    %cst = arith.constant dense<0.000000e+00> : vector<4xf64>
    %c-1 = arith.constant -1 : index
    %cst_0 = arith.constant dense<[0, 1, 2, 3]> : vector<4xi32>
    %4 = builtin.unrealized_conversion_cast %arg1 : memref<?xindex> to !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %5 = builtin.unrealized_conversion_cast %arg0 : memref<?xindex> to !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %6 = builtin.unrealized_conversion_cast %arg2 : memref<?xf64> to !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %7 = llvm.extractvalue %6[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %8 = bufferization.to_memref %arg4 : tensor<10x10xf64> to memref<10x10xf64>
    %9 = builtin.unrealized_conversion_cast %8 : memref<10x10xf64> to !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)>
    %10 = bufferization.to_memref %arg5 : tensor<10x10xf64> to memref<10x10xf64>
    %11 = builtin.unrealized_conversion_cast %10 : memref<10x10xf64> to !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)>
    %12 = llvm.extractvalue %5[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %13 = llvm.extractvalue %4[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    cf.br ^bb1(%c0 : index)
  ^bb1(%14: index):  // 2 preds: ^bb0, ^bb8
    %15 = builtin.unrealized_conversion_cast %14 : index to i64
    %16 = builtin.unrealized_conversion_cast %14 : index to i64
    %17 = arith.cmpi slt, %14, %c10 : index
    cf.cond_br %17, ^bb2, ^bb9
  ^bb2:  // pred: ^bb1
    %18 = llvm.getelementptr %12[%15] : (!llvm.ptr, i64) -> !llvm.ptr, i64
    %19 = llvm.load %18 : !llvm.ptr -> i64
    %20 = builtin.unrealized_conversion_cast %19 : i64 to index
    %21 = arith.addi %14, %c1 : index
    %22 = builtin.unrealized_conversion_cast %21 : index to i64
    %23 = llvm.getelementptr %12[%22] : (!llvm.ptr, i64) -> !llvm.ptr, i64
    %24 = llvm.load %23 : !llvm.ptr -> i64
    %25 = builtin.unrealized_conversion_cast %24 : i64 to index
    cf.br ^bb3(%20 : index)
  ^bb3(%26: index):  // 2 preds: ^bb2, ^bb7
    %27 = builtin.unrealized_conversion_cast %26 : index to i64
    %28 = arith.cmpi slt, %26, %25 : index
    cf.cond_br %28, ^bb4, ^bb8
  ^bb4:  // pred: ^bb3
    %29 = llvm.getelementptr %13[%27] : (!llvm.ptr, i64) -> !llvm.ptr, i64
    %30 = llvm.load %29 : !llvm.ptr -> i64
    %31 = llvm.getelementptr %7[%27] : (!llvm.ptr, i64) -> !llvm.ptr, f64
    %32 = llvm.load %31 : !llvm.ptr -> f64
    cf.br ^bb5(%c0 : index)
  ^bb5(%33: index):  // 2 preds: ^bb4, ^bb6
    %34 = builtin.unrealized_conversion_cast %33 : index to i64
    %35 = arith.cmpi slt, %33, %c10 : index
    cf.cond_br %35, ^bb6, ^bb7
  ^bb6:  // pred: ^bb5
    %36 = arith.muli %33, %c-1 overflow<nsw> : index
    %37 = arith.addi %36, %c10 : index
    %38 = arith.cmpi slt, %37, %c4 : index
    %39 = arith.select %38, %37, %c4 : index
    %40 = arith.index_cast %39 : index to i32
    %41 = llvm.insertelement %40, %3[%2 : i32] : vector<4xi32>
    %42 = llvm.shufflevector %41, %3 [0, 0, 0, 0] : vector<4xi32> 
    %43 = arith.cmpi sgt, %42, %cst_0 : vector<4xi32>
    %44 = llvm.extractvalue %11[1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %45 = llvm.mul %16, %1 : i64
    %46 = llvm.add %45, %34 : i64
    %47 = llvm.getelementptr %44[%46] : (!llvm.ptr, i64) -> !llvm.ptr, f64
    %48 = llvm.intr.masked.load %47, %43, %cst {alignment = 8 : i32} : (!llvm.ptr, vector<4xi1>, vector<4xf64>) -> vector<4xf64>
    %49 = llvm.insertelement %32, %0[%2 : i32] : vector<4xf64>
    %50 = llvm.shufflevector %49, %0 [0, 0, 0, 0] : vector<4xf64> 
    %51 = llvm.extractvalue %9[1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %52 = llvm.mul %30, %1 : i64
    %53 = llvm.add %52, %34 : i64
    %54 = llvm.getelementptr %51[%53] : (!llvm.ptr, i64) -> !llvm.ptr, f64
    %55 = llvm.intr.masked.load %54, %43, %cst {alignment = 8 : i32} : (!llvm.ptr, vector<4xi1>, vector<4xf64>) -> vector<4xf64>
    %56 = arith.mulf %50, %55 : vector<4xf64>
    %57 = arith.addf %48, %56 : vector<4xf64>
    %58 = llvm.extractvalue %11[1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %59 = llvm.mul %16, %1 : i64
    %60 = llvm.add %59, %34 : i64
    %61 = llvm.getelementptr %58[%60] : (!llvm.ptr, i64) -> !llvm.ptr, f64
    llvm.intr.masked.store %57, %61, %43 {alignment = 8 : i32} : vector<4xf64>, vector<4xi1> into !llvm.ptr
    %62 = arith.addi %33, %c4 : index
    cf.br ^bb5(%62 : index)
  ^bb7:  // pred: ^bb5
    %63 = arith.addi %26, %c1 : index
    cf.br ^bb3(%63 : index)
  ^bb8:  // pred: ^bb3
    %64 = arith.addi %14, %c1 : index
    cf.br ^bb1(%64 : index)
  ^bb9:  // pred: ^bb1
    %65 = bufferization.to_tensor %10 : memref<10x10xf64> to tensor<10x10xf64>
    return %65 : tensor<10x10xf64>
  }
  func.func @main() -> i64 {
    %0 = llvm.mlir.constant(0 : index) : i64
    %1 = llvm.mlir.poison : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)>
    %2 = llvm.mlir.constant(3735928559 : index) : i64
    %3 = llvm.mlir.addressof @__constant_10x10xf64 : !llvm.ptr
    %c9 = arith.constant 9 : index
    %c8 = arith.constant 8 : index
    %cst = arith.constant 0.000000e+00 : f64
    %c1 = arith.constant 1 : index
    %c10 = arith.constant 10 : index
    %c0 = arith.constant 0 : index
    %4 = llvm.mlir.constant(10 : index) : i64
    %5 = llvm.mlir.constant(1 : index) : i64
    %6 = llvm.getelementptr %3[0, 0, 0] : (!llvm.ptr) -> !llvm.ptr, !llvm.array<10 x array<10 x f64>>
    %7 = llvm.inttoptr %2 : i64 to !llvm.ptr
    %8 = llvm.insertvalue %7, %1[0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %9 = llvm.insertvalue %6, %8[1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %10 = llvm.insertvalue %0, %9[2] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %11 = llvm.insertvalue %4, %10[3, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %12 = llvm.insertvalue %4, %11[3, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %13 = llvm.insertvalue %4, %12[4, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %14 = llvm.insertvalue %5, %13[4, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %15 = builtin.unrealized_conversion_cast %14 : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> to memref<10x10xf64>
    %16 = bufferization.to_tensor %15 : memref<10x10xf64> to tensor<10x10xf64>
    %17 = bufferization.alloc_tensor() : tensor<10x10xf64>
    %18:4 = call @assemble_sparse() : () -> (memref<?xindex>, memref<?xindex>, memref<?xf64>, !llvm.struct<(array<2 x i64>, array<3 x i64>)>)
    %19 = call @matmul(%18#0, %18#1, %18#2, %18#3, %16, %17) : (memref<?xindex>, memref<?xindex>, memref<?xf64>, !llvm.struct<(array<2 x i64>, array<3 x i64>)>, tensor<10x10xf64>, tensor<10x10xf64>) -> tensor<10x10xf64>
    cf.br ^bb1(%c0 : index)
  ^bb1(%20: index):  // 2 preds: ^bb0, ^bb7
    %21 = arith.cmpi slt, %20, %c10 : index
    cf.cond_br %21, ^bb2, ^bb8
  ^bb2:  // pred: ^bb1
    %22 = vector.transfer_read %19[%20, %c0], %cst {in_bounds = [true]} : tensor<10x10xf64>, vector<10xf64>
    llvm.call @printOpen() : () -> ()
    cf.br ^bb3(%c0 : index)
  ^bb3(%23: index):  // 2 preds: ^bb2, ^bb6
    %24 = builtin.unrealized_conversion_cast %23 : index to i64
    %25 = arith.cmpi slt, %23, %c10 : index
    cf.cond_br %25, ^bb4, ^bb7
  ^bb4:  // pred: ^bb3
    %26 = llvm.extractelement %22[%24 : i64] : vector<10xf64>
    llvm.call @printF64(%26) : (f64) -> ()
    %27 = arith.cmpi ult, %23, %c9 : index
    cf.cond_br %27, ^bb5, ^bb6
  ^bb5:  // pred: ^bb4
    llvm.call @printComma() : () -> ()
    cf.br ^bb6
  ^bb6:  // 2 preds: ^bb4, ^bb5
    %28 = arith.addi %23, %c1 : index
    cf.br ^bb3(%28 : index)
  ^bb7:  // pred: ^bb3
    llvm.call @printClose() : () -> ()
    llvm.call @printNewline() : () -> ()
    %29 = arith.addi %20, %c1 : index
    cf.br ^bb1(%29 : index)
  ^bb8:  // pred: ^bb1
    %extracted = tensor.extract %19[%c8, %c8] : tensor<10x10xf64>
    %30 = arith.fptosi %extracted : f64 to i64
    return %30 : i64
  }
  func.func @assemble_sparse() -> (memref<?xindex>, memref<?xindex>, memref<?xf64>, !llvm.struct<(array<2 x i64>, array<3 x i64>)>) {
    %0 = llvm.mlir.addressof @__constant_30xindex : !llvm.ptr
    %1 = llvm.mlir.addressof @__constant_11xindex : !llvm.ptr
    %2 = llvm.mlir.constant(11 : index) : i64
    %3 = llvm.mlir.constant(0 : index) : i64
    %4 = llvm.mlir.poison : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %5 = llvm.mlir.constant(3735928559 : index) : i64
    %6 = llvm.mlir.addressof @__constant_30xf64 : !llvm.ptr
    %7 = llvm.mlir.constant(1 : index) : i64
    %8 = llvm.mlir.constant(30 : index) : i64
    %c11_i64 = arith.constant 11 : i64
    %c10_i64 = arith.constant 10 : i64
    %c0_i64 = arith.constant 0 : i64
    %9 = llvm.mlir.poison : !llvm.struct<(array<2 x i64>, array<3 x i64>)>
    %c10 = arith.constant 10 : index
    %10 = builtin.unrealized_conversion_cast %c10 : index to i64
    %11 = llvm.getelementptr %6[0, 0] : (!llvm.ptr) -> !llvm.ptr, !llvm.array<30 x f64>
    %12 = llvm.inttoptr %5 : i64 to !llvm.ptr
    %13 = llvm.insertvalue %12, %4[0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %14 = llvm.insertvalue %11, %13[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %15 = llvm.insertvalue %3, %14[2] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %16 = llvm.insertvalue %8, %15[3, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %17 = llvm.insertvalue %7, %16[4, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %18 = builtin.unrealized_conversion_cast %17 : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> to memref<?xf64>
    %19 = llvm.getelementptr %1[0, 0] : (!llvm.ptr) -> !llvm.ptr, !llvm.array<11 x i64>
    %20 = llvm.inttoptr %5 : i64 to !llvm.ptr
    %21 = llvm.insertvalue %20, %4[0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %22 = llvm.insertvalue %19, %21[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %23 = llvm.insertvalue %3, %22[2] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %24 = llvm.insertvalue %2, %23[3, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %25 = llvm.insertvalue %7, %24[4, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %26 = builtin.unrealized_conversion_cast %25 : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> to memref<?xindex>
    %27 = llvm.getelementptr %0[0, 0] : (!llvm.ptr) -> !llvm.ptr, !llvm.array<30 x i64>
    %28 = llvm.inttoptr %5 : i64 to !llvm.ptr
    %29 = llvm.insertvalue %28, %4[0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %30 = llvm.insertvalue %27, %29[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %31 = llvm.insertvalue %3, %30[2] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %32 = llvm.insertvalue %8, %31[3, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %33 = llvm.insertvalue %7, %32[4, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %34 = builtin.unrealized_conversion_cast %33 : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> to memref<?xindex>
    %35 = llvm.insertvalue %c0_i64, %9[1, 0] : !llvm.struct<(array<2 x i64>, array<3 x i64>)> 
    %36 = llvm.insertvalue %c0_i64, %35[1, 1] : !llvm.struct<(array<2 x i64>, array<3 x i64>)> 
    %37 = llvm.insertvalue %c0_i64, %36[1, 2] : !llvm.struct<(array<2 x i64>, array<3 x i64>)> 
    %38 = llvm.insertvalue %c10_i64, %37[0, 0] : !llvm.struct<(array<2 x i64>, array<3 x i64>)> 
    %39 = llvm.insertvalue %c10_i64, %38[0, 1] : !llvm.struct<(array<2 x i64>, array<3 x i64>)> 
    %40 = llvm.insertvalue %c11_i64, %39[1, 0] : !llvm.struct<(array<2 x i64>, array<3 x i64>)> 
    %41 = llvm.getelementptr %19[%10] : (!llvm.ptr, i64) -> !llvm.ptr, i64
    %42 = llvm.load %41 : !llvm.ptr -> i64
    %43 = builtin.unrealized_conversion_cast %42 : i64 to index
    %44 = arith.index_cast %43 : index to i64
    %45 = llvm.insertvalue %44, %40[1, 1] : !llvm.struct<(array<2 x i64>, array<3 x i64>)> 
    %46 = arith.index_cast %43 : index to i64
    %47 = llvm.insertvalue %46, %45[1, 2] : !llvm.struct<(array<2 x i64>, array<3 x i64>)> 
    return %26, %34, %18, %47 : memref<?xindex>, memref<?xindex>, memref<?xf64>, !llvm.struct<(array<2 x i64>, array<3 x i64>)>
  }
}


// -----// IR Dump After ConvertComplexToLLVMPass (convert-complex-to-llvm) //----- //
module {
  llvm.func @printNewline()
  llvm.func @printClose()
  llvm.func @printComma()
  llvm.func @printF64(f64)
  llvm.func @printOpen()
  llvm.mlir.global private constant @__constant_30xindex(dense<[8, 3, 4, 6, 9, 2, 4, 0, 1, 2, 3, 5, 7, 8, 3, 6, 2, 3, 4, 5, 8, 1, 5, 7, 8, 5, 9, 4, 7, 7]> : tensor<30xindex>) {addr_space = 0 : i32, alignment = 64 : i64} : !llvm.array<30 x i64>
  llvm.mlir.global private constant @__constant_11xindex(dense<[0, 1, 5, 7, 14, 16, 21, 25, 27, 29, 30]> : tensor<11xindex>) {addr_space = 0 : i32, alignment = 64 : i64} : !llvm.array<11 x i64>
  llvm.mlir.global private constant @__constant_30xf64(dense<[4.7563469999999999, 2.102859, 5.4238689999999998, 5.577680e+00, 3.001240e-01, 4.8357549999999998, 8.8596050000000002, 1.592490e+00, 7.372070e+00, 7.2462879999999998, 5.9191609999999999, 5.9593920000000002, 4.6956530000000001, 6.328630e-01, 3.1591619999999998, 4.7083050000000002, 8.4356449999999992, 5.4309390000000004, 2.1190630000000001, 1.545420e-01, 2.595040e+00, 1.4655819999999999, 1.321259, 3.702925, 3.542246, 6.831162, 1.723510e+00, 7.8729019999999998, 6.0081550000000004, 1.047045]> : tensor<30xf64>) {addr_space = 0 : i32, alignment = 64 : i64} : !llvm.array<30 x f64>
  llvm.mlir.global private constant @__constant_10x10xf64(dense<[[5.0072820879405331, 2.1420497309468542, 8.4364357946217474, 3.3512684114489364, 4.8578737173077684, 6.5026873298607608, 4.481183080848961, 1.6018142840321781, 1.6482067031075565, 2.7697353449463433], [8.2796435610104453, 9.7956308688691446, 5.066309369035312, 1.0691978274975567, 7.2754747197326219, 7.4679216752662611, 1.8460472498040226, 1.7245060332115747, 9.828847678500983, 5.8523888503628294], [4.735129046344202, 0.21389279999051047, 9.9823910553584571, 0.22751442405574696, 4.3063298537464378, 1.0300462704374436, 7.1885192597496097, 1.7297134743393461, 7.4494154821665912, 8.2180913094628564], [0.55370097211729696, 7.0871105126860554, 7.7450498540614178, 4.2448327660994876, 1.2746000519648371, 9.4391729894286023, 6.1902689198805465, 6.0312877871821424, 8.7890699247898425, 3.1611885774377635], [8.9903796016343396, 3.4471256572948263, 8.4932841564173884, 9.9373309006088171, 2.6191045587156303, 0.77351004199567641, 1.4024547359632467, 7.454551829233095, 2.6194195569905077, 4.0298520046877577], [4.7641019675563543, 3.8129279818642861, 9.0747728919768225, 6.4920816381757511, 6.7882405668469881, 7.0063465072165911, 5.7386637585592792, 7.5230234961300599, 0.91592641387099771, 8.6646639602141899], [5.6862365678538973, 4.8755032417073192, 9.5859588536709328, 8.1186668576209513, 5.3811119011589454, 3.8280043169558411, 9.9983397606134918, 6.1835824149566241, 3.4201107815517515, 0.84968218962971687], [2.791270331453247, 2.9735813587818685, 3.0654358664150494, 5.4929582569491755, 3.9238922832952996, 9.2657934977933269, 5.0681592194030571, 9.6910348814034712, 2.0972430846802959, 0.96789458347651514], [3.1989914495545624, 3.7607248895716507, 5.5182323136835318, 2.4724154287944913, 7.2920674615977124, 9.7009225179758473, 9.9421519655410044, 2.6109645810252315, 9.0484630420475316, 3.6771724535825703], [6.305746358135309, 7.6948754823713771, 3.6012681436537397, 1.263350310992416, 3.8581878444772943, 7.1047027925517909, 2.1904752468927735, 0.32914734762647391, 3.1668377278172235, 2.0518472657841924]]> : tensor<10x10xf64>) {addr_space = 0 : i32, alignment = 64 : i64} : !llvm.array<10 x array<10 x f64>>
  func.func @matmul(%arg0: memref<?xindex>, %arg1: memref<?xindex>, %arg2: memref<?xf64>, %arg3: !llvm.struct<(array<2 x i64>, array<3 x i64>)>, %arg4: tensor<10x10xf64>, %arg5: tensor<10x10xf64>) -> tensor<10x10xf64> {
    %0 = llvm.mlir.poison : vector<4xf64>
    %1 = llvm.mlir.constant(10 : index) : i64
    %2 = llvm.mlir.constant(0 : i32) : i32
    %3 = llvm.mlir.poison : vector<4xi32>
    %c10 = arith.constant 10 : index
    %c0 = arith.constant 0 : index
    %c1 = arith.constant 1 : index
    %c4 = arith.constant 4 : index
    %cst = arith.constant dense<0.000000e+00> : vector<4xf64>
    %c-1 = arith.constant -1 : index
    %cst_0 = arith.constant dense<[0, 1, 2, 3]> : vector<4xi32>
    %4 = builtin.unrealized_conversion_cast %arg1 : memref<?xindex> to !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %5 = builtin.unrealized_conversion_cast %arg0 : memref<?xindex> to !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %6 = builtin.unrealized_conversion_cast %arg2 : memref<?xf64> to !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %7 = llvm.extractvalue %6[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %8 = bufferization.to_memref %arg4 : tensor<10x10xf64> to memref<10x10xf64>
    %9 = builtin.unrealized_conversion_cast %8 : memref<10x10xf64> to !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)>
    %10 = bufferization.to_memref %arg5 : tensor<10x10xf64> to memref<10x10xf64>
    %11 = builtin.unrealized_conversion_cast %10 : memref<10x10xf64> to !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)>
    %12 = llvm.extractvalue %5[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %13 = llvm.extractvalue %4[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    cf.br ^bb1(%c0 : index)
  ^bb1(%14: index):  // 2 preds: ^bb0, ^bb8
    %15 = builtin.unrealized_conversion_cast %14 : index to i64
    %16 = builtin.unrealized_conversion_cast %14 : index to i64
    %17 = arith.cmpi slt, %14, %c10 : index
    cf.cond_br %17, ^bb2, ^bb9
  ^bb2:  // pred: ^bb1
    %18 = llvm.getelementptr %12[%15] : (!llvm.ptr, i64) -> !llvm.ptr, i64
    %19 = llvm.load %18 : !llvm.ptr -> i64
    %20 = builtin.unrealized_conversion_cast %19 : i64 to index
    %21 = arith.addi %14, %c1 : index
    %22 = builtin.unrealized_conversion_cast %21 : index to i64
    %23 = llvm.getelementptr %12[%22] : (!llvm.ptr, i64) -> !llvm.ptr, i64
    %24 = llvm.load %23 : !llvm.ptr -> i64
    %25 = builtin.unrealized_conversion_cast %24 : i64 to index
    cf.br ^bb3(%20 : index)
  ^bb3(%26: index):  // 2 preds: ^bb2, ^bb7
    %27 = builtin.unrealized_conversion_cast %26 : index to i64
    %28 = arith.cmpi slt, %26, %25 : index
    cf.cond_br %28, ^bb4, ^bb8
  ^bb4:  // pred: ^bb3
    %29 = llvm.getelementptr %13[%27] : (!llvm.ptr, i64) -> !llvm.ptr, i64
    %30 = llvm.load %29 : !llvm.ptr -> i64
    %31 = llvm.getelementptr %7[%27] : (!llvm.ptr, i64) -> !llvm.ptr, f64
    %32 = llvm.load %31 : !llvm.ptr -> f64
    cf.br ^bb5(%c0 : index)
  ^bb5(%33: index):  // 2 preds: ^bb4, ^bb6
    %34 = builtin.unrealized_conversion_cast %33 : index to i64
    %35 = arith.cmpi slt, %33, %c10 : index
    cf.cond_br %35, ^bb6, ^bb7
  ^bb6:  // pred: ^bb5
    %36 = arith.muli %33, %c-1 overflow<nsw> : index
    %37 = arith.addi %36, %c10 : index
    %38 = arith.cmpi slt, %37, %c4 : index
    %39 = arith.select %38, %37, %c4 : index
    %40 = arith.index_cast %39 : index to i32
    %41 = llvm.insertelement %40, %3[%2 : i32] : vector<4xi32>
    %42 = llvm.shufflevector %41, %3 [0, 0, 0, 0] : vector<4xi32> 
    %43 = arith.cmpi sgt, %42, %cst_0 : vector<4xi32>
    %44 = llvm.extractvalue %11[1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %45 = llvm.mul %16, %1 : i64
    %46 = llvm.add %45, %34 : i64
    %47 = llvm.getelementptr %44[%46] : (!llvm.ptr, i64) -> !llvm.ptr, f64
    %48 = llvm.intr.masked.load %47, %43, %cst {alignment = 8 : i32} : (!llvm.ptr, vector<4xi1>, vector<4xf64>) -> vector<4xf64>
    %49 = llvm.insertelement %32, %0[%2 : i32] : vector<4xf64>
    %50 = llvm.shufflevector %49, %0 [0, 0, 0, 0] : vector<4xf64> 
    %51 = llvm.extractvalue %9[1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %52 = llvm.mul %30, %1 : i64
    %53 = llvm.add %52, %34 : i64
    %54 = llvm.getelementptr %51[%53] : (!llvm.ptr, i64) -> !llvm.ptr, f64
    %55 = llvm.intr.masked.load %54, %43, %cst {alignment = 8 : i32} : (!llvm.ptr, vector<4xi1>, vector<4xf64>) -> vector<4xf64>
    %56 = arith.mulf %50, %55 : vector<4xf64>
    %57 = arith.addf %48, %56 : vector<4xf64>
    %58 = llvm.extractvalue %11[1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %59 = llvm.mul %16, %1 : i64
    %60 = llvm.add %59, %34 : i64
    %61 = llvm.getelementptr %58[%60] : (!llvm.ptr, i64) -> !llvm.ptr, f64
    llvm.intr.masked.store %57, %61, %43 {alignment = 8 : i32} : vector<4xf64>, vector<4xi1> into !llvm.ptr
    %62 = arith.addi %33, %c4 : index
    cf.br ^bb5(%62 : index)
  ^bb7:  // pred: ^bb5
    %63 = arith.addi %26, %c1 : index
    cf.br ^bb3(%63 : index)
  ^bb8:  // pred: ^bb3
    %64 = arith.addi %14, %c1 : index
    cf.br ^bb1(%64 : index)
  ^bb9:  // pred: ^bb1
    %65 = bufferization.to_tensor %10 : memref<10x10xf64> to tensor<10x10xf64>
    return %65 : tensor<10x10xf64>
  }
  func.func @main() -> i64 {
    %0 = llvm.mlir.constant(0 : index) : i64
    %1 = llvm.mlir.poison : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)>
    %2 = llvm.mlir.constant(3735928559 : index) : i64
    %3 = llvm.mlir.addressof @__constant_10x10xf64 : !llvm.ptr
    %c9 = arith.constant 9 : index
    %c8 = arith.constant 8 : index
    %cst = arith.constant 0.000000e+00 : f64
    %c1 = arith.constant 1 : index
    %c10 = arith.constant 10 : index
    %c0 = arith.constant 0 : index
    %4 = llvm.mlir.constant(10 : index) : i64
    %5 = llvm.mlir.constant(1 : index) : i64
    %6 = llvm.getelementptr %3[0, 0, 0] : (!llvm.ptr) -> !llvm.ptr, !llvm.array<10 x array<10 x f64>>
    %7 = llvm.inttoptr %2 : i64 to !llvm.ptr
    %8 = llvm.insertvalue %7, %1[0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %9 = llvm.insertvalue %6, %8[1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %10 = llvm.insertvalue %0, %9[2] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %11 = llvm.insertvalue %4, %10[3, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %12 = llvm.insertvalue %4, %11[3, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %13 = llvm.insertvalue %4, %12[4, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %14 = llvm.insertvalue %5, %13[4, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %15 = builtin.unrealized_conversion_cast %14 : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> to memref<10x10xf64>
    %16 = bufferization.to_tensor %15 : memref<10x10xf64> to tensor<10x10xf64>
    %17 = bufferization.alloc_tensor() : tensor<10x10xf64>
    %18:4 = call @assemble_sparse() : () -> (memref<?xindex>, memref<?xindex>, memref<?xf64>, !llvm.struct<(array<2 x i64>, array<3 x i64>)>)
    %19 = call @matmul(%18#0, %18#1, %18#2, %18#3, %16, %17) : (memref<?xindex>, memref<?xindex>, memref<?xf64>, !llvm.struct<(array<2 x i64>, array<3 x i64>)>, tensor<10x10xf64>, tensor<10x10xf64>) -> tensor<10x10xf64>
    cf.br ^bb1(%c0 : index)
  ^bb1(%20: index):  // 2 preds: ^bb0, ^bb7
    %21 = arith.cmpi slt, %20, %c10 : index
    cf.cond_br %21, ^bb2, ^bb8
  ^bb2:  // pred: ^bb1
    %22 = vector.transfer_read %19[%20, %c0], %cst {in_bounds = [true]} : tensor<10x10xf64>, vector<10xf64>
    llvm.call @printOpen() : () -> ()
    cf.br ^bb3(%c0 : index)
  ^bb3(%23: index):  // 2 preds: ^bb2, ^bb6
    %24 = builtin.unrealized_conversion_cast %23 : index to i64
    %25 = arith.cmpi slt, %23, %c10 : index
    cf.cond_br %25, ^bb4, ^bb7
  ^bb4:  // pred: ^bb3
    %26 = llvm.extractelement %22[%24 : i64] : vector<10xf64>
    llvm.call @printF64(%26) : (f64) -> ()
    %27 = arith.cmpi ult, %23, %c9 : index
    cf.cond_br %27, ^bb5, ^bb6
  ^bb5:  // pred: ^bb4
    llvm.call @printComma() : () -> ()
    cf.br ^bb6
  ^bb6:  // 2 preds: ^bb4, ^bb5
    %28 = arith.addi %23, %c1 : index
    cf.br ^bb3(%28 : index)
  ^bb7:  // pred: ^bb3
    llvm.call @printClose() : () -> ()
    llvm.call @printNewline() : () -> ()
    %29 = arith.addi %20, %c1 : index
    cf.br ^bb1(%29 : index)
  ^bb8:  // pred: ^bb1
    %extracted = tensor.extract %19[%c8, %c8] : tensor<10x10xf64>
    %30 = arith.fptosi %extracted : f64 to i64
    return %30 : i64
  }
  func.func @assemble_sparse() -> (memref<?xindex>, memref<?xindex>, memref<?xf64>, !llvm.struct<(array<2 x i64>, array<3 x i64>)>) {
    %0 = llvm.mlir.addressof @__constant_30xindex : !llvm.ptr
    %1 = llvm.mlir.addressof @__constant_11xindex : !llvm.ptr
    %2 = llvm.mlir.constant(11 : index) : i64
    %3 = llvm.mlir.constant(0 : index) : i64
    %4 = llvm.mlir.poison : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %5 = llvm.mlir.constant(3735928559 : index) : i64
    %6 = llvm.mlir.addressof @__constant_30xf64 : !llvm.ptr
    %7 = llvm.mlir.constant(1 : index) : i64
    %8 = llvm.mlir.constant(30 : index) : i64
    %c11_i64 = arith.constant 11 : i64
    %c10_i64 = arith.constant 10 : i64
    %c0_i64 = arith.constant 0 : i64
    %9 = llvm.mlir.poison : !llvm.struct<(array<2 x i64>, array<3 x i64>)>
    %c10 = arith.constant 10 : index
    %10 = builtin.unrealized_conversion_cast %c10 : index to i64
    %11 = llvm.getelementptr %6[0, 0] : (!llvm.ptr) -> !llvm.ptr, !llvm.array<30 x f64>
    %12 = llvm.inttoptr %5 : i64 to !llvm.ptr
    %13 = llvm.insertvalue %12, %4[0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %14 = llvm.insertvalue %11, %13[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %15 = llvm.insertvalue %3, %14[2] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %16 = llvm.insertvalue %8, %15[3, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %17 = llvm.insertvalue %7, %16[4, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %18 = builtin.unrealized_conversion_cast %17 : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> to memref<?xf64>
    %19 = llvm.getelementptr %1[0, 0] : (!llvm.ptr) -> !llvm.ptr, !llvm.array<11 x i64>
    %20 = llvm.inttoptr %5 : i64 to !llvm.ptr
    %21 = llvm.insertvalue %20, %4[0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %22 = llvm.insertvalue %19, %21[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %23 = llvm.insertvalue %3, %22[2] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %24 = llvm.insertvalue %2, %23[3, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %25 = llvm.insertvalue %7, %24[4, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %26 = builtin.unrealized_conversion_cast %25 : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> to memref<?xindex>
    %27 = llvm.getelementptr %0[0, 0] : (!llvm.ptr) -> !llvm.ptr, !llvm.array<30 x i64>
    %28 = llvm.inttoptr %5 : i64 to !llvm.ptr
    %29 = llvm.insertvalue %28, %4[0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %30 = llvm.insertvalue %27, %29[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %31 = llvm.insertvalue %3, %30[2] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %32 = llvm.insertvalue %8, %31[3, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %33 = llvm.insertvalue %7, %32[4, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %34 = builtin.unrealized_conversion_cast %33 : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> to memref<?xindex>
    %35 = llvm.insertvalue %c0_i64, %9[1, 0] : !llvm.struct<(array<2 x i64>, array<3 x i64>)> 
    %36 = llvm.insertvalue %c0_i64, %35[1, 1] : !llvm.struct<(array<2 x i64>, array<3 x i64>)> 
    %37 = llvm.insertvalue %c0_i64, %36[1, 2] : !llvm.struct<(array<2 x i64>, array<3 x i64>)> 
    %38 = llvm.insertvalue %c10_i64, %37[0, 0] : !llvm.struct<(array<2 x i64>, array<3 x i64>)> 
    %39 = llvm.insertvalue %c10_i64, %38[0, 1] : !llvm.struct<(array<2 x i64>, array<3 x i64>)> 
    %40 = llvm.insertvalue %c11_i64, %39[1, 0] : !llvm.struct<(array<2 x i64>, array<3 x i64>)> 
    %41 = llvm.getelementptr %19[%10] : (!llvm.ptr, i64) -> !llvm.ptr, i64
    %42 = llvm.load %41 : !llvm.ptr -> i64
    %43 = builtin.unrealized_conversion_cast %42 : i64 to index
    %44 = arith.index_cast %43 : index to i64
    %45 = llvm.insertvalue %44, %40[1, 1] : !llvm.struct<(array<2 x i64>, array<3 x i64>)> 
    %46 = arith.index_cast %43 : index to i64
    %47 = llvm.insertvalue %46, %45[1, 2] : !llvm.struct<(array<2 x i64>, array<3 x i64>)> 
    return %26, %34, %18, %47 : memref<?xindex>, memref<?xindex>, memref<?xf64>, !llvm.struct<(array<2 x i64>, array<3 x i64>)>
  }
}


// -----// IR Dump After ConvertVectorToLLVMPass (convert-vector-to-llvm) //----- //
module {
  llvm.func @printNewline()
  llvm.func @printClose()
  llvm.func @printComma()
  llvm.func @printF64(f64)
  llvm.func @printOpen()
  llvm.mlir.global private constant @__constant_30xindex(dense<[8, 3, 4, 6, 9, 2, 4, 0, 1, 2, 3, 5, 7, 8, 3, 6, 2, 3, 4, 5, 8, 1, 5, 7, 8, 5, 9, 4, 7, 7]> : tensor<30xindex>) {addr_space = 0 : i32, alignment = 64 : i64} : !llvm.array<30 x i64>
  llvm.mlir.global private constant @__constant_11xindex(dense<[0, 1, 5, 7, 14, 16, 21, 25, 27, 29, 30]> : tensor<11xindex>) {addr_space = 0 : i32, alignment = 64 : i64} : !llvm.array<11 x i64>
  llvm.mlir.global private constant @__constant_30xf64(dense<[4.7563469999999999, 2.102859, 5.4238689999999998, 5.577680e+00, 3.001240e-01, 4.8357549999999998, 8.8596050000000002, 1.592490e+00, 7.372070e+00, 7.2462879999999998, 5.9191609999999999, 5.9593920000000002, 4.6956530000000001, 6.328630e-01, 3.1591619999999998, 4.7083050000000002, 8.4356449999999992, 5.4309390000000004, 2.1190630000000001, 1.545420e-01, 2.595040e+00, 1.4655819999999999, 1.321259, 3.702925, 3.542246, 6.831162, 1.723510e+00, 7.8729019999999998, 6.0081550000000004, 1.047045]> : tensor<30xf64>) {addr_space = 0 : i32, alignment = 64 : i64} : !llvm.array<30 x f64>
  llvm.mlir.global private constant @__constant_10x10xf64(dense<[[5.0072820879405331, 2.1420497309468542, 8.4364357946217474, 3.3512684114489364, 4.8578737173077684, 6.5026873298607608, 4.481183080848961, 1.6018142840321781, 1.6482067031075565, 2.7697353449463433], [8.2796435610104453, 9.7956308688691446, 5.066309369035312, 1.0691978274975567, 7.2754747197326219, 7.4679216752662611, 1.8460472498040226, 1.7245060332115747, 9.828847678500983, 5.8523888503628294], [4.735129046344202, 0.21389279999051047, 9.9823910553584571, 0.22751442405574696, 4.3063298537464378, 1.0300462704374436, 7.1885192597496097, 1.7297134743393461, 7.4494154821665912, 8.2180913094628564], [0.55370097211729696, 7.0871105126860554, 7.7450498540614178, 4.2448327660994876, 1.2746000519648371, 9.4391729894286023, 6.1902689198805465, 6.0312877871821424, 8.7890699247898425, 3.1611885774377635], [8.9903796016343396, 3.4471256572948263, 8.4932841564173884, 9.9373309006088171, 2.6191045587156303, 0.77351004199567641, 1.4024547359632467, 7.454551829233095, 2.6194195569905077, 4.0298520046877577], [4.7641019675563543, 3.8129279818642861, 9.0747728919768225, 6.4920816381757511, 6.7882405668469881, 7.0063465072165911, 5.7386637585592792, 7.5230234961300599, 0.91592641387099771, 8.6646639602141899], [5.6862365678538973, 4.8755032417073192, 9.5859588536709328, 8.1186668576209513, 5.3811119011589454, 3.8280043169558411, 9.9983397606134918, 6.1835824149566241, 3.4201107815517515, 0.84968218962971687], [2.791270331453247, 2.9735813587818685, 3.0654358664150494, 5.4929582569491755, 3.9238922832952996, 9.2657934977933269, 5.0681592194030571, 9.6910348814034712, 2.0972430846802959, 0.96789458347651514], [3.1989914495545624, 3.7607248895716507, 5.5182323136835318, 2.4724154287944913, 7.2920674615977124, 9.7009225179758473, 9.9421519655410044, 2.6109645810252315, 9.0484630420475316, 3.6771724535825703], [6.305746358135309, 7.6948754823713771, 3.6012681436537397, 1.263350310992416, 3.8581878444772943, 7.1047027925517909, 2.1904752468927735, 0.32914734762647391, 3.1668377278172235, 2.0518472657841924]]> : tensor<10x10xf64>) {addr_space = 0 : i32, alignment = 64 : i64} : !llvm.array<10 x array<10 x f64>>
  func.func @matmul(%arg0: memref<?xindex>, %arg1: memref<?xindex>, %arg2: memref<?xf64>, %arg3: !llvm.struct<(array<2 x i64>, array<3 x i64>)>, %arg4: tensor<10x10xf64>, %arg5: tensor<10x10xf64>) -> tensor<10x10xf64> {
    %0 = llvm.mlir.poison : vector<4xf64>
    %1 = llvm.mlir.constant(10 : index) : i64
    %2 = llvm.mlir.constant(0 : i32) : i32
    %3 = llvm.mlir.poison : vector<4xi32>
    %c10 = arith.constant 10 : index
    %c0 = arith.constant 0 : index
    %c1 = arith.constant 1 : index
    %c4 = arith.constant 4 : index
    %cst = arith.constant dense<0.000000e+00> : vector<4xf64>
    %c-1 = arith.constant -1 : index
    %cst_0 = arith.constant dense<[0, 1, 2, 3]> : vector<4xi32>
    %4 = builtin.unrealized_conversion_cast %arg1 : memref<?xindex> to !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %5 = builtin.unrealized_conversion_cast %arg0 : memref<?xindex> to !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %6 = builtin.unrealized_conversion_cast %arg2 : memref<?xf64> to !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %7 = llvm.extractvalue %6[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %8 = bufferization.to_memref %arg4 : tensor<10x10xf64> to memref<10x10xf64>
    %9 = builtin.unrealized_conversion_cast %8 : memref<10x10xf64> to !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)>
    %10 = bufferization.to_memref %arg5 : tensor<10x10xf64> to memref<10x10xf64>
    %11 = builtin.unrealized_conversion_cast %10 : memref<10x10xf64> to !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)>
    %12 = llvm.extractvalue %5[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %13 = llvm.extractvalue %4[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    cf.br ^bb1(%c0 : index)
  ^bb1(%14: index):  // 2 preds: ^bb0, ^bb8
    %15 = builtin.unrealized_conversion_cast %14 : index to i64
    %16 = builtin.unrealized_conversion_cast %14 : index to i64
    %17 = arith.cmpi slt, %14, %c10 : index
    cf.cond_br %17, ^bb2, ^bb9
  ^bb2:  // pred: ^bb1
    %18 = llvm.getelementptr %12[%15] : (!llvm.ptr, i64) -> !llvm.ptr, i64
    %19 = llvm.load %18 : !llvm.ptr -> i64
    %20 = builtin.unrealized_conversion_cast %19 : i64 to index
    %21 = arith.addi %14, %c1 : index
    %22 = builtin.unrealized_conversion_cast %21 : index to i64
    %23 = llvm.getelementptr %12[%22] : (!llvm.ptr, i64) -> !llvm.ptr, i64
    %24 = llvm.load %23 : !llvm.ptr -> i64
    %25 = builtin.unrealized_conversion_cast %24 : i64 to index
    cf.br ^bb3(%20 : index)
  ^bb3(%26: index):  // 2 preds: ^bb2, ^bb7
    %27 = builtin.unrealized_conversion_cast %26 : index to i64
    %28 = arith.cmpi slt, %26, %25 : index
    cf.cond_br %28, ^bb4, ^bb8
  ^bb4:  // pred: ^bb3
    %29 = llvm.getelementptr %13[%27] : (!llvm.ptr, i64) -> !llvm.ptr, i64
    %30 = llvm.load %29 : !llvm.ptr -> i64
    %31 = llvm.getelementptr %7[%27] : (!llvm.ptr, i64) -> !llvm.ptr, f64
    %32 = llvm.load %31 : !llvm.ptr -> f64
    cf.br ^bb5(%c0 : index)
  ^bb5(%33: index):  // 2 preds: ^bb4, ^bb6
    %34 = builtin.unrealized_conversion_cast %33 : index to i64
    %35 = arith.cmpi slt, %33, %c10 : index
    cf.cond_br %35, ^bb6, ^bb7
  ^bb6:  // pred: ^bb5
    %36 = arith.muli %33, %c-1 overflow<nsw> : index
    %37 = arith.addi %36, %c10 : index
    %38 = arith.cmpi slt, %37, %c4 : index
    %39 = arith.select %38, %37, %c4 : index
    %40 = arith.index_cast %39 : index to i32
    %41 = llvm.insertelement %40, %3[%2 : i32] : vector<4xi32>
    %42 = llvm.shufflevector %41, %3 [0, 0, 0, 0] : vector<4xi32> 
    %43 = arith.cmpi sgt, %42, %cst_0 : vector<4xi32>
    %44 = llvm.extractvalue %11[1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %45 = llvm.mul %16, %1 : i64
    %46 = llvm.add %45, %34 : i64
    %47 = llvm.getelementptr %44[%46] : (!llvm.ptr, i64) -> !llvm.ptr, f64
    %48 = llvm.intr.masked.load %47, %43, %cst {alignment = 8 : i32} : (!llvm.ptr, vector<4xi1>, vector<4xf64>) -> vector<4xf64>
    %49 = llvm.insertelement %32, %0[%2 : i32] : vector<4xf64>
    %50 = llvm.shufflevector %49, %0 [0, 0, 0, 0] : vector<4xf64> 
    %51 = llvm.extractvalue %9[1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %52 = llvm.mul %30, %1 : i64
    %53 = llvm.add %52, %34 : i64
    %54 = llvm.getelementptr %51[%53] : (!llvm.ptr, i64) -> !llvm.ptr, f64
    %55 = llvm.intr.masked.load %54, %43, %cst {alignment = 8 : i32} : (!llvm.ptr, vector<4xi1>, vector<4xf64>) -> vector<4xf64>
    %56 = arith.mulf %50, %55 : vector<4xf64>
    %57 = arith.addf %48, %56 : vector<4xf64>
    %58 = llvm.extractvalue %11[1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %59 = llvm.mul %16, %1 : i64
    %60 = llvm.add %59, %34 : i64
    %61 = llvm.getelementptr %58[%60] : (!llvm.ptr, i64) -> !llvm.ptr, f64
    llvm.intr.masked.store %57, %61, %43 {alignment = 8 : i32} : vector<4xf64>, vector<4xi1> into !llvm.ptr
    %62 = arith.addi %33, %c4 : index
    cf.br ^bb5(%62 : index)
  ^bb7:  // pred: ^bb5
    %63 = arith.addi %26, %c1 : index
    cf.br ^bb3(%63 : index)
  ^bb8:  // pred: ^bb3
    %64 = arith.addi %14, %c1 : index
    cf.br ^bb1(%64 : index)
  ^bb9:  // pred: ^bb1
    %65 = bufferization.to_tensor %10 : memref<10x10xf64> to tensor<10x10xf64>
    return %65 : tensor<10x10xf64>
  }
  func.func @main() -> i64 {
    %0 = llvm.mlir.constant(0 : index) : i64
    %1 = llvm.mlir.poison : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)>
    %2 = llvm.mlir.constant(3735928559 : index) : i64
    %3 = llvm.mlir.addressof @__constant_10x10xf64 : !llvm.ptr
    %c9 = arith.constant 9 : index
    %c8 = arith.constant 8 : index
    %cst = arith.constant 0.000000e+00 : f64
    %c1 = arith.constant 1 : index
    %c10 = arith.constant 10 : index
    %c0 = arith.constant 0 : index
    %4 = llvm.mlir.constant(10 : index) : i64
    %5 = llvm.mlir.constant(1 : index) : i64
    %6 = llvm.getelementptr %3[0, 0, 0] : (!llvm.ptr) -> !llvm.ptr, !llvm.array<10 x array<10 x f64>>
    %7 = llvm.inttoptr %2 : i64 to !llvm.ptr
    %8 = llvm.insertvalue %7, %1[0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %9 = llvm.insertvalue %6, %8[1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %10 = llvm.insertvalue %0, %9[2] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %11 = llvm.insertvalue %4, %10[3, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %12 = llvm.insertvalue %4, %11[3, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %13 = llvm.insertvalue %4, %12[4, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %14 = llvm.insertvalue %5, %13[4, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %15 = builtin.unrealized_conversion_cast %14 : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> to memref<10x10xf64>
    %16 = bufferization.to_tensor %15 : memref<10x10xf64> to tensor<10x10xf64>
    %17 = bufferization.alloc_tensor() : tensor<10x10xf64>
    %18:4 = call @assemble_sparse() : () -> (memref<?xindex>, memref<?xindex>, memref<?xf64>, !llvm.struct<(array<2 x i64>, array<3 x i64>)>)
    %19 = call @matmul(%18#0, %18#1, %18#2, %18#3, %16, %17) : (memref<?xindex>, memref<?xindex>, memref<?xf64>, !llvm.struct<(array<2 x i64>, array<3 x i64>)>, tensor<10x10xf64>, tensor<10x10xf64>) -> tensor<10x10xf64>
    cf.br ^bb1(%c0 : index)
  ^bb1(%20: index):  // 2 preds: ^bb0, ^bb7
    %21 = arith.cmpi slt, %20, %c10 : index
    cf.cond_br %21, ^bb2, ^bb8
  ^bb2:  // pred: ^bb1
    %22 = vector.transfer_read %19[%20, %c0], %cst {in_bounds = [true]} : tensor<10x10xf64>, vector<10xf64>
    llvm.call @printOpen() : () -> ()
    cf.br ^bb3(%c0 : index)
  ^bb3(%23: index):  // 2 preds: ^bb2, ^bb6
    %24 = builtin.unrealized_conversion_cast %23 : index to i64
    %25 = arith.cmpi slt, %23, %c10 : index
    cf.cond_br %25, ^bb4, ^bb7
  ^bb4:  // pred: ^bb3
    %26 = llvm.extractelement %22[%24 : i64] : vector<10xf64>
    llvm.call @printF64(%26) : (f64) -> ()
    %27 = arith.cmpi ult, %23, %c9 : index
    cf.cond_br %27, ^bb5, ^bb6
  ^bb5:  // pred: ^bb4
    llvm.call @printComma() : () -> ()
    cf.br ^bb6
  ^bb6:  // 2 preds: ^bb4, ^bb5
    %28 = arith.addi %23, %c1 : index
    cf.br ^bb3(%28 : index)
  ^bb7:  // pred: ^bb3
    llvm.call @printClose() : () -> ()
    llvm.call @printNewline() : () -> ()
    %29 = arith.addi %20, %c1 : index
    cf.br ^bb1(%29 : index)
  ^bb8:  // pred: ^bb1
    %extracted = tensor.extract %19[%c8, %c8] : tensor<10x10xf64>
    %30 = arith.fptosi %extracted : f64 to i64
    return %30 : i64
  }
  func.func @assemble_sparse() -> (memref<?xindex>, memref<?xindex>, memref<?xf64>, !llvm.struct<(array<2 x i64>, array<3 x i64>)>) {
    %0 = llvm.mlir.addressof @__constant_30xindex : !llvm.ptr
    %1 = llvm.mlir.addressof @__constant_11xindex : !llvm.ptr
    %2 = llvm.mlir.constant(11 : index) : i64
    %3 = llvm.mlir.constant(0 : index) : i64
    %4 = llvm.mlir.poison : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %5 = llvm.mlir.constant(3735928559 : index) : i64
    %6 = llvm.mlir.addressof @__constant_30xf64 : !llvm.ptr
    %7 = llvm.mlir.constant(1 : index) : i64
    %8 = llvm.mlir.constant(30 : index) : i64
    %c11_i64 = arith.constant 11 : i64
    %c10_i64 = arith.constant 10 : i64
    %c0_i64 = arith.constant 0 : i64
    %9 = llvm.mlir.poison : !llvm.struct<(array<2 x i64>, array<3 x i64>)>
    %c10 = arith.constant 10 : index
    %10 = builtin.unrealized_conversion_cast %c10 : index to i64
    %11 = llvm.getelementptr %6[0, 0] : (!llvm.ptr) -> !llvm.ptr, !llvm.array<30 x f64>
    %12 = llvm.inttoptr %5 : i64 to !llvm.ptr
    %13 = llvm.insertvalue %12, %4[0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %14 = llvm.insertvalue %11, %13[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %15 = llvm.insertvalue %3, %14[2] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %16 = llvm.insertvalue %8, %15[3, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %17 = llvm.insertvalue %7, %16[4, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %18 = builtin.unrealized_conversion_cast %17 : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> to memref<?xf64>
    %19 = llvm.getelementptr %1[0, 0] : (!llvm.ptr) -> !llvm.ptr, !llvm.array<11 x i64>
    %20 = llvm.inttoptr %5 : i64 to !llvm.ptr
    %21 = llvm.insertvalue %20, %4[0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %22 = llvm.insertvalue %19, %21[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %23 = llvm.insertvalue %3, %22[2] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %24 = llvm.insertvalue %2, %23[3, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %25 = llvm.insertvalue %7, %24[4, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %26 = builtin.unrealized_conversion_cast %25 : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> to memref<?xindex>
    %27 = llvm.getelementptr %0[0, 0] : (!llvm.ptr) -> !llvm.ptr, !llvm.array<30 x i64>
    %28 = llvm.inttoptr %5 : i64 to !llvm.ptr
    %29 = llvm.insertvalue %28, %4[0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %30 = llvm.insertvalue %27, %29[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %31 = llvm.insertvalue %3, %30[2] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %32 = llvm.insertvalue %8, %31[3, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %33 = llvm.insertvalue %7, %32[4, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %34 = builtin.unrealized_conversion_cast %33 : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> to memref<?xindex>
    %35 = llvm.insertvalue %c0_i64, %9[1, 0] : !llvm.struct<(array<2 x i64>, array<3 x i64>)> 
    %36 = llvm.insertvalue %c0_i64, %35[1, 1] : !llvm.struct<(array<2 x i64>, array<3 x i64>)> 
    %37 = llvm.insertvalue %c0_i64, %36[1, 2] : !llvm.struct<(array<2 x i64>, array<3 x i64>)> 
    %38 = llvm.insertvalue %c10_i64, %37[0, 0] : !llvm.struct<(array<2 x i64>, array<3 x i64>)> 
    %39 = llvm.insertvalue %c10_i64, %38[0, 1] : !llvm.struct<(array<2 x i64>, array<3 x i64>)> 
    %40 = llvm.insertvalue %c11_i64, %39[1, 0] : !llvm.struct<(array<2 x i64>, array<3 x i64>)> 
    %41 = llvm.getelementptr %19[%10] : (!llvm.ptr, i64) -> !llvm.ptr, i64
    %42 = llvm.load %41 : !llvm.ptr -> i64
    %43 = builtin.unrealized_conversion_cast %42 : i64 to index
    %44 = arith.index_cast %43 : index to i64
    %45 = llvm.insertvalue %44, %40[1, 1] : !llvm.struct<(array<2 x i64>, array<3 x i64>)> 
    %46 = arith.index_cast %43 : index to i64
    %47 = llvm.insertvalue %46, %45[1, 2] : !llvm.struct<(array<2 x i64>, array<3 x i64>)> 
    return %26, %34, %18, %47 : memref<?xindex>, memref<?xindex>, memref<?xf64>, !llvm.struct<(array<2 x i64>, array<3 x i64>)>
  }
}


// -----// IR Dump After ConvertFuncToLLVMPass (convert-func-to-llvm) //----- //
module {
  llvm.func @printNewline()
  llvm.func @printClose()
  llvm.func @printComma()
  llvm.func @printF64(f64)
  llvm.func @printOpen()
  llvm.mlir.global private constant @__constant_30xindex(dense<[8, 3, 4, 6, 9, 2, 4, 0, 1, 2, 3, 5, 7, 8, 3, 6, 2, 3, 4, 5, 8, 1, 5, 7, 8, 5, 9, 4, 7, 7]> : tensor<30xindex>) {addr_space = 0 : i32, alignment = 64 : i64} : !llvm.array<30 x i64>
  llvm.mlir.global private constant @__constant_11xindex(dense<[0, 1, 5, 7, 14, 16, 21, 25, 27, 29, 30]> : tensor<11xindex>) {addr_space = 0 : i32, alignment = 64 : i64} : !llvm.array<11 x i64>
  llvm.mlir.global private constant @__constant_30xf64(dense<[4.7563469999999999, 2.102859, 5.4238689999999998, 5.577680e+00, 3.001240e-01, 4.8357549999999998, 8.8596050000000002, 1.592490e+00, 7.372070e+00, 7.2462879999999998, 5.9191609999999999, 5.9593920000000002, 4.6956530000000001, 6.328630e-01, 3.1591619999999998, 4.7083050000000002, 8.4356449999999992, 5.4309390000000004, 2.1190630000000001, 1.545420e-01, 2.595040e+00, 1.4655819999999999, 1.321259, 3.702925, 3.542246, 6.831162, 1.723510e+00, 7.8729019999999998, 6.0081550000000004, 1.047045]> : tensor<30xf64>) {addr_space = 0 : i32, alignment = 64 : i64} : !llvm.array<30 x f64>
  llvm.mlir.global private constant @__constant_10x10xf64(dense<[[5.0072820879405331, 2.1420497309468542, 8.4364357946217474, 3.3512684114489364, 4.8578737173077684, 6.5026873298607608, 4.481183080848961, 1.6018142840321781, 1.6482067031075565, 2.7697353449463433], [8.2796435610104453, 9.7956308688691446, 5.066309369035312, 1.0691978274975567, 7.2754747197326219, 7.4679216752662611, 1.8460472498040226, 1.7245060332115747, 9.828847678500983, 5.8523888503628294], [4.735129046344202, 0.21389279999051047, 9.9823910553584571, 0.22751442405574696, 4.3063298537464378, 1.0300462704374436, 7.1885192597496097, 1.7297134743393461, 7.4494154821665912, 8.2180913094628564], [0.55370097211729696, 7.0871105126860554, 7.7450498540614178, 4.2448327660994876, 1.2746000519648371, 9.4391729894286023, 6.1902689198805465, 6.0312877871821424, 8.7890699247898425, 3.1611885774377635], [8.9903796016343396, 3.4471256572948263, 8.4932841564173884, 9.9373309006088171, 2.6191045587156303, 0.77351004199567641, 1.4024547359632467, 7.454551829233095, 2.6194195569905077, 4.0298520046877577], [4.7641019675563543, 3.8129279818642861, 9.0747728919768225, 6.4920816381757511, 6.7882405668469881, 7.0063465072165911, 5.7386637585592792, 7.5230234961300599, 0.91592641387099771, 8.6646639602141899], [5.6862365678538973, 4.8755032417073192, 9.5859588536709328, 8.1186668576209513, 5.3811119011589454, 3.8280043169558411, 9.9983397606134918, 6.1835824149566241, 3.4201107815517515, 0.84968218962971687], [2.791270331453247, 2.9735813587818685, 3.0654358664150494, 5.4929582569491755, 3.9238922832952996, 9.2657934977933269, 5.0681592194030571, 9.6910348814034712, 2.0972430846802959, 0.96789458347651514], [3.1989914495545624, 3.7607248895716507, 5.5182323136835318, 2.4724154287944913, 7.2920674615977124, 9.7009225179758473, 9.9421519655410044, 2.6109645810252315, 9.0484630420475316, 3.6771724535825703], [6.305746358135309, 7.6948754823713771, 3.6012681436537397, 1.263350310992416, 3.8581878444772943, 7.1047027925517909, 2.1904752468927735, 0.32914734762647391, 3.1668377278172235, 2.0518472657841924]]> : tensor<10x10xf64>) {addr_space = 0 : i32, alignment = 64 : i64} : !llvm.array<10 x array<10 x f64>>
  func.func @matmul(%arg0: memref<?xindex>, %arg1: memref<?xindex>, %arg2: memref<?xf64>, %arg3: !llvm.struct<(array<2 x i64>, array<3 x i64>)>, %arg4: tensor<10x10xf64>, %arg5: tensor<10x10xf64>) -> tensor<10x10xf64> {
    %0 = llvm.mlir.poison : vector<4xf64>
    %1 = llvm.mlir.constant(10 : index) : i64
    %2 = llvm.mlir.constant(0 : i32) : i32
    %3 = llvm.mlir.poison : vector<4xi32>
    %c10 = arith.constant 10 : index
    %c0 = arith.constant 0 : index
    %c1 = arith.constant 1 : index
    %c4 = arith.constant 4 : index
    %cst = arith.constant dense<0.000000e+00> : vector<4xf64>
    %c-1 = arith.constant -1 : index
    %cst_0 = arith.constant dense<[0, 1, 2, 3]> : vector<4xi32>
    %4 = builtin.unrealized_conversion_cast %arg1 : memref<?xindex> to !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %5 = builtin.unrealized_conversion_cast %arg0 : memref<?xindex> to !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %6 = builtin.unrealized_conversion_cast %arg2 : memref<?xf64> to !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %7 = llvm.extractvalue %6[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %8 = bufferization.to_memref %arg4 : tensor<10x10xf64> to memref<10x10xf64>
    %9 = builtin.unrealized_conversion_cast %8 : memref<10x10xf64> to !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)>
    %10 = bufferization.to_memref %arg5 : tensor<10x10xf64> to memref<10x10xf64>
    %11 = builtin.unrealized_conversion_cast %10 : memref<10x10xf64> to !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)>
    %12 = llvm.extractvalue %5[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %13 = llvm.extractvalue %4[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    cf.br ^bb1(%c0 : index)
  ^bb1(%14: index):  // 2 preds: ^bb0, ^bb8
    %15 = builtin.unrealized_conversion_cast %14 : index to i64
    %16 = builtin.unrealized_conversion_cast %14 : index to i64
    %17 = arith.cmpi slt, %14, %c10 : index
    cf.cond_br %17, ^bb2, ^bb9
  ^bb2:  // pred: ^bb1
    %18 = llvm.getelementptr %12[%15] : (!llvm.ptr, i64) -> !llvm.ptr, i64
    %19 = llvm.load %18 : !llvm.ptr -> i64
    %20 = builtin.unrealized_conversion_cast %19 : i64 to index
    %21 = arith.addi %14, %c1 : index
    %22 = builtin.unrealized_conversion_cast %21 : index to i64
    %23 = llvm.getelementptr %12[%22] : (!llvm.ptr, i64) -> !llvm.ptr, i64
    %24 = llvm.load %23 : !llvm.ptr -> i64
    %25 = builtin.unrealized_conversion_cast %24 : i64 to index
    cf.br ^bb3(%20 : index)
  ^bb3(%26: index):  // 2 preds: ^bb2, ^bb7
    %27 = builtin.unrealized_conversion_cast %26 : index to i64
    %28 = arith.cmpi slt, %26, %25 : index
    cf.cond_br %28, ^bb4, ^bb8
  ^bb4:  // pred: ^bb3
    %29 = llvm.getelementptr %13[%27] : (!llvm.ptr, i64) -> !llvm.ptr, i64
    %30 = llvm.load %29 : !llvm.ptr -> i64
    %31 = llvm.getelementptr %7[%27] : (!llvm.ptr, i64) -> !llvm.ptr, f64
    %32 = llvm.load %31 : !llvm.ptr -> f64
    cf.br ^bb5(%c0 : index)
  ^bb5(%33: index):  // 2 preds: ^bb4, ^bb6
    %34 = builtin.unrealized_conversion_cast %33 : index to i64
    %35 = arith.cmpi slt, %33, %c10 : index
    cf.cond_br %35, ^bb6, ^bb7
  ^bb6:  // pred: ^bb5
    %36 = arith.muli %33, %c-1 overflow<nsw> : index
    %37 = arith.addi %36, %c10 : index
    %38 = arith.cmpi slt, %37, %c4 : index
    %39 = arith.select %38, %37, %c4 : index
    %40 = arith.index_cast %39 : index to i32
    %41 = llvm.insertelement %40, %3[%2 : i32] : vector<4xi32>
    %42 = llvm.shufflevector %41, %3 [0, 0, 0, 0] : vector<4xi32> 
    %43 = arith.cmpi sgt, %42, %cst_0 : vector<4xi32>
    %44 = llvm.extractvalue %11[1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %45 = llvm.mul %16, %1 : i64
    %46 = llvm.add %45, %34 : i64
    %47 = llvm.getelementptr %44[%46] : (!llvm.ptr, i64) -> !llvm.ptr, f64
    %48 = llvm.intr.masked.load %47, %43, %cst {alignment = 8 : i32} : (!llvm.ptr, vector<4xi1>, vector<4xf64>) -> vector<4xf64>
    %49 = llvm.insertelement %32, %0[%2 : i32] : vector<4xf64>
    %50 = llvm.shufflevector %49, %0 [0, 0, 0, 0] : vector<4xf64> 
    %51 = llvm.extractvalue %9[1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %52 = llvm.mul %30, %1 : i64
    %53 = llvm.add %52, %34 : i64
    %54 = llvm.getelementptr %51[%53] : (!llvm.ptr, i64) -> !llvm.ptr, f64
    %55 = llvm.intr.masked.load %54, %43, %cst {alignment = 8 : i32} : (!llvm.ptr, vector<4xi1>, vector<4xf64>) -> vector<4xf64>
    %56 = arith.mulf %50, %55 : vector<4xf64>
    %57 = arith.addf %48, %56 : vector<4xf64>
    %58 = llvm.extractvalue %11[1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %59 = llvm.mul %16, %1 : i64
    %60 = llvm.add %59, %34 : i64
    %61 = llvm.getelementptr %58[%60] : (!llvm.ptr, i64) -> !llvm.ptr, f64
    llvm.intr.masked.store %57, %61, %43 {alignment = 8 : i32} : vector<4xf64>, vector<4xi1> into !llvm.ptr
    %62 = arith.addi %33, %c4 : index
    cf.br ^bb5(%62 : index)
  ^bb7:  // pred: ^bb5
    %63 = arith.addi %26, %c1 : index
    cf.br ^bb3(%63 : index)
  ^bb8:  // pred: ^bb3
    %64 = arith.addi %14, %c1 : index
    cf.br ^bb1(%64 : index)
  ^bb9:  // pred: ^bb1
    %65 = bufferization.to_tensor %10 : memref<10x10xf64> to tensor<10x10xf64>
    return %65 : tensor<10x10xf64>
  }
  llvm.func @main() -> i64 {
    %0 = llvm.mlir.constant(0 : index) : i64
    %1 = llvm.mlir.poison : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)>
    %2 = llvm.mlir.constant(3735928559 : index) : i64
    %3 = llvm.mlir.addressof @__constant_10x10xf64 : !llvm.ptr
    %c9 = arith.constant 9 : index
    %c8 = arith.constant 8 : index
    %cst = arith.constant 0.000000e+00 : f64
    %c1 = arith.constant 1 : index
    %c10 = arith.constant 10 : index
    %c0 = arith.constant 0 : index
    %4 = llvm.mlir.constant(10 : index) : i64
    %5 = llvm.mlir.constant(1 : index) : i64
    %6 = llvm.getelementptr %3[0, 0, 0] : (!llvm.ptr) -> !llvm.ptr, !llvm.array<10 x array<10 x f64>>
    %7 = llvm.inttoptr %2 : i64 to !llvm.ptr
    %8 = llvm.insertvalue %7, %1[0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %9 = llvm.insertvalue %6, %8[1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %10 = llvm.insertvalue %0, %9[2] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %11 = llvm.insertvalue %4, %10[3, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %12 = llvm.insertvalue %4, %11[3, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %13 = llvm.insertvalue %4, %12[4, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %14 = llvm.insertvalue %5, %13[4, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %15 = builtin.unrealized_conversion_cast %14 : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> to memref<10x10xf64>
    %16 = bufferization.to_tensor %15 : memref<10x10xf64> to tensor<10x10xf64>
    %17 = bufferization.alloc_tensor() : tensor<10x10xf64>
    %18 = llvm.call @assemble_sparse() : () -> !llvm.struct<(struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>, struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>, struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>, struct<(array<2 x i64>, array<3 x i64>)>)>
    %19 = llvm.extractvalue %18[0] : !llvm.struct<(struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>, struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>, struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>, struct<(array<2 x i64>, array<3 x i64>)>)> 
    %20 = builtin.unrealized_conversion_cast %19 : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> to memref<?xindex>
    %21 = llvm.extractvalue %18[1] : !llvm.struct<(struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>, struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>, struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>, struct<(array<2 x i64>, array<3 x i64>)>)> 
    %22 = builtin.unrealized_conversion_cast %21 : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> to memref<?xindex>
    %23 = llvm.extractvalue %18[2] : !llvm.struct<(struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>, struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>, struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>, struct<(array<2 x i64>, array<3 x i64>)>)> 
    %24 = builtin.unrealized_conversion_cast %23 : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> to memref<?xf64>
    %25 = llvm.extractvalue %18[3] : !llvm.struct<(struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>, struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>, struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>, struct<(array<2 x i64>, array<3 x i64>)>)> 
    %26 = func.call @matmul(%20, %22, %24, %25, %16, %17) : (memref<?xindex>, memref<?xindex>, memref<?xf64>, !llvm.struct<(array<2 x i64>, array<3 x i64>)>, tensor<10x10xf64>, tensor<10x10xf64>) -> tensor<10x10xf64>
    cf.br ^bb1(%c0 : index)
  ^bb1(%27: index):  // 2 preds: ^bb0, ^bb7
    %28 = arith.cmpi slt, %27, %c10 : index
    cf.cond_br %28, ^bb2, ^bb8
  ^bb2:  // pred: ^bb1
    %29 = vector.transfer_read %26[%27, %c0], %cst {in_bounds = [true]} : tensor<10x10xf64>, vector<10xf64>
    llvm.call @printOpen() : () -> ()
    cf.br ^bb3(%c0 : index)
  ^bb3(%30: index):  // 2 preds: ^bb2, ^bb6
    %31 = builtin.unrealized_conversion_cast %30 : index to i64
    %32 = arith.cmpi slt, %30, %c10 : index
    cf.cond_br %32, ^bb4, ^bb7
  ^bb4:  // pred: ^bb3
    %33 = llvm.extractelement %29[%31 : i64] : vector<10xf64>
    llvm.call @printF64(%33) : (f64) -> ()
    %34 = arith.cmpi ult, %30, %c9 : index
    cf.cond_br %34, ^bb5, ^bb6
  ^bb5:  // pred: ^bb4
    llvm.call @printComma() : () -> ()
    cf.br ^bb6
  ^bb6:  // 2 preds: ^bb4, ^bb5
    %35 = arith.addi %30, %c1 : index
    cf.br ^bb3(%35 : index)
  ^bb7:  // pred: ^bb3
    llvm.call @printClose() : () -> ()
    llvm.call @printNewline() : () -> ()
    %36 = arith.addi %27, %c1 : index
    cf.br ^bb1(%36 : index)
  ^bb8:  // pred: ^bb1
    %extracted = tensor.extract %26[%c8, %c8] : tensor<10x10xf64>
    %37 = arith.fptosi %extracted : f64 to i64
    llvm.return %37 : i64
  }
  llvm.func @assemble_sparse() -> !llvm.struct<(struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>, struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>, struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>, struct<(array<2 x i64>, array<3 x i64>)>)> {
    %0 = llvm.mlir.addressof @__constant_30xindex : !llvm.ptr
    %1 = llvm.mlir.addressof @__constant_11xindex : !llvm.ptr
    %2 = llvm.mlir.constant(11 : index) : i64
    %3 = llvm.mlir.constant(0 : index) : i64
    %4 = llvm.mlir.poison : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %5 = llvm.mlir.constant(3735928559 : index) : i64
    %6 = llvm.mlir.addressof @__constant_30xf64 : !llvm.ptr
    %7 = llvm.mlir.constant(1 : index) : i64
    %8 = llvm.mlir.constant(30 : index) : i64
    %c11_i64 = arith.constant 11 : i64
    %c10_i64 = arith.constant 10 : i64
    %c0_i64 = arith.constant 0 : i64
    %9 = llvm.mlir.poison : !llvm.struct<(array<2 x i64>, array<3 x i64>)>
    %c10 = arith.constant 10 : index
    %10 = builtin.unrealized_conversion_cast %c10 : index to i64
    %11 = llvm.getelementptr %6[0, 0] : (!llvm.ptr) -> !llvm.ptr, !llvm.array<30 x f64>
    %12 = llvm.inttoptr %5 : i64 to !llvm.ptr
    %13 = llvm.insertvalue %12, %4[0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %14 = llvm.insertvalue %11, %13[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %15 = llvm.insertvalue %3, %14[2] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %16 = llvm.insertvalue %8, %15[3, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %17 = llvm.insertvalue %7, %16[4, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %18 = llvm.getelementptr %1[0, 0] : (!llvm.ptr) -> !llvm.ptr, !llvm.array<11 x i64>
    %19 = llvm.inttoptr %5 : i64 to !llvm.ptr
    %20 = llvm.insertvalue %19, %4[0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %21 = llvm.insertvalue %18, %20[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %22 = llvm.insertvalue %3, %21[2] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %23 = llvm.insertvalue %2, %22[3, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %24 = llvm.insertvalue %7, %23[4, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %25 = llvm.getelementptr %0[0, 0] : (!llvm.ptr) -> !llvm.ptr, !llvm.array<30 x i64>
    %26 = llvm.inttoptr %5 : i64 to !llvm.ptr
    %27 = llvm.insertvalue %26, %4[0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %28 = llvm.insertvalue %25, %27[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %29 = llvm.insertvalue %3, %28[2] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %30 = llvm.insertvalue %8, %29[3, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %31 = llvm.insertvalue %7, %30[4, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %32 = llvm.insertvalue %c0_i64, %9[1, 0] : !llvm.struct<(array<2 x i64>, array<3 x i64>)> 
    %33 = llvm.insertvalue %c0_i64, %32[1, 1] : !llvm.struct<(array<2 x i64>, array<3 x i64>)> 
    %34 = llvm.insertvalue %c0_i64, %33[1, 2] : !llvm.struct<(array<2 x i64>, array<3 x i64>)> 
    %35 = llvm.insertvalue %c10_i64, %34[0, 0] : !llvm.struct<(array<2 x i64>, array<3 x i64>)> 
    %36 = llvm.insertvalue %c10_i64, %35[0, 1] : !llvm.struct<(array<2 x i64>, array<3 x i64>)> 
    %37 = llvm.insertvalue %c11_i64, %36[1, 0] : !llvm.struct<(array<2 x i64>, array<3 x i64>)> 
    %38 = llvm.getelementptr %18[%10] : (!llvm.ptr, i64) -> !llvm.ptr, i64
    %39 = llvm.load %38 : !llvm.ptr -> i64
    %40 = builtin.unrealized_conversion_cast %39 : i64 to index
    %41 = arith.index_cast %40 : index to i64
    %42 = llvm.insertvalue %41, %37[1, 1] : !llvm.struct<(array<2 x i64>, array<3 x i64>)> 
    %43 = arith.index_cast %40 : index to i64
    %44 = llvm.insertvalue %43, %42[1, 2] : !llvm.struct<(array<2 x i64>, array<3 x i64>)> 
    %45 = llvm.mlir.poison : !llvm.struct<(struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>, struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>, struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>, struct<(array<2 x i64>, array<3 x i64>)>)>
    %46 = llvm.insertvalue %24, %45[0] : !llvm.struct<(struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>, struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>, struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>, struct<(array<2 x i64>, array<3 x i64>)>)> 
    %47 = llvm.insertvalue %31, %46[1] : !llvm.struct<(struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>, struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>, struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>, struct<(array<2 x i64>, array<3 x i64>)>)> 
    %48 = llvm.insertvalue %17, %47[2] : !llvm.struct<(struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>, struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>, struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>, struct<(array<2 x i64>, array<3 x i64>)>)> 
    %49 = llvm.insertvalue %44, %48[3] : !llvm.struct<(struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>, struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>, struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>, struct<(array<2 x i64>, array<3 x i64>)>)> 
    llvm.return %49 : !llvm.struct<(struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>, struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>, struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>, struct<(array<2 x i64>, array<3 x i64>)>)>
  }
}


// -----// IR Dump After ArithToLLVMConversionPass (convert-arith-to-llvm) //----- //
module {
  llvm.func @printNewline()
  llvm.func @printClose()
  llvm.func @printComma()
  llvm.func @printF64(f64)
  llvm.func @printOpen()
  llvm.mlir.global private constant @__constant_30xindex(dense<[8, 3, 4, 6, 9, 2, 4, 0, 1, 2, 3, 5, 7, 8, 3, 6, 2, 3, 4, 5, 8, 1, 5, 7, 8, 5, 9, 4, 7, 7]> : tensor<30xindex>) {addr_space = 0 : i32, alignment = 64 : i64} : !llvm.array<30 x i64>
  llvm.mlir.global private constant @__constant_11xindex(dense<[0, 1, 5, 7, 14, 16, 21, 25, 27, 29, 30]> : tensor<11xindex>) {addr_space = 0 : i32, alignment = 64 : i64} : !llvm.array<11 x i64>
  llvm.mlir.global private constant @__constant_30xf64(dense<[4.7563469999999999, 2.102859, 5.4238689999999998, 5.577680e+00, 3.001240e-01, 4.8357549999999998, 8.8596050000000002, 1.592490e+00, 7.372070e+00, 7.2462879999999998, 5.9191609999999999, 5.9593920000000002, 4.6956530000000001, 6.328630e-01, 3.1591619999999998, 4.7083050000000002, 8.4356449999999992, 5.4309390000000004, 2.1190630000000001, 1.545420e-01, 2.595040e+00, 1.4655819999999999, 1.321259, 3.702925, 3.542246, 6.831162, 1.723510e+00, 7.8729019999999998, 6.0081550000000004, 1.047045]> : tensor<30xf64>) {addr_space = 0 : i32, alignment = 64 : i64} : !llvm.array<30 x f64>
  llvm.mlir.global private constant @__constant_10x10xf64(dense<[[5.0072820879405331, 2.1420497309468542, 8.4364357946217474, 3.3512684114489364, 4.8578737173077684, 6.5026873298607608, 4.481183080848961, 1.6018142840321781, 1.6482067031075565, 2.7697353449463433], [8.2796435610104453, 9.7956308688691446, 5.066309369035312, 1.0691978274975567, 7.2754747197326219, 7.4679216752662611, 1.8460472498040226, 1.7245060332115747, 9.828847678500983, 5.8523888503628294], [4.735129046344202, 0.21389279999051047, 9.9823910553584571, 0.22751442405574696, 4.3063298537464378, 1.0300462704374436, 7.1885192597496097, 1.7297134743393461, 7.4494154821665912, 8.2180913094628564], [0.55370097211729696, 7.0871105126860554, 7.7450498540614178, 4.2448327660994876, 1.2746000519648371, 9.4391729894286023, 6.1902689198805465, 6.0312877871821424, 8.7890699247898425, 3.1611885774377635], [8.9903796016343396, 3.4471256572948263, 8.4932841564173884, 9.9373309006088171, 2.6191045587156303, 0.77351004199567641, 1.4024547359632467, 7.454551829233095, 2.6194195569905077, 4.0298520046877577], [4.7641019675563543, 3.8129279818642861, 9.0747728919768225, 6.4920816381757511, 6.7882405668469881, 7.0063465072165911, 5.7386637585592792, 7.5230234961300599, 0.91592641387099771, 8.6646639602141899], [5.6862365678538973, 4.8755032417073192, 9.5859588536709328, 8.1186668576209513, 5.3811119011589454, 3.8280043169558411, 9.9983397606134918, 6.1835824149566241, 3.4201107815517515, 0.84968218962971687], [2.791270331453247, 2.9735813587818685, 3.0654358664150494, 5.4929582569491755, 3.9238922832952996, 9.2657934977933269, 5.0681592194030571, 9.6910348814034712, 2.0972430846802959, 0.96789458347651514], [3.1989914495545624, 3.7607248895716507, 5.5182323136835318, 2.4724154287944913, 7.2920674615977124, 9.7009225179758473, 9.9421519655410044, 2.6109645810252315, 9.0484630420475316, 3.6771724535825703], [6.305746358135309, 7.6948754823713771, 3.6012681436537397, 1.263350310992416, 3.8581878444772943, 7.1047027925517909, 2.1904752468927735, 0.32914734762647391, 3.1668377278172235, 2.0518472657841924]]> : tensor<10x10xf64>) {addr_space = 0 : i32, alignment = 64 : i64} : !llvm.array<10 x array<10 x f64>>
  func.func @matmul(%arg0: memref<?xindex>, %arg1: memref<?xindex>, %arg2: memref<?xf64>, %arg3: !llvm.struct<(array<2 x i64>, array<3 x i64>)>, %arg4: tensor<10x10xf64>, %arg5: tensor<10x10xf64>) -> tensor<10x10xf64> {
    %0 = llvm.mlir.poison : vector<4xf64>
    %1 = llvm.mlir.constant(10 : index) : i64
    %2 = llvm.mlir.constant(0 : i32) : i32
    %3 = llvm.mlir.poison : vector<4xi32>
    %4 = llvm.mlir.constant(10 : index) : i64
    %5 = llvm.mlir.constant(0 : index) : i64
    %6 = builtin.unrealized_conversion_cast %5 : i64 to index
    %7 = llvm.mlir.constant(1 : index) : i64
    %8 = llvm.mlir.constant(4 : index) : i64
    %9 = llvm.mlir.constant(dense<0.000000e+00> : vector<4xf64>) : vector<4xf64>
    %10 = llvm.mlir.constant(-1 : index) : i64
    %11 = llvm.mlir.constant(dense<[0, 1, 2, 3]> : vector<4xi32>) : vector<4xi32>
    %12 = builtin.unrealized_conversion_cast %arg1 : memref<?xindex> to !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %13 = builtin.unrealized_conversion_cast %arg0 : memref<?xindex> to !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %14 = builtin.unrealized_conversion_cast %arg2 : memref<?xf64> to !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %15 = llvm.extractvalue %14[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %16 = bufferization.to_memref %arg4 : tensor<10x10xf64> to memref<10x10xf64>
    %17 = builtin.unrealized_conversion_cast %16 : memref<10x10xf64> to !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)>
    %18 = bufferization.to_memref %arg5 : tensor<10x10xf64> to memref<10x10xf64>
    %19 = builtin.unrealized_conversion_cast %18 : memref<10x10xf64> to !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)>
    %20 = llvm.extractvalue %13[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %21 = llvm.extractvalue %12[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    cf.br ^bb1(%6 : index)
  ^bb1(%22: index):  // 2 preds: ^bb0, ^bb8
    %23 = builtin.unrealized_conversion_cast %22 : index to i64
    %24 = builtin.unrealized_conversion_cast %22 : index to i64
    %25 = builtin.unrealized_conversion_cast %22 : index to i64
    %26 = llvm.icmp "slt" %23, %4 : i64
    cf.cond_br %26, ^bb2, ^bb9
  ^bb2:  // pred: ^bb1
    %27 = llvm.getelementptr %20[%24] : (!llvm.ptr, i64) -> !llvm.ptr, i64
    %28 = llvm.load %27 : !llvm.ptr -> i64
    %29 = builtin.unrealized_conversion_cast %28 : i64 to index
    %30 = llvm.add %23, %7 : i64
    %31 = builtin.unrealized_conversion_cast %30 : i64 to index
    %32 = builtin.unrealized_conversion_cast %31 : index to i64
    %33 = llvm.getelementptr %20[%32] : (!llvm.ptr, i64) -> !llvm.ptr, i64
    %34 = llvm.load %33 : !llvm.ptr -> i64
    cf.br ^bb3(%29 : index)
  ^bb3(%35: index):  // 2 preds: ^bb2, ^bb7
    %36 = builtin.unrealized_conversion_cast %35 : index to i64
    %37 = builtin.unrealized_conversion_cast %35 : index to i64
    %38 = llvm.icmp "slt" %36, %34 : i64
    cf.cond_br %38, ^bb4, ^bb8
  ^bb4:  // pred: ^bb3
    %39 = llvm.getelementptr %21[%37] : (!llvm.ptr, i64) -> !llvm.ptr, i64
    %40 = llvm.load %39 : !llvm.ptr -> i64
    %41 = llvm.getelementptr %15[%37] : (!llvm.ptr, i64) -> !llvm.ptr, f64
    %42 = llvm.load %41 : !llvm.ptr -> f64
    cf.br ^bb5(%6 : index)
  ^bb5(%43: index):  // 2 preds: ^bb4, ^bb6
    %44 = builtin.unrealized_conversion_cast %43 : index to i64
    %45 = builtin.unrealized_conversion_cast %43 : index to i64
    %46 = llvm.icmp "slt" %44, %4 : i64
    cf.cond_br %46, ^bb6, ^bb7
  ^bb6:  // pred: ^bb5
    %47 = llvm.mul %44, %10 overflow<nsw> : i64
    %48 = llvm.add %47, %4 : i64
    %49 = llvm.icmp "slt" %48, %8 : i64
    %50 = llvm.select %49, %48, %8 : i1, i64
    %51 = llvm.trunc %50 : i64 to i32
    %52 = llvm.insertelement %51, %3[%2 : i32] : vector<4xi32>
    %53 = llvm.shufflevector %52, %3 [0, 0, 0, 0] : vector<4xi32> 
    %54 = llvm.icmp "sgt" %53, %11 : vector<4xi32>
    %55 = llvm.extractvalue %19[1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %56 = llvm.mul %25, %1 : i64
    %57 = llvm.add %56, %45 : i64
    %58 = llvm.getelementptr %55[%57] : (!llvm.ptr, i64) -> !llvm.ptr, f64
    %59 = llvm.intr.masked.load %58, %54, %9 {alignment = 8 : i32} : (!llvm.ptr, vector<4xi1>, vector<4xf64>) -> vector<4xf64>
    %60 = llvm.insertelement %42, %0[%2 : i32] : vector<4xf64>
    %61 = llvm.shufflevector %60, %0 [0, 0, 0, 0] : vector<4xf64> 
    %62 = llvm.extractvalue %17[1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %63 = llvm.mul %40, %1 : i64
    %64 = llvm.add %63, %45 : i64
    %65 = llvm.getelementptr %62[%64] : (!llvm.ptr, i64) -> !llvm.ptr, f64
    %66 = llvm.intr.masked.load %65, %54, %9 {alignment = 8 : i32} : (!llvm.ptr, vector<4xi1>, vector<4xf64>) -> vector<4xf64>
    %67 = llvm.fmul %61, %66 : vector<4xf64>
    %68 = llvm.fadd %59, %67 : vector<4xf64>
    %69 = llvm.extractvalue %19[1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %70 = llvm.mul %25, %1 : i64
    %71 = llvm.add %70, %45 : i64
    %72 = llvm.getelementptr %69[%71] : (!llvm.ptr, i64) -> !llvm.ptr, f64
    llvm.intr.masked.store %68, %72, %54 {alignment = 8 : i32} : vector<4xf64>, vector<4xi1> into !llvm.ptr
    %73 = llvm.add %44, %8 : i64
    %74 = builtin.unrealized_conversion_cast %73 : i64 to index
    cf.br ^bb5(%74 : index)
  ^bb7:  // pred: ^bb5
    %75 = llvm.add %36, %7 : i64
    %76 = builtin.unrealized_conversion_cast %75 : i64 to index
    cf.br ^bb3(%76 : index)
  ^bb8:  // pred: ^bb3
    %77 = llvm.add %23, %7 : i64
    %78 = builtin.unrealized_conversion_cast %77 : i64 to index
    cf.br ^bb1(%78 : index)
  ^bb9:  // pred: ^bb1
    %79 = bufferization.to_tensor %18 : memref<10x10xf64> to tensor<10x10xf64>
    return %79 : tensor<10x10xf64>
  }
  llvm.func @main() -> i64 {
    %0 = llvm.mlir.constant(0 : index) : i64
    %1 = llvm.mlir.poison : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)>
    %2 = llvm.mlir.constant(3735928559 : index) : i64
    %3 = llvm.mlir.addressof @__constant_10x10xf64 : !llvm.ptr
    %4 = llvm.mlir.constant(9 : index) : i64
    %5 = llvm.mlir.constant(8 : index) : i64
    %6 = builtin.unrealized_conversion_cast %5 : i64 to index
    %7 = llvm.mlir.constant(0.000000e+00 : f64) : f64
    %8 = llvm.mlir.constant(1 : index) : i64
    %9 = llvm.mlir.constant(10 : index) : i64
    %10 = llvm.mlir.constant(0 : index) : i64
    %11 = builtin.unrealized_conversion_cast %10 : i64 to index
    %12 = llvm.mlir.constant(10 : index) : i64
    %13 = llvm.mlir.constant(1 : index) : i64
    %14 = llvm.getelementptr %3[0, 0, 0] : (!llvm.ptr) -> !llvm.ptr, !llvm.array<10 x array<10 x f64>>
    %15 = llvm.inttoptr %2 : i64 to !llvm.ptr
    %16 = llvm.insertvalue %15, %1[0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %17 = llvm.insertvalue %14, %16[1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %18 = llvm.insertvalue %0, %17[2] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %19 = llvm.insertvalue %12, %18[3, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %20 = llvm.insertvalue %12, %19[3, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %21 = llvm.insertvalue %12, %20[4, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %22 = llvm.insertvalue %13, %21[4, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %23 = builtin.unrealized_conversion_cast %22 : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> to memref<10x10xf64>
    %24 = bufferization.to_tensor %23 : memref<10x10xf64> to tensor<10x10xf64>
    %25 = bufferization.alloc_tensor() : tensor<10x10xf64>
    %26 = llvm.call @assemble_sparse() : () -> !llvm.struct<(struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>, struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>, struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>, struct<(array<2 x i64>, array<3 x i64>)>)>
    %27 = llvm.extractvalue %26[0] : !llvm.struct<(struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>, struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>, struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>, struct<(array<2 x i64>, array<3 x i64>)>)> 
    %28 = builtin.unrealized_conversion_cast %27 : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> to memref<?xindex>
    %29 = llvm.extractvalue %26[1] : !llvm.struct<(struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>, struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>, struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>, struct<(array<2 x i64>, array<3 x i64>)>)> 
    %30 = builtin.unrealized_conversion_cast %29 : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> to memref<?xindex>
    %31 = llvm.extractvalue %26[2] : !llvm.struct<(struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>, struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>, struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>, struct<(array<2 x i64>, array<3 x i64>)>)> 
    %32 = builtin.unrealized_conversion_cast %31 : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> to memref<?xf64>
    %33 = llvm.extractvalue %26[3] : !llvm.struct<(struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>, struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>, struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>, struct<(array<2 x i64>, array<3 x i64>)>)> 
    %34 = func.call @matmul(%28, %30, %32, %33, %24, %25) : (memref<?xindex>, memref<?xindex>, memref<?xf64>, !llvm.struct<(array<2 x i64>, array<3 x i64>)>, tensor<10x10xf64>, tensor<10x10xf64>) -> tensor<10x10xf64>
    cf.br ^bb1(%11 : index)
  ^bb1(%35: index):  // 2 preds: ^bb0, ^bb7
    %36 = builtin.unrealized_conversion_cast %35 : index to i64
    %37 = llvm.icmp "slt" %36, %9 : i64
    cf.cond_br %37, ^bb2, ^bb8
  ^bb2:  // pred: ^bb1
    %38 = vector.transfer_read %34[%35, %11], %7 {in_bounds = [true]} : tensor<10x10xf64>, vector<10xf64>
    llvm.call @printOpen() : () -> ()
    cf.br ^bb3(%11 : index)
  ^bb3(%39: index):  // 2 preds: ^bb2, ^bb6
    %40 = builtin.unrealized_conversion_cast %39 : index to i64
    %41 = builtin.unrealized_conversion_cast %39 : index to i64
    %42 = llvm.icmp "slt" %40, %9 : i64
    cf.cond_br %42, ^bb4, ^bb7
  ^bb4:  // pred: ^bb3
    %43 = llvm.extractelement %38[%41 : i64] : vector<10xf64>
    llvm.call @printF64(%43) : (f64) -> ()
    %44 = llvm.icmp "ult" %40, %4 : i64
    cf.cond_br %44, ^bb5, ^bb6
  ^bb5:  // pred: ^bb4
    llvm.call @printComma() : () -> ()
    cf.br ^bb6
  ^bb6:  // 2 preds: ^bb4, ^bb5
    %45 = llvm.add %40, %8 : i64
    %46 = builtin.unrealized_conversion_cast %45 : i64 to index
    cf.br ^bb3(%46 : index)
  ^bb7:  // pred: ^bb3
    llvm.call @printClose() : () -> ()
    llvm.call @printNewline() : () -> ()
    %47 = llvm.add %36, %8 : i64
    %48 = builtin.unrealized_conversion_cast %47 : i64 to index
    cf.br ^bb1(%48 : index)
  ^bb8:  // pred: ^bb1
    %extracted = tensor.extract %34[%6, %6] : tensor<10x10xf64>
    %49 = llvm.fptosi %extracted : f64 to i64
    llvm.return %49 : i64
  }
  llvm.func @assemble_sparse() -> !llvm.struct<(struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>, struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>, struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>, struct<(array<2 x i64>, array<3 x i64>)>)> {
    %0 = llvm.mlir.addressof @__constant_30xindex : !llvm.ptr
    %1 = llvm.mlir.addressof @__constant_11xindex : !llvm.ptr
    %2 = llvm.mlir.constant(11 : index) : i64
    %3 = llvm.mlir.constant(0 : index) : i64
    %4 = llvm.mlir.poison : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %5 = llvm.mlir.constant(3735928559 : index) : i64
    %6 = llvm.mlir.addressof @__constant_30xf64 : !llvm.ptr
    %7 = llvm.mlir.constant(1 : index) : i64
    %8 = llvm.mlir.constant(30 : index) : i64
    %9 = llvm.mlir.constant(11 : i64) : i64
    %10 = llvm.mlir.constant(10 : i64) : i64
    %11 = llvm.mlir.constant(0 : i64) : i64
    %12 = llvm.mlir.poison : !llvm.struct<(array<2 x i64>, array<3 x i64>)>
    %13 = llvm.mlir.constant(10 : index) : i64
    %14 = builtin.unrealized_conversion_cast %13 : i64 to index
    %15 = builtin.unrealized_conversion_cast %14 : index to i64
    %16 = llvm.getelementptr %6[0, 0] : (!llvm.ptr) -> !llvm.ptr, !llvm.array<30 x f64>
    %17 = llvm.inttoptr %5 : i64 to !llvm.ptr
    %18 = llvm.insertvalue %17, %4[0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %19 = llvm.insertvalue %16, %18[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %20 = llvm.insertvalue %3, %19[2] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %21 = llvm.insertvalue %8, %20[3, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %22 = llvm.insertvalue %7, %21[4, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %23 = llvm.getelementptr %1[0, 0] : (!llvm.ptr) -> !llvm.ptr, !llvm.array<11 x i64>
    %24 = llvm.inttoptr %5 : i64 to !llvm.ptr
    %25 = llvm.insertvalue %24, %4[0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %26 = llvm.insertvalue %23, %25[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %27 = llvm.insertvalue %3, %26[2] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %28 = llvm.insertvalue %2, %27[3, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %29 = llvm.insertvalue %7, %28[4, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %30 = llvm.getelementptr %0[0, 0] : (!llvm.ptr) -> !llvm.ptr, !llvm.array<30 x i64>
    %31 = llvm.inttoptr %5 : i64 to !llvm.ptr
    %32 = llvm.insertvalue %31, %4[0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %33 = llvm.insertvalue %30, %32[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %34 = llvm.insertvalue %3, %33[2] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %35 = llvm.insertvalue %8, %34[3, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %36 = llvm.insertvalue %7, %35[4, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %37 = llvm.insertvalue %11, %12[1, 0] : !llvm.struct<(array<2 x i64>, array<3 x i64>)> 
    %38 = llvm.insertvalue %11, %37[1, 1] : !llvm.struct<(array<2 x i64>, array<3 x i64>)> 
    %39 = llvm.insertvalue %11, %38[1, 2] : !llvm.struct<(array<2 x i64>, array<3 x i64>)> 
    %40 = llvm.insertvalue %10, %39[0, 0] : !llvm.struct<(array<2 x i64>, array<3 x i64>)> 
    %41 = llvm.insertvalue %10, %40[0, 1] : !llvm.struct<(array<2 x i64>, array<3 x i64>)> 
    %42 = llvm.insertvalue %9, %41[1, 0] : !llvm.struct<(array<2 x i64>, array<3 x i64>)> 
    %43 = llvm.getelementptr %23[%15] : (!llvm.ptr, i64) -> !llvm.ptr, i64
    %44 = llvm.load %43 : !llvm.ptr -> i64
    %45 = llvm.insertvalue %44, %42[1, 1] : !llvm.struct<(array<2 x i64>, array<3 x i64>)> 
    %46 = llvm.insertvalue %44, %45[1, 2] : !llvm.struct<(array<2 x i64>, array<3 x i64>)> 
    %47 = llvm.mlir.poison : !llvm.struct<(struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>, struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>, struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>, struct<(array<2 x i64>, array<3 x i64>)>)>
    %48 = llvm.insertvalue %29, %47[0] : !llvm.struct<(struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>, struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>, struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>, struct<(array<2 x i64>, array<3 x i64>)>)> 
    %49 = llvm.insertvalue %36, %48[1] : !llvm.struct<(struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>, struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>, struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>, struct<(array<2 x i64>, array<3 x i64>)>)> 
    %50 = llvm.insertvalue %22, %49[2] : !llvm.struct<(struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>, struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>, struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>, struct<(array<2 x i64>, array<3 x i64>)>)> 
    %51 = llvm.insertvalue %46, %50[3] : !llvm.struct<(struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>, struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>, struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>, struct<(array<2 x i64>, array<3 x i64>)>)> 
    llvm.return %51 : !llvm.struct<(struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>, struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>, struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>, struct<(array<2 x i64>, array<3 x i64>)>)>
  }
}


// -----// IR Dump After ConvertControlFlowToLLVMPass (convert-cf-to-llvm) //----- //
module {
  llvm.func @printNewline()
  llvm.func @printClose()
  llvm.func @printComma()
  llvm.func @printF64(f64)
  llvm.func @printOpen()
  llvm.mlir.global private constant @__constant_30xindex(dense<[8, 3, 4, 6, 9, 2, 4, 0, 1, 2, 3, 5, 7, 8, 3, 6, 2, 3, 4, 5, 8, 1, 5, 7, 8, 5, 9, 4, 7, 7]> : tensor<30xindex>) {addr_space = 0 : i32, alignment = 64 : i64} : !llvm.array<30 x i64>
  llvm.mlir.global private constant @__constant_11xindex(dense<[0, 1, 5, 7, 14, 16, 21, 25, 27, 29, 30]> : tensor<11xindex>) {addr_space = 0 : i32, alignment = 64 : i64} : !llvm.array<11 x i64>
  llvm.mlir.global private constant @__constant_30xf64(dense<[4.7563469999999999, 2.102859, 5.4238689999999998, 5.577680e+00, 3.001240e-01, 4.8357549999999998, 8.8596050000000002, 1.592490e+00, 7.372070e+00, 7.2462879999999998, 5.9191609999999999, 5.9593920000000002, 4.6956530000000001, 6.328630e-01, 3.1591619999999998, 4.7083050000000002, 8.4356449999999992, 5.4309390000000004, 2.1190630000000001, 1.545420e-01, 2.595040e+00, 1.4655819999999999, 1.321259, 3.702925, 3.542246, 6.831162, 1.723510e+00, 7.8729019999999998, 6.0081550000000004, 1.047045]> : tensor<30xf64>) {addr_space = 0 : i32, alignment = 64 : i64} : !llvm.array<30 x f64>
  llvm.mlir.global private constant @__constant_10x10xf64(dense<[[5.0072820879405331, 2.1420497309468542, 8.4364357946217474, 3.3512684114489364, 4.8578737173077684, 6.5026873298607608, 4.481183080848961, 1.6018142840321781, 1.6482067031075565, 2.7697353449463433], [8.2796435610104453, 9.7956308688691446, 5.066309369035312, 1.0691978274975567, 7.2754747197326219, 7.4679216752662611, 1.8460472498040226, 1.7245060332115747, 9.828847678500983, 5.8523888503628294], [4.735129046344202, 0.21389279999051047, 9.9823910553584571, 0.22751442405574696, 4.3063298537464378, 1.0300462704374436, 7.1885192597496097, 1.7297134743393461, 7.4494154821665912, 8.2180913094628564], [0.55370097211729696, 7.0871105126860554, 7.7450498540614178, 4.2448327660994876, 1.2746000519648371, 9.4391729894286023, 6.1902689198805465, 6.0312877871821424, 8.7890699247898425, 3.1611885774377635], [8.9903796016343396, 3.4471256572948263, 8.4932841564173884, 9.9373309006088171, 2.6191045587156303, 0.77351004199567641, 1.4024547359632467, 7.454551829233095, 2.6194195569905077, 4.0298520046877577], [4.7641019675563543, 3.8129279818642861, 9.0747728919768225, 6.4920816381757511, 6.7882405668469881, 7.0063465072165911, 5.7386637585592792, 7.5230234961300599, 0.91592641387099771, 8.6646639602141899], [5.6862365678538973, 4.8755032417073192, 9.5859588536709328, 8.1186668576209513, 5.3811119011589454, 3.8280043169558411, 9.9983397606134918, 6.1835824149566241, 3.4201107815517515, 0.84968218962971687], [2.791270331453247, 2.9735813587818685, 3.0654358664150494, 5.4929582569491755, 3.9238922832952996, 9.2657934977933269, 5.0681592194030571, 9.6910348814034712, 2.0972430846802959, 0.96789458347651514], [3.1989914495545624, 3.7607248895716507, 5.5182323136835318, 2.4724154287944913, 7.2920674615977124, 9.7009225179758473, 9.9421519655410044, 2.6109645810252315, 9.0484630420475316, 3.6771724535825703], [6.305746358135309, 7.6948754823713771, 3.6012681436537397, 1.263350310992416, 3.8581878444772943, 7.1047027925517909, 2.1904752468927735, 0.32914734762647391, 3.1668377278172235, 2.0518472657841924]]> : tensor<10x10xf64>) {addr_space = 0 : i32, alignment = 64 : i64} : !llvm.array<10 x array<10 x f64>>
  func.func @matmul(%arg0: memref<?xindex>, %arg1: memref<?xindex>, %arg2: memref<?xf64>, %arg3: !llvm.struct<(array<2 x i64>, array<3 x i64>)>, %arg4: tensor<10x10xf64>, %arg5: tensor<10x10xf64>) -> tensor<10x10xf64> {
    %0 = llvm.mlir.poison : vector<4xf64>
    %1 = llvm.mlir.constant(10 : index) : i64
    %2 = llvm.mlir.constant(0 : i32) : i32
    %3 = llvm.mlir.poison : vector<4xi32>
    %4 = llvm.mlir.constant(10 : index) : i64
    %5 = llvm.mlir.constant(0 : index) : i64
    %6 = llvm.mlir.constant(1 : index) : i64
    %7 = llvm.mlir.constant(4 : index) : i64
    %8 = llvm.mlir.constant(dense<0.000000e+00> : vector<4xf64>) : vector<4xf64>
    %9 = llvm.mlir.constant(-1 : index) : i64
    %10 = llvm.mlir.constant(dense<[0, 1, 2, 3]> : vector<4xi32>) : vector<4xi32>
    %11 = builtin.unrealized_conversion_cast %arg1 : memref<?xindex> to !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %12 = builtin.unrealized_conversion_cast %arg0 : memref<?xindex> to !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %13 = builtin.unrealized_conversion_cast %arg2 : memref<?xf64> to !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %14 = llvm.extractvalue %13[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %15 = bufferization.to_memref %arg4 : tensor<10x10xf64> to memref<10x10xf64>
    %16 = builtin.unrealized_conversion_cast %15 : memref<10x10xf64> to !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)>
    %17 = bufferization.to_memref %arg5 : tensor<10x10xf64> to memref<10x10xf64>
    %18 = builtin.unrealized_conversion_cast %17 : memref<10x10xf64> to !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)>
    %19 = llvm.extractvalue %12[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %20 = llvm.extractvalue %11[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    llvm.br ^bb1(%5 : i64)
  ^bb1(%21: i64):  // 2 preds: ^bb0, ^bb8
    %22 = builtin.unrealized_conversion_cast %21 : i64 to index
    %23 = builtin.unrealized_conversion_cast %22 : index to i64
    %24 = builtin.unrealized_conversion_cast %22 : index to i64
    %25 = builtin.unrealized_conversion_cast %22 : index to i64
    %26 = llvm.icmp "slt" %23, %4 : i64
    llvm.cond_br %26, ^bb2, ^bb9
  ^bb2:  // pred: ^bb1
    %27 = llvm.getelementptr %19[%24] : (!llvm.ptr, i64) -> !llvm.ptr, i64
    %28 = llvm.load %27 : !llvm.ptr -> i64
    %29 = llvm.add %23, %6 : i64
    %30 = builtin.unrealized_conversion_cast %29 : i64 to index
    %31 = builtin.unrealized_conversion_cast %30 : index to i64
    %32 = llvm.getelementptr %19[%31] : (!llvm.ptr, i64) -> !llvm.ptr, i64
    %33 = llvm.load %32 : !llvm.ptr -> i64
    llvm.br ^bb3(%28 : i64)
  ^bb3(%34: i64):  // 2 preds: ^bb2, ^bb7
    %35 = builtin.unrealized_conversion_cast %34 : i64 to index
    %36 = builtin.unrealized_conversion_cast %35 : index to i64
    %37 = builtin.unrealized_conversion_cast %35 : index to i64
    %38 = llvm.icmp "slt" %36, %33 : i64
    llvm.cond_br %38, ^bb4, ^bb8
  ^bb4:  // pred: ^bb3
    %39 = llvm.getelementptr %20[%37] : (!llvm.ptr, i64) -> !llvm.ptr, i64
    %40 = llvm.load %39 : !llvm.ptr -> i64
    %41 = llvm.getelementptr %14[%37] : (!llvm.ptr, i64) -> !llvm.ptr, f64
    %42 = llvm.load %41 : !llvm.ptr -> f64
    llvm.br ^bb5(%5 : i64)
  ^bb5(%43: i64):  // 2 preds: ^bb4, ^bb6
    %44 = builtin.unrealized_conversion_cast %43 : i64 to index
    %45 = builtin.unrealized_conversion_cast %44 : index to i64
    %46 = builtin.unrealized_conversion_cast %44 : index to i64
    %47 = llvm.icmp "slt" %45, %4 : i64
    llvm.cond_br %47, ^bb6, ^bb7
  ^bb6:  // pred: ^bb5
    %48 = llvm.mul %45, %9 overflow<nsw> : i64
    %49 = llvm.add %48, %4 : i64
    %50 = llvm.icmp "slt" %49, %7 : i64
    %51 = llvm.select %50, %49, %7 : i1, i64
    %52 = llvm.trunc %51 : i64 to i32
    %53 = llvm.insertelement %52, %3[%2 : i32] : vector<4xi32>
    %54 = llvm.shufflevector %53, %3 [0, 0, 0, 0] : vector<4xi32> 
    %55 = llvm.icmp "sgt" %54, %10 : vector<4xi32>
    %56 = llvm.extractvalue %18[1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %57 = llvm.mul %25, %1 : i64
    %58 = llvm.add %57, %46 : i64
    %59 = llvm.getelementptr %56[%58] : (!llvm.ptr, i64) -> !llvm.ptr, f64
    %60 = llvm.intr.masked.load %59, %55, %8 {alignment = 8 : i32} : (!llvm.ptr, vector<4xi1>, vector<4xf64>) -> vector<4xf64>
    %61 = llvm.insertelement %42, %0[%2 : i32] : vector<4xf64>
    %62 = llvm.shufflevector %61, %0 [0, 0, 0, 0] : vector<4xf64> 
    %63 = llvm.extractvalue %16[1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %64 = llvm.mul %40, %1 : i64
    %65 = llvm.add %64, %46 : i64
    %66 = llvm.getelementptr %63[%65] : (!llvm.ptr, i64) -> !llvm.ptr, f64
    %67 = llvm.intr.masked.load %66, %55, %8 {alignment = 8 : i32} : (!llvm.ptr, vector<4xi1>, vector<4xf64>) -> vector<4xf64>
    %68 = llvm.fmul %62, %67 : vector<4xf64>
    %69 = llvm.fadd %60, %68 : vector<4xf64>
    %70 = llvm.extractvalue %18[1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %71 = llvm.mul %25, %1 : i64
    %72 = llvm.add %71, %46 : i64
    %73 = llvm.getelementptr %70[%72] : (!llvm.ptr, i64) -> !llvm.ptr, f64
    llvm.intr.masked.store %69, %73, %55 {alignment = 8 : i32} : vector<4xf64>, vector<4xi1> into !llvm.ptr
    %74 = llvm.add %45, %7 : i64
    llvm.br ^bb5(%74 : i64)
  ^bb7:  // pred: ^bb5
    %75 = llvm.add %36, %6 : i64
    llvm.br ^bb3(%75 : i64)
  ^bb8:  // pred: ^bb3
    %76 = llvm.add %23, %6 : i64
    llvm.br ^bb1(%76 : i64)
  ^bb9:  // pred: ^bb1
    %77 = bufferization.to_tensor %17 : memref<10x10xf64> to tensor<10x10xf64>
    return %77 : tensor<10x10xf64>
  }
  llvm.func @main() -> i64 {
    %0 = llvm.mlir.constant(0 : index) : i64
    %1 = llvm.mlir.poison : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)>
    %2 = llvm.mlir.constant(3735928559 : index) : i64
    %3 = llvm.mlir.addressof @__constant_10x10xf64 : !llvm.ptr
    %4 = llvm.mlir.constant(9 : index) : i64
    %5 = llvm.mlir.constant(8 : index) : i64
    %6 = builtin.unrealized_conversion_cast %5 : i64 to index
    %7 = llvm.mlir.constant(0.000000e+00 : f64) : f64
    %8 = llvm.mlir.constant(1 : index) : i64
    %9 = llvm.mlir.constant(10 : index) : i64
    %10 = llvm.mlir.constant(0 : index) : i64
    %11 = builtin.unrealized_conversion_cast %10 : i64 to index
    %12 = llvm.mlir.constant(10 : index) : i64
    %13 = llvm.mlir.constant(1 : index) : i64
    %14 = llvm.getelementptr %3[0, 0, 0] : (!llvm.ptr) -> !llvm.ptr, !llvm.array<10 x array<10 x f64>>
    %15 = llvm.inttoptr %2 : i64 to !llvm.ptr
    %16 = llvm.insertvalue %15, %1[0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %17 = llvm.insertvalue %14, %16[1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %18 = llvm.insertvalue %0, %17[2] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %19 = llvm.insertvalue %12, %18[3, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %20 = llvm.insertvalue %12, %19[3, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %21 = llvm.insertvalue %12, %20[4, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %22 = llvm.insertvalue %13, %21[4, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %23 = builtin.unrealized_conversion_cast %22 : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> to memref<10x10xf64>
    %24 = bufferization.to_tensor %23 : memref<10x10xf64> to tensor<10x10xf64>
    %25 = bufferization.alloc_tensor() : tensor<10x10xf64>
    %26 = llvm.call @assemble_sparse() : () -> !llvm.struct<(struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>, struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>, struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>, struct<(array<2 x i64>, array<3 x i64>)>)>
    %27 = llvm.extractvalue %26[0] : !llvm.struct<(struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>, struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>, struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>, struct<(array<2 x i64>, array<3 x i64>)>)> 
    %28 = builtin.unrealized_conversion_cast %27 : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> to memref<?xindex>
    %29 = llvm.extractvalue %26[1] : !llvm.struct<(struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>, struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>, struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>, struct<(array<2 x i64>, array<3 x i64>)>)> 
    %30 = builtin.unrealized_conversion_cast %29 : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> to memref<?xindex>
    %31 = llvm.extractvalue %26[2] : !llvm.struct<(struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>, struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>, struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>, struct<(array<2 x i64>, array<3 x i64>)>)> 
    %32 = builtin.unrealized_conversion_cast %31 : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> to memref<?xf64>
    %33 = llvm.extractvalue %26[3] : !llvm.struct<(struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>, struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>, struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>, struct<(array<2 x i64>, array<3 x i64>)>)> 
    %34 = func.call @matmul(%28, %30, %32, %33, %24, %25) : (memref<?xindex>, memref<?xindex>, memref<?xf64>, !llvm.struct<(array<2 x i64>, array<3 x i64>)>, tensor<10x10xf64>, tensor<10x10xf64>) -> tensor<10x10xf64>
    llvm.br ^bb1(%10 : i64)
  ^bb1(%35: i64):  // 2 preds: ^bb0, ^bb7
    %36 = builtin.unrealized_conversion_cast %35 : i64 to index
    %37 = builtin.unrealized_conversion_cast %36 : index to i64
    %38 = llvm.icmp "slt" %37, %9 : i64
    llvm.cond_br %38, ^bb2, ^bb8
  ^bb2:  // pred: ^bb1
    %39 = vector.transfer_read %34[%36, %11], %7 {in_bounds = [true]} : tensor<10x10xf64>, vector<10xf64>
    llvm.call @printOpen() : () -> ()
    llvm.br ^bb3(%10 : i64)
  ^bb3(%40: i64):  // 2 preds: ^bb2, ^bb6
    %41 = builtin.unrealized_conversion_cast %40 : i64 to index
    %42 = builtin.unrealized_conversion_cast %41 : index to i64
    %43 = builtin.unrealized_conversion_cast %41 : index to i64
    %44 = llvm.icmp "slt" %42, %9 : i64
    llvm.cond_br %44, ^bb4, ^bb7
  ^bb4:  // pred: ^bb3
    %45 = llvm.extractelement %39[%43 : i64] : vector<10xf64>
    llvm.call @printF64(%45) : (f64) -> ()
    %46 = llvm.icmp "ult" %42, %4 : i64
    llvm.cond_br %46, ^bb5, ^bb6
  ^bb5:  // pred: ^bb4
    llvm.call @printComma() : () -> ()
    llvm.br ^bb6
  ^bb6:  // 2 preds: ^bb4, ^bb5
    %47 = llvm.add %42, %8 : i64
    llvm.br ^bb3(%47 : i64)
  ^bb7:  // pred: ^bb3
    llvm.call @printClose() : () -> ()
    llvm.call @printNewline() : () -> ()
    %48 = llvm.add %37, %8 : i64
    llvm.br ^bb1(%48 : i64)
  ^bb8:  // pred: ^bb1
    %extracted = tensor.extract %34[%6, %6] : tensor<10x10xf64>
    %49 = llvm.fptosi %extracted : f64 to i64
    llvm.return %49 : i64
  }
  llvm.func @assemble_sparse() -> !llvm.struct<(struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>, struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>, struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>, struct<(array<2 x i64>, array<3 x i64>)>)> {
    %0 = llvm.mlir.addressof @__constant_30xindex : !llvm.ptr
    %1 = llvm.mlir.addressof @__constant_11xindex : !llvm.ptr
    %2 = llvm.mlir.constant(11 : index) : i64
    %3 = llvm.mlir.constant(0 : index) : i64
    %4 = llvm.mlir.poison : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %5 = llvm.mlir.constant(3735928559 : index) : i64
    %6 = llvm.mlir.addressof @__constant_30xf64 : !llvm.ptr
    %7 = llvm.mlir.constant(1 : index) : i64
    %8 = llvm.mlir.constant(30 : index) : i64
    %9 = llvm.mlir.constant(11 : i64) : i64
    %10 = llvm.mlir.constant(10 : i64) : i64
    %11 = llvm.mlir.constant(0 : i64) : i64
    %12 = llvm.mlir.poison : !llvm.struct<(array<2 x i64>, array<3 x i64>)>
    %13 = llvm.mlir.constant(10 : index) : i64
    %14 = builtin.unrealized_conversion_cast %13 : i64 to index
    %15 = builtin.unrealized_conversion_cast %14 : index to i64
    %16 = llvm.getelementptr %6[0, 0] : (!llvm.ptr) -> !llvm.ptr, !llvm.array<30 x f64>
    %17 = llvm.inttoptr %5 : i64 to !llvm.ptr
    %18 = llvm.insertvalue %17, %4[0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %19 = llvm.insertvalue %16, %18[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %20 = llvm.insertvalue %3, %19[2] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %21 = llvm.insertvalue %8, %20[3, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %22 = llvm.insertvalue %7, %21[4, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %23 = llvm.getelementptr %1[0, 0] : (!llvm.ptr) -> !llvm.ptr, !llvm.array<11 x i64>
    %24 = llvm.inttoptr %5 : i64 to !llvm.ptr
    %25 = llvm.insertvalue %24, %4[0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %26 = llvm.insertvalue %23, %25[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %27 = llvm.insertvalue %3, %26[2] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %28 = llvm.insertvalue %2, %27[3, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %29 = llvm.insertvalue %7, %28[4, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %30 = llvm.getelementptr %0[0, 0] : (!llvm.ptr) -> !llvm.ptr, !llvm.array<30 x i64>
    %31 = llvm.inttoptr %5 : i64 to !llvm.ptr
    %32 = llvm.insertvalue %31, %4[0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %33 = llvm.insertvalue %30, %32[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %34 = llvm.insertvalue %3, %33[2] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %35 = llvm.insertvalue %8, %34[3, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %36 = llvm.insertvalue %7, %35[4, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %37 = llvm.insertvalue %11, %12[1, 0] : !llvm.struct<(array<2 x i64>, array<3 x i64>)> 
    %38 = llvm.insertvalue %11, %37[1, 1] : !llvm.struct<(array<2 x i64>, array<3 x i64>)> 
    %39 = llvm.insertvalue %11, %38[1, 2] : !llvm.struct<(array<2 x i64>, array<3 x i64>)> 
    %40 = llvm.insertvalue %10, %39[0, 0] : !llvm.struct<(array<2 x i64>, array<3 x i64>)> 
    %41 = llvm.insertvalue %10, %40[0, 1] : !llvm.struct<(array<2 x i64>, array<3 x i64>)> 
    %42 = llvm.insertvalue %9, %41[1, 0] : !llvm.struct<(array<2 x i64>, array<3 x i64>)> 
    %43 = llvm.getelementptr %23[%15] : (!llvm.ptr, i64) -> !llvm.ptr, i64
    %44 = llvm.load %43 : !llvm.ptr -> i64
    %45 = llvm.insertvalue %44, %42[1, 1] : !llvm.struct<(array<2 x i64>, array<3 x i64>)> 
    %46 = llvm.insertvalue %44, %45[1, 2] : !llvm.struct<(array<2 x i64>, array<3 x i64>)> 
    %47 = llvm.mlir.poison : !llvm.struct<(struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>, struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>, struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>, struct<(array<2 x i64>, array<3 x i64>)>)>
    %48 = llvm.insertvalue %29, %47[0] : !llvm.struct<(struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>, struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>, struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>, struct<(array<2 x i64>, array<3 x i64>)>)> 
    %49 = llvm.insertvalue %36, %48[1] : !llvm.struct<(struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>, struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>, struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>, struct<(array<2 x i64>, array<3 x i64>)>)> 
    %50 = llvm.insertvalue %22, %49[2] : !llvm.struct<(struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>, struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>, struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>, struct<(array<2 x i64>, array<3 x i64>)>)> 
    %51 = llvm.insertvalue %46, %50[3] : !llvm.struct<(struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>, struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>, struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>, struct<(array<2 x i64>, array<3 x i64>)>)> 
    llvm.return %51 : !llvm.struct<(struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>, struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>, struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>, struct<(array<2 x i64>, array<3 x i64>)>)>
  }
}


// -----// IR Dump After UBToLLVMConversionPass (convert-ub-to-llvm) //----- //
module {
  llvm.func @printNewline()
  llvm.func @printClose()
  llvm.func @printComma()
  llvm.func @printF64(f64)
  llvm.func @printOpen()
  llvm.mlir.global private constant @__constant_30xindex(dense<[8, 3, 4, 6, 9, 2, 4, 0, 1, 2, 3, 5, 7, 8, 3, 6, 2, 3, 4, 5, 8, 1, 5, 7, 8, 5, 9, 4, 7, 7]> : tensor<30xindex>) {addr_space = 0 : i32, alignment = 64 : i64} : !llvm.array<30 x i64>
  llvm.mlir.global private constant @__constant_11xindex(dense<[0, 1, 5, 7, 14, 16, 21, 25, 27, 29, 30]> : tensor<11xindex>) {addr_space = 0 : i32, alignment = 64 : i64} : !llvm.array<11 x i64>
  llvm.mlir.global private constant @__constant_30xf64(dense<[4.7563469999999999, 2.102859, 5.4238689999999998, 5.577680e+00, 3.001240e-01, 4.8357549999999998, 8.8596050000000002, 1.592490e+00, 7.372070e+00, 7.2462879999999998, 5.9191609999999999, 5.9593920000000002, 4.6956530000000001, 6.328630e-01, 3.1591619999999998, 4.7083050000000002, 8.4356449999999992, 5.4309390000000004, 2.1190630000000001, 1.545420e-01, 2.595040e+00, 1.4655819999999999, 1.321259, 3.702925, 3.542246, 6.831162, 1.723510e+00, 7.8729019999999998, 6.0081550000000004, 1.047045]> : tensor<30xf64>) {addr_space = 0 : i32, alignment = 64 : i64} : !llvm.array<30 x f64>
  llvm.mlir.global private constant @__constant_10x10xf64(dense<[[5.0072820879405331, 2.1420497309468542, 8.4364357946217474, 3.3512684114489364, 4.8578737173077684, 6.5026873298607608, 4.481183080848961, 1.6018142840321781, 1.6482067031075565, 2.7697353449463433], [8.2796435610104453, 9.7956308688691446, 5.066309369035312, 1.0691978274975567, 7.2754747197326219, 7.4679216752662611, 1.8460472498040226, 1.7245060332115747, 9.828847678500983, 5.8523888503628294], [4.735129046344202, 0.21389279999051047, 9.9823910553584571, 0.22751442405574696, 4.3063298537464378, 1.0300462704374436, 7.1885192597496097, 1.7297134743393461, 7.4494154821665912, 8.2180913094628564], [0.55370097211729696, 7.0871105126860554, 7.7450498540614178, 4.2448327660994876, 1.2746000519648371, 9.4391729894286023, 6.1902689198805465, 6.0312877871821424, 8.7890699247898425, 3.1611885774377635], [8.9903796016343396, 3.4471256572948263, 8.4932841564173884, 9.9373309006088171, 2.6191045587156303, 0.77351004199567641, 1.4024547359632467, 7.454551829233095, 2.6194195569905077, 4.0298520046877577], [4.7641019675563543, 3.8129279818642861, 9.0747728919768225, 6.4920816381757511, 6.7882405668469881, 7.0063465072165911, 5.7386637585592792, 7.5230234961300599, 0.91592641387099771, 8.6646639602141899], [5.6862365678538973, 4.8755032417073192, 9.5859588536709328, 8.1186668576209513, 5.3811119011589454, 3.8280043169558411, 9.9983397606134918, 6.1835824149566241, 3.4201107815517515, 0.84968218962971687], [2.791270331453247, 2.9735813587818685, 3.0654358664150494, 5.4929582569491755, 3.9238922832952996, 9.2657934977933269, 5.0681592194030571, 9.6910348814034712, 2.0972430846802959, 0.96789458347651514], [3.1989914495545624, 3.7607248895716507, 5.5182323136835318, 2.4724154287944913, 7.2920674615977124, 9.7009225179758473, 9.9421519655410044, 2.6109645810252315, 9.0484630420475316, 3.6771724535825703], [6.305746358135309, 7.6948754823713771, 3.6012681436537397, 1.263350310992416, 3.8581878444772943, 7.1047027925517909, 2.1904752468927735, 0.32914734762647391, 3.1668377278172235, 2.0518472657841924]]> : tensor<10x10xf64>) {addr_space = 0 : i32, alignment = 64 : i64} : !llvm.array<10 x array<10 x f64>>
  func.func @matmul(%arg0: memref<?xindex>, %arg1: memref<?xindex>, %arg2: memref<?xf64>, %arg3: !llvm.struct<(array<2 x i64>, array<3 x i64>)>, %arg4: tensor<10x10xf64>, %arg5: tensor<10x10xf64>) -> tensor<10x10xf64> {
    %0 = llvm.mlir.poison : vector<4xf64>
    %1 = llvm.mlir.constant(10 : index) : i64
    %2 = llvm.mlir.constant(0 : i32) : i32
    %3 = llvm.mlir.poison : vector<4xi32>
    %4 = llvm.mlir.constant(10 : index) : i64
    %5 = llvm.mlir.constant(0 : index) : i64
    %6 = llvm.mlir.constant(1 : index) : i64
    %7 = llvm.mlir.constant(4 : index) : i64
    %8 = llvm.mlir.constant(dense<0.000000e+00> : vector<4xf64>) : vector<4xf64>
    %9 = llvm.mlir.constant(-1 : index) : i64
    %10 = llvm.mlir.constant(dense<[0, 1, 2, 3]> : vector<4xi32>) : vector<4xi32>
    %11 = builtin.unrealized_conversion_cast %arg1 : memref<?xindex> to !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %12 = builtin.unrealized_conversion_cast %arg0 : memref<?xindex> to !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %13 = builtin.unrealized_conversion_cast %arg2 : memref<?xf64> to !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %14 = llvm.extractvalue %13[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %15 = bufferization.to_memref %arg4 : tensor<10x10xf64> to memref<10x10xf64>
    %16 = builtin.unrealized_conversion_cast %15 : memref<10x10xf64> to !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)>
    %17 = bufferization.to_memref %arg5 : tensor<10x10xf64> to memref<10x10xf64>
    %18 = builtin.unrealized_conversion_cast %17 : memref<10x10xf64> to !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)>
    %19 = llvm.extractvalue %12[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %20 = llvm.extractvalue %11[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    llvm.br ^bb1(%5 : i64)
  ^bb1(%21: i64):  // 2 preds: ^bb0, ^bb8
    %22 = builtin.unrealized_conversion_cast %21 : i64 to index
    %23 = builtin.unrealized_conversion_cast %22 : index to i64
    %24 = builtin.unrealized_conversion_cast %22 : index to i64
    %25 = builtin.unrealized_conversion_cast %22 : index to i64
    %26 = llvm.icmp "slt" %23, %4 : i64
    llvm.cond_br %26, ^bb2, ^bb9
  ^bb2:  // pred: ^bb1
    %27 = llvm.getelementptr %19[%24] : (!llvm.ptr, i64) -> !llvm.ptr, i64
    %28 = llvm.load %27 : !llvm.ptr -> i64
    %29 = llvm.add %23, %6 : i64
    %30 = builtin.unrealized_conversion_cast %29 : i64 to index
    %31 = builtin.unrealized_conversion_cast %30 : index to i64
    %32 = llvm.getelementptr %19[%31] : (!llvm.ptr, i64) -> !llvm.ptr, i64
    %33 = llvm.load %32 : !llvm.ptr -> i64
    llvm.br ^bb3(%28 : i64)
  ^bb3(%34: i64):  // 2 preds: ^bb2, ^bb7
    %35 = builtin.unrealized_conversion_cast %34 : i64 to index
    %36 = builtin.unrealized_conversion_cast %35 : index to i64
    %37 = builtin.unrealized_conversion_cast %35 : index to i64
    %38 = llvm.icmp "slt" %36, %33 : i64
    llvm.cond_br %38, ^bb4, ^bb8
  ^bb4:  // pred: ^bb3
    %39 = llvm.getelementptr %20[%37] : (!llvm.ptr, i64) -> !llvm.ptr, i64
    %40 = llvm.load %39 : !llvm.ptr -> i64
    %41 = llvm.getelementptr %14[%37] : (!llvm.ptr, i64) -> !llvm.ptr, f64
    %42 = llvm.load %41 : !llvm.ptr -> f64
    llvm.br ^bb5(%5 : i64)
  ^bb5(%43: i64):  // 2 preds: ^bb4, ^bb6
    %44 = builtin.unrealized_conversion_cast %43 : i64 to index
    %45 = builtin.unrealized_conversion_cast %44 : index to i64
    %46 = builtin.unrealized_conversion_cast %44 : index to i64
    %47 = llvm.icmp "slt" %45, %4 : i64
    llvm.cond_br %47, ^bb6, ^bb7
  ^bb6:  // pred: ^bb5
    %48 = llvm.mul %45, %9 overflow<nsw> : i64
    %49 = llvm.add %48, %4 : i64
    %50 = llvm.icmp "slt" %49, %7 : i64
    %51 = llvm.select %50, %49, %7 : i1, i64
    %52 = llvm.trunc %51 : i64 to i32
    %53 = llvm.insertelement %52, %3[%2 : i32] : vector<4xi32>
    %54 = llvm.shufflevector %53, %3 [0, 0, 0, 0] : vector<4xi32> 
    %55 = llvm.icmp "sgt" %54, %10 : vector<4xi32>
    %56 = llvm.extractvalue %18[1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %57 = llvm.mul %25, %1 : i64
    %58 = llvm.add %57, %46 : i64
    %59 = llvm.getelementptr %56[%58] : (!llvm.ptr, i64) -> !llvm.ptr, f64
    %60 = llvm.intr.masked.load %59, %55, %8 {alignment = 8 : i32} : (!llvm.ptr, vector<4xi1>, vector<4xf64>) -> vector<4xf64>
    %61 = llvm.insertelement %42, %0[%2 : i32] : vector<4xf64>
    %62 = llvm.shufflevector %61, %0 [0, 0, 0, 0] : vector<4xf64> 
    %63 = llvm.extractvalue %16[1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %64 = llvm.mul %40, %1 : i64
    %65 = llvm.add %64, %46 : i64
    %66 = llvm.getelementptr %63[%65] : (!llvm.ptr, i64) -> !llvm.ptr, f64
    %67 = llvm.intr.masked.load %66, %55, %8 {alignment = 8 : i32} : (!llvm.ptr, vector<4xi1>, vector<4xf64>) -> vector<4xf64>
    %68 = llvm.fmul %62, %67 : vector<4xf64>
    %69 = llvm.fadd %60, %68 : vector<4xf64>
    %70 = llvm.extractvalue %18[1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %71 = llvm.mul %25, %1 : i64
    %72 = llvm.add %71, %46 : i64
    %73 = llvm.getelementptr %70[%72] : (!llvm.ptr, i64) -> !llvm.ptr, f64
    llvm.intr.masked.store %69, %73, %55 {alignment = 8 : i32} : vector<4xf64>, vector<4xi1> into !llvm.ptr
    %74 = llvm.add %45, %7 : i64
    llvm.br ^bb5(%74 : i64)
  ^bb7:  // pred: ^bb5
    %75 = llvm.add %36, %6 : i64
    llvm.br ^bb3(%75 : i64)
  ^bb8:  // pred: ^bb3
    %76 = llvm.add %23, %6 : i64
    llvm.br ^bb1(%76 : i64)
  ^bb9:  // pred: ^bb1
    %77 = bufferization.to_tensor %17 : memref<10x10xf64> to tensor<10x10xf64>
    return %77 : tensor<10x10xf64>
  }
  llvm.func @main() -> i64 {
    %0 = llvm.mlir.constant(0 : index) : i64
    %1 = llvm.mlir.poison : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)>
    %2 = llvm.mlir.constant(3735928559 : index) : i64
    %3 = llvm.mlir.addressof @__constant_10x10xf64 : !llvm.ptr
    %4 = llvm.mlir.constant(9 : index) : i64
    %5 = llvm.mlir.constant(8 : index) : i64
    %6 = builtin.unrealized_conversion_cast %5 : i64 to index
    %7 = llvm.mlir.constant(0.000000e+00 : f64) : f64
    %8 = llvm.mlir.constant(1 : index) : i64
    %9 = llvm.mlir.constant(10 : index) : i64
    %10 = llvm.mlir.constant(0 : index) : i64
    %11 = builtin.unrealized_conversion_cast %10 : i64 to index
    %12 = llvm.mlir.constant(10 : index) : i64
    %13 = llvm.mlir.constant(1 : index) : i64
    %14 = llvm.getelementptr %3[0, 0, 0] : (!llvm.ptr) -> !llvm.ptr, !llvm.array<10 x array<10 x f64>>
    %15 = llvm.inttoptr %2 : i64 to !llvm.ptr
    %16 = llvm.insertvalue %15, %1[0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %17 = llvm.insertvalue %14, %16[1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %18 = llvm.insertvalue %0, %17[2] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %19 = llvm.insertvalue %12, %18[3, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %20 = llvm.insertvalue %12, %19[3, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %21 = llvm.insertvalue %12, %20[4, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %22 = llvm.insertvalue %13, %21[4, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %23 = builtin.unrealized_conversion_cast %22 : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> to memref<10x10xf64>
    %24 = bufferization.to_tensor %23 : memref<10x10xf64> to tensor<10x10xf64>
    %25 = bufferization.alloc_tensor() : tensor<10x10xf64>
    %26 = llvm.call @assemble_sparse() : () -> !llvm.struct<(struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>, struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>, struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>, struct<(array<2 x i64>, array<3 x i64>)>)>
    %27 = llvm.extractvalue %26[0] : !llvm.struct<(struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>, struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>, struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>, struct<(array<2 x i64>, array<3 x i64>)>)> 
    %28 = builtin.unrealized_conversion_cast %27 : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> to memref<?xindex>
    %29 = llvm.extractvalue %26[1] : !llvm.struct<(struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>, struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>, struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>, struct<(array<2 x i64>, array<3 x i64>)>)> 
    %30 = builtin.unrealized_conversion_cast %29 : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> to memref<?xindex>
    %31 = llvm.extractvalue %26[2] : !llvm.struct<(struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>, struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>, struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>, struct<(array<2 x i64>, array<3 x i64>)>)> 
    %32 = builtin.unrealized_conversion_cast %31 : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> to memref<?xf64>
    %33 = llvm.extractvalue %26[3] : !llvm.struct<(struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>, struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>, struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>, struct<(array<2 x i64>, array<3 x i64>)>)> 
    %34 = func.call @matmul(%28, %30, %32, %33, %24, %25) : (memref<?xindex>, memref<?xindex>, memref<?xf64>, !llvm.struct<(array<2 x i64>, array<3 x i64>)>, tensor<10x10xf64>, tensor<10x10xf64>) -> tensor<10x10xf64>
    llvm.br ^bb1(%10 : i64)
  ^bb1(%35: i64):  // 2 preds: ^bb0, ^bb7
    %36 = builtin.unrealized_conversion_cast %35 : i64 to index
    %37 = builtin.unrealized_conversion_cast %36 : index to i64
    %38 = llvm.icmp "slt" %37, %9 : i64
    llvm.cond_br %38, ^bb2, ^bb8
  ^bb2:  // pred: ^bb1
    %39 = vector.transfer_read %34[%36, %11], %7 {in_bounds = [true]} : tensor<10x10xf64>, vector<10xf64>
    llvm.call @printOpen() : () -> ()
    llvm.br ^bb3(%10 : i64)
  ^bb3(%40: i64):  // 2 preds: ^bb2, ^bb6
    %41 = builtin.unrealized_conversion_cast %40 : i64 to index
    %42 = builtin.unrealized_conversion_cast %41 : index to i64
    %43 = builtin.unrealized_conversion_cast %41 : index to i64
    %44 = llvm.icmp "slt" %42, %9 : i64
    llvm.cond_br %44, ^bb4, ^bb7
  ^bb4:  // pred: ^bb3
    %45 = llvm.extractelement %39[%43 : i64] : vector<10xf64>
    llvm.call @printF64(%45) : (f64) -> ()
    %46 = llvm.icmp "ult" %42, %4 : i64
    llvm.cond_br %46, ^bb5, ^bb6
  ^bb5:  // pred: ^bb4
    llvm.call @printComma() : () -> ()
    llvm.br ^bb6
  ^bb6:  // 2 preds: ^bb4, ^bb5
    %47 = llvm.add %42, %8 : i64
    llvm.br ^bb3(%47 : i64)
  ^bb7:  // pred: ^bb3
    llvm.call @printClose() : () -> ()
    llvm.call @printNewline() : () -> ()
    %48 = llvm.add %37, %8 : i64
    llvm.br ^bb1(%48 : i64)
  ^bb8:  // pred: ^bb1
    %extracted = tensor.extract %34[%6, %6] : tensor<10x10xf64>
    %49 = llvm.fptosi %extracted : f64 to i64
    llvm.return %49 : i64
  }
  llvm.func @assemble_sparse() -> !llvm.struct<(struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>, struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>, struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>, struct<(array<2 x i64>, array<3 x i64>)>)> {
    %0 = llvm.mlir.addressof @__constant_30xindex : !llvm.ptr
    %1 = llvm.mlir.addressof @__constant_11xindex : !llvm.ptr
    %2 = llvm.mlir.constant(11 : index) : i64
    %3 = llvm.mlir.constant(0 : index) : i64
    %4 = llvm.mlir.poison : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %5 = llvm.mlir.constant(3735928559 : index) : i64
    %6 = llvm.mlir.addressof @__constant_30xf64 : !llvm.ptr
    %7 = llvm.mlir.constant(1 : index) : i64
    %8 = llvm.mlir.constant(30 : index) : i64
    %9 = llvm.mlir.constant(11 : i64) : i64
    %10 = llvm.mlir.constant(10 : i64) : i64
    %11 = llvm.mlir.constant(0 : i64) : i64
    %12 = llvm.mlir.poison : !llvm.struct<(array<2 x i64>, array<3 x i64>)>
    %13 = llvm.mlir.constant(10 : index) : i64
    %14 = builtin.unrealized_conversion_cast %13 : i64 to index
    %15 = builtin.unrealized_conversion_cast %14 : index to i64
    %16 = llvm.getelementptr %6[0, 0] : (!llvm.ptr) -> !llvm.ptr, !llvm.array<30 x f64>
    %17 = llvm.inttoptr %5 : i64 to !llvm.ptr
    %18 = llvm.insertvalue %17, %4[0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %19 = llvm.insertvalue %16, %18[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %20 = llvm.insertvalue %3, %19[2] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %21 = llvm.insertvalue %8, %20[3, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %22 = llvm.insertvalue %7, %21[4, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %23 = llvm.getelementptr %1[0, 0] : (!llvm.ptr) -> !llvm.ptr, !llvm.array<11 x i64>
    %24 = llvm.inttoptr %5 : i64 to !llvm.ptr
    %25 = llvm.insertvalue %24, %4[0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %26 = llvm.insertvalue %23, %25[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %27 = llvm.insertvalue %3, %26[2] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %28 = llvm.insertvalue %2, %27[3, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %29 = llvm.insertvalue %7, %28[4, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %30 = llvm.getelementptr %0[0, 0] : (!llvm.ptr) -> !llvm.ptr, !llvm.array<30 x i64>
    %31 = llvm.inttoptr %5 : i64 to !llvm.ptr
    %32 = llvm.insertvalue %31, %4[0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %33 = llvm.insertvalue %30, %32[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %34 = llvm.insertvalue %3, %33[2] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %35 = llvm.insertvalue %8, %34[3, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %36 = llvm.insertvalue %7, %35[4, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %37 = llvm.insertvalue %11, %12[1, 0] : !llvm.struct<(array<2 x i64>, array<3 x i64>)> 
    %38 = llvm.insertvalue %11, %37[1, 1] : !llvm.struct<(array<2 x i64>, array<3 x i64>)> 
    %39 = llvm.insertvalue %11, %38[1, 2] : !llvm.struct<(array<2 x i64>, array<3 x i64>)> 
    %40 = llvm.insertvalue %10, %39[0, 0] : !llvm.struct<(array<2 x i64>, array<3 x i64>)> 
    %41 = llvm.insertvalue %10, %40[0, 1] : !llvm.struct<(array<2 x i64>, array<3 x i64>)> 
    %42 = llvm.insertvalue %9, %41[1, 0] : !llvm.struct<(array<2 x i64>, array<3 x i64>)> 
    %43 = llvm.getelementptr %23[%15] : (!llvm.ptr, i64) -> !llvm.ptr, i64
    %44 = llvm.load %43 : !llvm.ptr -> i64
    %45 = llvm.insertvalue %44, %42[1, 1] : !llvm.struct<(array<2 x i64>, array<3 x i64>)> 
    %46 = llvm.insertvalue %44, %45[1, 2] : !llvm.struct<(array<2 x i64>, array<3 x i64>)> 
    %47 = llvm.mlir.poison : !llvm.struct<(struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>, struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>, struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>, struct<(array<2 x i64>, array<3 x i64>)>)>
    %48 = llvm.insertvalue %29, %47[0] : !llvm.struct<(struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>, struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>, struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>, struct<(array<2 x i64>, array<3 x i64>)>)> 
    %49 = llvm.insertvalue %36, %48[1] : !llvm.struct<(struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>, struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>, struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>, struct<(array<2 x i64>, array<3 x i64>)>)> 
    %50 = llvm.insertvalue %22, %49[2] : !llvm.struct<(struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>, struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>, struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>, struct<(array<2 x i64>, array<3 x i64>)>)> 
    %51 = llvm.insertvalue %46, %50[3] : !llvm.struct<(struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>, struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>, struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>, struct<(array<2 x i64>, array<3 x i64>)>)> 
    llvm.return %51 : !llvm.struct<(struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>, struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>, struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>, struct<(array<2 x i64>, array<3 x i64>)>)>
  }
}


// -----// IR Dump After ReconcileUnrealizedCastsPass (reconcile-unrealized-casts) //----- //
module {
  llvm.func @printNewline()
  llvm.func @printClose()
  llvm.func @printComma()
  llvm.func @printF64(f64)
  llvm.func @printOpen()
  llvm.mlir.global private constant @__constant_30xindex(dense<[8, 3, 4, 6, 9, 2, 4, 0, 1, 2, 3, 5, 7, 8, 3, 6, 2, 3, 4, 5, 8, 1, 5, 7, 8, 5, 9, 4, 7, 7]> : tensor<30xindex>) {addr_space = 0 : i32, alignment = 64 : i64} : !llvm.array<30 x i64>
  llvm.mlir.global private constant @__constant_11xindex(dense<[0, 1, 5, 7, 14, 16, 21, 25, 27, 29, 30]> : tensor<11xindex>) {addr_space = 0 : i32, alignment = 64 : i64} : !llvm.array<11 x i64>
  llvm.mlir.global private constant @__constant_30xf64(dense<[4.7563469999999999, 2.102859, 5.4238689999999998, 5.577680e+00, 3.001240e-01, 4.8357549999999998, 8.8596050000000002, 1.592490e+00, 7.372070e+00, 7.2462879999999998, 5.9191609999999999, 5.9593920000000002, 4.6956530000000001, 6.328630e-01, 3.1591619999999998, 4.7083050000000002, 8.4356449999999992, 5.4309390000000004, 2.1190630000000001, 1.545420e-01, 2.595040e+00, 1.4655819999999999, 1.321259, 3.702925, 3.542246, 6.831162, 1.723510e+00, 7.8729019999999998, 6.0081550000000004, 1.047045]> : tensor<30xf64>) {addr_space = 0 : i32, alignment = 64 : i64} : !llvm.array<30 x f64>
  llvm.mlir.global private constant @__constant_10x10xf64(dense<[[5.0072820879405331, 2.1420497309468542, 8.4364357946217474, 3.3512684114489364, 4.8578737173077684, 6.5026873298607608, 4.481183080848961, 1.6018142840321781, 1.6482067031075565, 2.7697353449463433], [8.2796435610104453, 9.7956308688691446, 5.066309369035312, 1.0691978274975567, 7.2754747197326219, 7.4679216752662611, 1.8460472498040226, 1.7245060332115747, 9.828847678500983, 5.8523888503628294], [4.735129046344202, 0.21389279999051047, 9.9823910553584571, 0.22751442405574696, 4.3063298537464378, 1.0300462704374436, 7.1885192597496097, 1.7297134743393461, 7.4494154821665912, 8.2180913094628564], [0.55370097211729696, 7.0871105126860554, 7.7450498540614178, 4.2448327660994876, 1.2746000519648371, 9.4391729894286023, 6.1902689198805465, 6.0312877871821424, 8.7890699247898425, 3.1611885774377635], [8.9903796016343396, 3.4471256572948263, 8.4932841564173884, 9.9373309006088171, 2.6191045587156303, 0.77351004199567641, 1.4024547359632467, 7.454551829233095, 2.6194195569905077, 4.0298520046877577], [4.7641019675563543, 3.8129279818642861, 9.0747728919768225, 6.4920816381757511, 6.7882405668469881, 7.0063465072165911, 5.7386637585592792, 7.5230234961300599, 0.91592641387099771, 8.6646639602141899], [5.6862365678538973, 4.8755032417073192, 9.5859588536709328, 8.1186668576209513, 5.3811119011589454, 3.8280043169558411, 9.9983397606134918, 6.1835824149566241, 3.4201107815517515, 0.84968218962971687], [2.791270331453247, 2.9735813587818685, 3.0654358664150494, 5.4929582569491755, 3.9238922832952996, 9.2657934977933269, 5.0681592194030571, 9.6910348814034712, 2.0972430846802959, 0.96789458347651514], [3.1989914495545624, 3.7607248895716507, 5.5182323136835318, 2.4724154287944913, 7.2920674615977124, 9.7009225179758473, 9.9421519655410044, 2.6109645810252315, 9.0484630420475316, 3.6771724535825703], [6.305746358135309, 7.6948754823713771, 3.6012681436537397, 1.263350310992416, 3.8581878444772943, 7.1047027925517909, 2.1904752468927735, 0.32914734762647391, 3.1668377278172235, 2.0518472657841924]]> : tensor<10x10xf64>) {addr_space = 0 : i32, alignment = 64 : i64} : !llvm.array<10 x array<10 x f64>>
  func.func @matmul(%arg0: memref<?xindex>, %arg1: memref<?xindex>, %arg2: memref<?xf64>, %arg3: !llvm.struct<(array<2 x i64>, array<3 x i64>)>, %arg4: tensor<10x10xf64>, %arg5: tensor<10x10xf64>) -> tensor<10x10xf64> {
    %0 = llvm.mlir.poison : vector<4xf64>
    %1 = llvm.mlir.constant(10 : index) : i64
    %2 = llvm.mlir.constant(0 : i32) : i32
    %3 = llvm.mlir.poison : vector<4xi32>
    %4 = llvm.mlir.constant(10 : index) : i64
    %5 = llvm.mlir.constant(0 : index) : i64
    %6 = llvm.mlir.constant(1 : index) : i64
    %7 = llvm.mlir.constant(4 : index) : i64
    %8 = llvm.mlir.constant(dense<0.000000e+00> : vector<4xf64>) : vector<4xf64>
    %9 = llvm.mlir.constant(-1 : index) : i64
    %10 = llvm.mlir.constant(dense<[0, 1, 2, 3]> : vector<4xi32>) : vector<4xi32>
    %11 = builtin.unrealized_conversion_cast %arg1 : memref<?xindex> to !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %12 = builtin.unrealized_conversion_cast %arg0 : memref<?xindex> to !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %13 = builtin.unrealized_conversion_cast %arg2 : memref<?xf64> to !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %14 = llvm.extractvalue %13[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %15 = bufferization.to_memref %arg4 : tensor<10x10xf64> to memref<10x10xf64>
    %16 = builtin.unrealized_conversion_cast %15 : memref<10x10xf64> to !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)>
    %17 = bufferization.to_memref %arg5 : tensor<10x10xf64> to memref<10x10xf64>
    %18 = builtin.unrealized_conversion_cast %17 : memref<10x10xf64> to !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)>
    %19 = llvm.extractvalue %12[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %20 = llvm.extractvalue %11[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    llvm.br ^bb1(%5 : i64)
  ^bb1(%21: i64):  // 2 preds: ^bb0, ^bb8
    %22 = llvm.icmp "slt" %21, %4 : i64
    llvm.cond_br %22, ^bb2, ^bb9
  ^bb2:  // pred: ^bb1
    %23 = llvm.getelementptr %19[%21] : (!llvm.ptr, i64) -> !llvm.ptr, i64
    %24 = llvm.load %23 : !llvm.ptr -> i64
    %25 = llvm.add %21, %6 : i64
    %26 = llvm.getelementptr %19[%25] : (!llvm.ptr, i64) -> !llvm.ptr, i64
    %27 = llvm.load %26 : !llvm.ptr -> i64
    llvm.br ^bb3(%24 : i64)
  ^bb3(%28: i64):  // 2 preds: ^bb2, ^bb7
    %29 = llvm.icmp "slt" %28, %27 : i64
    llvm.cond_br %29, ^bb4, ^bb8
  ^bb4:  // pred: ^bb3
    %30 = llvm.getelementptr %20[%28] : (!llvm.ptr, i64) -> !llvm.ptr, i64
    %31 = llvm.load %30 : !llvm.ptr -> i64
    %32 = llvm.getelementptr %14[%28] : (!llvm.ptr, i64) -> !llvm.ptr, f64
    %33 = llvm.load %32 : !llvm.ptr -> f64
    llvm.br ^bb5(%5 : i64)
  ^bb5(%34: i64):  // 2 preds: ^bb4, ^bb6
    %35 = llvm.icmp "slt" %34, %4 : i64
    llvm.cond_br %35, ^bb6, ^bb7
  ^bb6:  // pred: ^bb5
    %36 = llvm.mul %34, %9 overflow<nsw> : i64
    %37 = llvm.add %36, %4 : i64
    %38 = llvm.icmp "slt" %37, %7 : i64
    %39 = llvm.select %38, %37, %7 : i1, i64
    %40 = llvm.trunc %39 : i64 to i32
    %41 = llvm.insertelement %40, %3[%2 : i32] : vector<4xi32>
    %42 = llvm.shufflevector %41, %3 [0, 0, 0, 0] : vector<4xi32> 
    %43 = llvm.icmp "sgt" %42, %10 : vector<4xi32>
    %44 = llvm.extractvalue %18[1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %45 = llvm.mul %21, %1 : i64
    %46 = llvm.add %45, %34 : i64
    %47 = llvm.getelementptr %44[%46] : (!llvm.ptr, i64) -> !llvm.ptr, f64
    %48 = llvm.intr.masked.load %47, %43, %8 {alignment = 8 : i32} : (!llvm.ptr, vector<4xi1>, vector<4xf64>) -> vector<4xf64>
    %49 = llvm.insertelement %33, %0[%2 : i32] : vector<4xf64>
    %50 = llvm.shufflevector %49, %0 [0, 0, 0, 0] : vector<4xf64> 
    %51 = llvm.extractvalue %16[1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %52 = llvm.mul %31, %1 : i64
    %53 = llvm.add %52, %34 : i64
    %54 = llvm.getelementptr %51[%53] : (!llvm.ptr, i64) -> !llvm.ptr, f64
    %55 = llvm.intr.masked.load %54, %43, %8 {alignment = 8 : i32} : (!llvm.ptr, vector<4xi1>, vector<4xf64>) -> vector<4xf64>
    %56 = llvm.fmul %50, %55 : vector<4xf64>
    %57 = llvm.fadd %48, %56 : vector<4xf64>
    %58 = llvm.extractvalue %18[1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %59 = llvm.mul %21, %1 : i64
    %60 = llvm.add %59, %34 : i64
    %61 = llvm.getelementptr %58[%60] : (!llvm.ptr, i64) -> !llvm.ptr, f64
    llvm.intr.masked.store %57, %61, %43 {alignment = 8 : i32} : vector<4xf64>, vector<4xi1> into !llvm.ptr
    %62 = llvm.add %34, %7 : i64
    llvm.br ^bb5(%62 : i64)
  ^bb7:  // pred: ^bb5
    %63 = llvm.add %28, %6 : i64
    llvm.br ^bb3(%63 : i64)
  ^bb8:  // pred: ^bb3
    %64 = llvm.add %21, %6 : i64
    llvm.br ^bb1(%64 : i64)
  ^bb9:  // pred: ^bb1
    %65 = bufferization.to_tensor %17 : memref<10x10xf64> to tensor<10x10xf64>
    return %65 : tensor<10x10xf64>
  }
  llvm.func @main() -> i64 {
    %0 = llvm.mlir.constant(0 : index) : i64
    %1 = llvm.mlir.poison : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)>
    %2 = llvm.mlir.constant(3735928559 : index) : i64
    %3 = llvm.mlir.addressof @__constant_10x10xf64 : !llvm.ptr
    %4 = llvm.mlir.constant(9 : index) : i64
    %5 = llvm.mlir.constant(8 : index) : i64
    %6 = builtin.unrealized_conversion_cast %5 : i64 to index
    %7 = llvm.mlir.constant(0.000000e+00 : f64) : f64
    %8 = llvm.mlir.constant(1 : index) : i64
    %9 = llvm.mlir.constant(10 : index) : i64
    %10 = llvm.mlir.constant(0 : index) : i64
    %11 = builtin.unrealized_conversion_cast %10 : i64 to index
    %12 = llvm.mlir.constant(10 : index) : i64
    %13 = llvm.mlir.constant(1 : index) : i64
    %14 = llvm.getelementptr %3[0, 0, 0] : (!llvm.ptr) -> !llvm.ptr, !llvm.array<10 x array<10 x f64>>
    %15 = llvm.inttoptr %2 : i64 to !llvm.ptr
    %16 = llvm.insertvalue %15, %1[0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %17 = llvm.insertvalue %14, %16[1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %18 = llvm.insertvalue %0, %17[2] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %19 = llvm.insertvalue %12, %18[3, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %20 = llvm.insertvalue %12, %19[3, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %21 = llvm.insertvalue %12, %20[4, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %22 = llvm.insertvalue %13, %21[4, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %23 = builtin.unrealized_conversion_cast %22 : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> to memref<10x10xf64>
    %24 = bufferization.to_tensor %23 : memref<10x10xf64> to tensor<10x10xf64>
    %25 = bufferization.alloc_tensor() : tensor<10x10xf64>
    %26 = llvm.call @assemble_sparse() : () -> !llvm.struct<(struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>, struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>, struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>, struct<(array<2 x i64>, array<3 x i64>)>)>
    %27 = llvm.extractvalue %26[0] : !llvm.struct<(struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>, struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>, struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>, struct<(array<2 x i64>, array<3 x i64>)>)> 
    %28 = builtin.unrealized_conversion_cast %27 : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> to memref<?xindex>
    %29 = llvm.extractvalue %26[1] : !llvm.struct<(struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>, struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>, struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>, struct<(array<2 x i64>, array<3 x i64>)>)> 
    %30 = builtin.unrealized_conversion_cast %29 : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> to memref<?xindex>
    %31 = llvm.extractvalue %26[2] : !llvm.struct<(struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>, struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>, struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>, struct<(array<2 x i64>, array<3 x i64>)>)> 
    %32 = builtin.unrealized_conversion_cast %31 : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> to memref<?xf64>
    %33 = llvm.extractvalue %26[3] : !llvm.struct<(struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>, struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>, struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>, struct<(array<2 x i64>, array<3 x i64>)>)> 
    %34 = func.call @matmul(%28, %30, %32, %33, %24, %25) : (memref<?xindex>, memref<?xindex>, memref<?xf64>, !llvm.struct<(array<2 x i64>, array<3 x i64>)>, tensor<10x10xf64>, tensor<10x10xf64>) -> tensor<10x10xf64>
    llvm.br ^bb1(%10 : i64)
  ^bb1(%35: i64):  // 2 preds: ^bb0, ^bb7
    %36 = builtin.unrealized_conversion_cast %35 : i64 to index
    %37 = llvm.icmp "slt" %35, %9 : i64
    llvm.cond_br %37, ^bb2, ^bb8
  ^bb2:  // pred: ^bb1
    %38 = vector.transfer_read %34[%36, %11], %7 {in_bounds = [true]} : tensor<10x10xf64>, vector<10xf64>
    llvm.call @printOpen() : () -> ()
    llvm.br ^bb3(%10 : i64)
  ^bb3(%39: i64):  // 2 preds: ^bb2, ^bb6
    %40 = llvm.icmp "slt" %39, %9 : i64
    llvm.cond_br %40, ^bb4, ^bb7
  ^bb4:  // pred: ^bb3
    %41 = llvm.extractelement %38[%39 : i64] : vector<10xf64>
    llvm.call @printF64(%41) : (f64) -> ()
    %42 = llvm.icmp "ult" %39, %4 : i64
    llvm.cond_br %42, ^bb5, ^bb6
  ^bb5:  // pred: ^bb4
    llvm.call @printComma() : () -> ()
    llvm.br ^bb6
  ^bb6:  // 2 preds: ^bb4, ^bb5
    %43 = llvm.add %39, %8 : i64
    llvm.br ^bb3(%43 : i64)
  ^bb7:  // pred: ^bb3
    llvm.call @printClose() : () -> ()
    llvm.call @printNewline() : () -> ()
    %44 = llvm.add %35, %8 : i64
    llvm.br ^bb1(%44 : i64)
  ^bb8:  // pred: ^bb1
    %extracted = tensor.extract %34[%6, %6] : tensor<10x10xf64>
    %45 = llvm.fptosi %extracted : f64 to i64
    llvm.return %45 : i64
  }
  llvm.func @assemble_sparse() -> !llvm.struct<(struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>, struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>, struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>, struct<(array<2 x i64>, array<3 x i64>)>)> {
    %0 = llvm.mlir.addressof @__constant_30xindex : !llvm.ptr
    %1 = llvm.mlir.addressof @__constant_11xindex : !llvm.ptr
    %2 = llvm.mlir.constant(11 : index) : i64
    %3 = llvm.mlir.constant(0 : index) : i64
    %4 = llvm.mlir.poison : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>
    %5 = llvm.mlir.constant(3735928559 : index) : i64
    %6 = llvm.mlir.addressof @__constant_30xf64 : !llvm.ptr
    %7 = llvm.mlir.constant(1 : index) : i64
    %8 = llvm.mlir.constant(30 : index) : i64
    %9 = llvm.mlir.constant(11 : i64) : i64
    %10 = llvm.mlir.constant(10 : i64) : i64
    %11 = llvm.mlir.constant(0 : i64) : i64
    %12 = llvm.mlir.poison : !llvm.struct<(array<2 x i64>, array<3 x i64>)>
    %13 = llvm.mlir.constant(10 : index) : i64
    %14 = llvm.getelementptr %6[0, 0] : (!llvm.ptr) -> !llvm.ptr, !llvm.array<30 x f64>
    %15 = llvm.inttoptr %5 : i64 to !llvm.ptr
    %16 = llvm.insertvalue %15, %4[0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %17 = llvm.insertvalue %14, %16[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %18 = llvm.insertvalue %3, %17[2] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %19 = llvm.insertvalue %8, %18[3, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %20 = llvm.insertvalue %7, %19[4, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %21 = llvm.getelementptr %1[0, 0] : (!llvm.ptr) -> !llvm.ptr, !llvm.array<11 x i64>
    %22 = llvm.inttoptr %5 : i64 to !llvm.ptr
    %23 = llvm.insertvalue %22, %4[0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %24 = llvm.insertvalue %21, %23[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %25 = llvm.insertvalue %3, %24[2] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %26 = llvm.insertvalue %2, %25[3, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %27 = llvm.insertvalue %7, %26[4, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %28 = llvm.getelementptr %0[0, 0] : (!llvm.ptr) -> !llvm.ptr, !llvm.array<30 x i64>
    %29 = llvm.inttoptr %5 : i64 to !llvm.ptr
    %30 = llvm.insertvalue %29, %4[0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %31 = llvm.insertvalue %28, %30[1] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %32 = llvm.insertvalue %3, %31[2] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %33 = llvm.insertvalue %8, %32[3, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %34 = llvm.insertvalue %7, %33[4, 0] : !llvm.struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)> 
    %35 = llvm.insertvalue %11, %12[1, 0] : !llvm.struct<(array<2 x i64>, array<3 x i64>)> 
    %36 = llvm.insertvalue %11, %35[1, 1] : !llvm.struct<(array<2 x i64>, array<3 x i64>)> 
    %37 = llvm.insertvalue %11, %36[1, 2] : !llvm.struct<(array<2 x i64>, array<3 x i64>)> 
    %38 = llvm.insertvalue %10, %37[0, 0] : !llvm.struct<(array<2 x i64>, array<3 x i64>)> 
    %39 = llvm.insertvalue %10, %38[0, 1] : !llvm.struct<(array<2 x i64>, array<3 x i64>)> 
    %40 = llvm.insertvalue %9, %39[1, 0] : !llvm.struct<(array<2 x i64>, array<3 x i64>)> 
    %41 = llvm.getelementptr %21[%13] : (!llvm.ptr, i64) -> !llvm.ptr, i64
    %42 = llvm.load %41 : !llvm.ptr -> i64
    %43 = llvm.insertvalue %42, %40[1, 1] : !llvm.struct<(array<2 x i64>, array<3 x i64>)> 
    %44 = llvm.insertvalue %42, %43[1, 2] : !llvm.struct<(array<2 x i64>, array<3 x i64>)> 
    %45 = llvm.mlir.poison : !llvm.struct<(struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>, struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>, struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>, struct<(array<2 x i64>, array<3 x i64>)>)>
    %46 = llvm.insertvalue %27, %45[0] : !llvm.struct<(struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>, struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>, struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>, struct<(array<2 x i64>, array<3 x i64>)>)> 
    %47 = llvm.insertvalue %34, %46[1] : !llvm.struct<(struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>, struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>, struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>, struct<(array<2 x i64>, array<3 x i64>)>)> 
    %48 = llvm.insertvalue %20, %47[2] : !llvm.struct<(struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>, struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>, struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>, struct<(array<2 x i64>, array<3 x i64>)>)> 
    %49 = llvm.insertvalue %44, %48[3] : !llvm.struct<(struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>, struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>, struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>, struct<(array<2 x i64>, array<3 x i64>)>)> 
    llvm.return %49 : !llvm.struct<(struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>, struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>, struct<(ptr, ptr, i64, array<1 x i64>, array<1 x i64>)>, struct<(array<2 x i64>, array<3 x i64>)>)>
  }
}


