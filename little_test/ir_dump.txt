mlir-opt  -linalg-generalize-named-ops -linalg-fuse-elementwise-ops -mlir-print-ir-after-all -pre-sparsification-rewrite -empty-tensor-to-alloc-tensor -sparse-reinterpret-map="scope=all" -sparsification="enable-runtime-library=false" -stage-sparse-ops -lower-sparse-ops-to-foreach="enable-convert=true" -sparse-reinterpret-map="scope=except-generic" -lower-sparse-foreach-to-scf -loop-invariant-code-motion -sparse-vectorization="vl=4"  -one-shot-bufferize="allow-return-allocs-from-loops=true" -sparse-tensor-codegen="enable-buffer-initialization=true"  -sparse-buffer-rewrite  -sparse-storage-specifier-to-llvm -canonicalize -convert-linalg-to-loops -convert-vector-to-scf -expand-realloc -convert-scf-to-cf -expand-strided-metadata -lower-affine -convert-vector-to-llvm -finalize-memref-to-llvm -convert-complex-to-standard -arith-expand -convert-math-to-llvm -convert-math-to-libm -convert-complex-to-libm -convert-vector-to-llvm -convert-complex-to-llvm -convert-vector-to-llvm -convert-func-to-llvm -convert-arith-to-llvm -convert-cf-to-llvm -convert-ub-to-llvm -reconcile-unrealized-casts -o from_scratch.llvm.mlir from_scratch.mlir
// -----// IR Dump After LinalgGeneralizeNamedOpsPass (linalg-generalize-named-ops) //----- //
#map = affine_map<(d0, d1, d2) -> (d0, d2)>
#map1 = affine_map<(d0, d1, d2) -> (d2, d1)>
#map2 = affine_map<(d0, d1, d2) -> (d0, d1)>
#sparse = #sparse_tensor.encoding<{ map = (d0, d1) -> (d0 : dense, d1 : compressed) }>
module {
  func.func @matmul(%arg0: tensor<10x10xf64, #sparse>, %arg1: tensor<10x10xf64>, %arg2: tensor<10x10xf64>) -> tensor<10x10xf64> {
    %0 = linalg.generic {indexing_maps = [#map, #map1, #map2], iterator_types = ["parallel", "parallel", "reduction"]} ins(%arg0, %arg1 : tensor<10x10xf64, #sparse>, tensor<10x10xf64>) outs(%arg2 : tensor<10x10xf64>) {
    ^bb0(%in: f64, %in_0: f64, %out: f64):
      %1 = arith.mulf %in, %in_0 : f64
      %2 = arith.addf %out, %1 : f64
      linalg.yield %2 : f64
    } -> tensor<10x10xf64>
    return %0 : tensor<10x10xf64>
  }
  func.func @main() -> i64 {
    %c8 = arith.constant 8 : index
    %cst = arith.constant 0.000000e+00 : f64
    %c1 = arith.constant 1 : index
    %c10 = arith.constant 10 : index
    %c0 = arith.constant 0 : index
    %cst_0 = arith.constant dense<[[5.0072820879405331, 2.1420497309468542, 8.4364357946217474, 3.3512684114489364, 4.8578737173077684, 6.5026873298607608, 4.481183080848961, 1.6018142840321781, 1.6482067031075565, 2.7697353449463433], [8.2796435610104453, 9.7956308688691446, 5.066309369035312, 1.0691978274975567, 7.2754747197326219, 7.4679216752662611, 1.8460472498040226, 1.7245060332115747, 9.828847678500983, 5.8523888503628294], [4.735129046344202, 0.21389279999051047, 9.9823910553584571, 0.22751442405574696, 4.3063298537464378, 1.0300462704374436, 7.1885192597496097, 1.7297134743393461, 7.4494154821665912, 8.2180913094628564], [0.55370097211729696, 7.0871105126860554, 7.7450498540614178, 4.2448327660994876, 1.2746000519648371, 9.4391729894286023, 6.1902689198805465, 6.0312877871821424, 8.7890699247898425, 3.1611885774377635], [8.9903796016343396, 3.4471256572948263, 8.4932841564173884, 9.9373309006088171, 2.6191045587156303, 0.77351004199567641, 1.4024547359632467, 7.454551829233095, 2.6194195569905077, 4.0298520046877577], [4.7641019675563543, 3.8129279818642861, 9.0747728919768225, 6.4920816381757511, 6.7882405668469881, 7.0063465072165911, 5.7386637585592792, 7.5230234961300599, 0.91592641387099771, 8.6646639602141899], [5.6862365678538973, 4.8755032417073192, 9.5859588536709328, 8.1186668576209513, 5.3811119011589454, 3.8280043169558411, 9.9983397606134918, 6.1835824149566241, 3.4201107815517515, 0.84968218962971687], [2.791270331453247, 2.9735813587818685, 3.0654358664150494, 5.4929582569491755, 3.9238922832952996, 9.2657934977933269, 5.0681592194030571, 9.6910348814034712, 2.0972430846802959, 0.96789458347651514], [3.1989914495545624, 3.7607248895716507, 5.5182323136835318, 2.4724154287944913, 7.2920674615977124, 9.7009225179758473, 9.9421519655410044, 2.6109645810252315, 9.0484630420475316, 3.6771724535825703], [6.305746358135309, 7.6948754823713771, 3.6012681436537397, 1.263350310992416, 3.8581878444772943, 7.1047027925517909, 2.1904752468927735, 0.32914734762647391, 3.1668377278172235, 2.0518472657841924]]> : tensor<10x10xf64>
    %0 = tensor.empty() : tensor<10x10xf64>
    %1 = call @assemble_sparse() : () -> tensor<10x10xf64, #sparse>
    %2 = call @matmul(%1, %cst_0, %0) : (tensor<10x10xf64, #sparse>, tensor<10x10xf64>, tensor<10x10xf64>) -> tensor<10x10xf64>
    scf.for %arg0 = %c0 to %c10 step %c1 {
      %4 = vector.transfer_read %2[%arg0, %c0], %cst {in_bounds = [true]} : tensor<10x10xf64>, vector<10xf64>
      vector.print %4 : vector<10xf64>
    }
    %extracted = tensor.extract %2[%c8, %c8] : tensor<10x10xf64>
    %3 = arith.fptosi %extracted : f64 to i64
    return %3 : i64
  }
  func.func @assemble_sparse() -> tensor<10x10xf64, #sparse> {
    %cst = arith.constant dense<[4.7563469999999999, 2.102859, 5.4238689999999998, 5.577680e+00, 3.001240e-01, 4.8357549999999998, 8.8596050000000002, 1.592490e+00, 7.372070e+00, 7.2462879999999998, 5.9191609999999999, 5.9593920000000002, 4.6956530000000001, 6.328630e-01, 3.1591619999999998, 4.7083050000000002, 8.4356449999999992, 5.4309390000000004, 2.1190630000000001, 1.545420e-01, 2.595040e+00, 1.4655819999999999, 1.321259, 3.702925, 3.542246, 6.831162, 1.723510e+00, 7.8729019999999998, 6.0081550000000004, 1.047045]> : tensor<30xf64>
    %cst_0 = arith.constant dense<[0, 1, 5, 7, 14, 16, 21, 25, 27, 29, 30]> : tensor<11xindex>
    %cst_1 = arith.constant dense<[8, 3, 4, 6, 9, 2, 4, 0, 1, 2, 3, 5, 7, 8, 3, 6, 2, 3, 4, 5, 8, 1, 5, 7, 8, 5, 9, 4, 7, 7]> : tensor<30xindex>
    %0 = sparse_tensor.assemble (%cst_0, %cst_1), %cst : (tensor<11xindex>, tensor<30xindex>), tensor<30xf64> to tensor<10x10xf64, #sparse>
    return %0 : tensor<10x10xf64, #sparse>
  }
}


// -----// IR Dump After LinalgElementwiseOpFusionPass (linalg-fuse-elementwise-ops) //----- //
#map = affine_map<(d0, d1, d2) -> (d0, d2)>
#map1 = affine_map<(d0, d1, d2) -> (d2, d1)>
#map2 = affine_map<(d0, d1, d2) -> (d0, d1)>
#sparse = #sparse_tensor.encoding<{ map = (d0, d1) -> (d0 : dense, d1 : compressed) }>
module {
  func.func @matmul(%arg0: tensor<10x10xf64, #sparse>, %arg1: tensor<10x10xf64>, %arg2: tensor<10x10xf64>) -> tensor<10x10xf64> {
    %0 = linalg.generic {indexing_maps = [#map, #map1, #map2], iterator_types = ["parallel", "parallel", "reduction"]} ins(%arg0, %arg1 : tensor<10x10xf64, #sparse>, tensor<10x10xf64>) outs(%arg2 : tensor<10x10xf64>) {
    ^bb0(%in: f64, %in_0: f64, %out: f64):
      %1 = arith.mulf %in, %in_0 : f64
      %2 = arith.addf %out, %1 : f64
      linalg.yield %2 : f64
    } -> tensor<10x10xf64>
    return %0 : tensor<10x10xf64>
  }
  func.func @main() -> i64 {
    %c8 = arith.constant 8 : index
    %cst = arith.constant 0.000000e+00 : f64
    %c1 = arith.constant 1 : index
    %c10 = arith.constant 10 : index
    %c0 = arith.constant 0 : index
    %cst_0 = arith.constant dense<[[5.0072820879405331, 2.1420497309468542, 8.4364357946217474, 3.3512684114489364, 4.8578737173077684, 6.5026873298607608, 4.481183080848961, 1.6018142840321781, 1.6482067031075565, 2.7697353449463433], [8.2796435610104453, 9.7956308688691446, 5.066309369035312, 1.0691978274975567, 7.2754747197326219, 7.4679216752662611, 1.8460472498040226, 1.7245060332115747, 9.828847678500983, 5.8523888503628294], [4.735129046344202, 0.21389279999051047, 9.9823910553584571, 0.22751442405574696, 4.3063298537464378, 1.0300462704374436, 7.1885192597496097, 1.7297134743393461, 7.4494154821665912, 8.2180913094628564], [0.55370097211729696, 7.0871105126860554, 7.7450498540614178, 4.2448327660994876, 1.2746000519648371, 9.4391729894286023, 6.1902689198805465, 6.0312877871821424, 8.7890699247898425, 3.1611885774377635], [8.9903796016343396, 3.4471256572948263, 8.4932841564173884, 9.9373309006088171, 2.6191045587156303, 0.77351004199567641, 1.4024547359632467, 7.454551829233095, 2.6194195569905077, 4.0298520046877577], [4.7641019675563543, 3.8129279818642861, 9.0747728919768225, 6.4920816381757511, 6.7882405668469881, 7.0063465072165911, 5.7386637585592792, 7.5230234961300599, 0.91592641387099771, 8.6646639602141899], [5.6862365678538973, 4.8755032417073192, 9.5859588536709328, 8.1186668576209513, 5.3811119011589454, 3.8280043169558411, 9.9983397606134918, 6.1835824149566241, 3.4201107815517515, 0.84968218962971687], [2.791270331453247, 2.9735813587818685, 3.0654358664150494, 5.4929582569491755, 3.9238922832952996, 9.2657934977933269, 5.0681592194030571, 9.6910348814034712, 2.0972430846802959, 0.96789458347651514], [3.1989914495545624, 3.7607248895716507, 5.5182323136835318, 2.4724154287944913, 7.2920674615977124, 9.7009225179758473, 9.9421519655410044, 2.6109645810252315, 9.0484630420475316, 3.6771724535825703], [6.305746358135309, 7.6948754823713771, 3.6012681436537397, 1.263350310992416, 3.8581878444772943, 7.1047027925517909, 2.1904752468927735, 0.32914734762647391, 3.1668377278172235, 2.0518472657841924]]> : tensor<10x10xf64>
    %0 = tensor.empty() : tensor<10x10xf64>
    %1 = call @assemble_sparse() : () -> tensor<10x10xf64, #sparse>
    %2 = call @matmul(%1, %cst_0, %0) : (tensor<10x10xf64, #sparse>, tensor<10x10xf64>, tensor<10x10xf64>) -> tensor<10x10xf64>
    scf.for %arg0 = %c0 to %c10 step %c1 {
      %4 = vector.transfer_read %2[%arg0, %c0], %cst {in_bounds = [true]} : tensor<10x10xf64>, vector<10xf64>
      vector.print %4 : vector<10xf64>
    }
    %extracted = tensor.extract %2[%c8, %c8] : tensor<10x10xf64>
    %3 = arith.fptosi %extracted : f64 to i64
    return %3 : i64
  }
  func.func @assemble_sparse() -> tensor<10x10xf64, #sparse> {
    %cst = arith.constant dense<[4.7563469999999999, 2.102859, 5.4238689999999998, 5.577680e+00, 3.001240e-01, 4.8357549999999998, 8.8596050000000002, 1.592490e+00, 7.372070e+00, 7.2462879999999998, 5.9191609999999999, 5.9593920000000002, 4.6956530000000001, 6.328630e-01, 3.1591619999999998, 4.7083050000000002, 8.4356449999999992, 5.4309390000000004, 2.1190630000000001, 1.545420e-01, 2.595040e+00, 1.4655819999999999, 1.321259, 3.702925, 3.542246, 6.831162, 1.723510e+00, 7.8729019999999998, 6.0081550000000004, 1.047045]> : tensor<30xf64>
    %cst_0 = arith.constant dense<[0, 1, 5, 7, 14, 16, 21, 25, 27, 29, 30]> : tensor<11xindex>
    %cst_1 = arith.constant dense<[8, 3, 4, 6, 9, 2, 4, 0, 1, 2, 3, 5, 7, 8, 3, 6, 2, 3, 4, 5, 8, 1, 5, 7, 8, 5, 9, 4, 7, 7]> : tensor<30xindex>
    %0 = sparse_tensor.assemble (%cst_0, %cst_1), %cst : (tensor<11xindex>, tensor<30xindex>), tensor<30xf64> to tensor<10x10xf64, #sparse>
    return %0 : tensor<10x10xf64, #sparse>
  }
}


// -----// IR Dump After PreSparsificationRewrite (pre-sparsification-rewrite) //----- //
#map = affine_map<(d0, d1, d2) -> (d0, d2)>
#map1 = affine_map<(d0, d1, d2) -> (d2, d1)>
#map2 = affine_map<(d0, d1, d2) -> (d0, d1)>
#sparse = #sparse_tensor.encoding<{ map = (d0, d1) -> (d0 : dense, d1 : compressed) }>
module {
  func.func @matmul(%arg0: tensor<10x10xf64, #sparse>, %arg1: tensor<10x10xf64>, %arg2: tensor<10x10xf64>) -> tensor<10x10xf64> {
    %0 = linalg.generic {indexing_maps = [#map, #map1, #map2], iterator_types = ["parallel", "parallel", "reduction"]} ins(%arg0, %arg1 : tensor<10x10xf64, #sparse>, tensor<10x10xf64>) outs(%arg2 : tensor<10x10xf64>) {
    ^bb0(%in: f64, %in_0: f64, %out: f64):
      %1 = arith.mulf %in, %in_0 : f64
      %2 = arith.addf %out, %1 : f64
      linalg.yield %2 : f64
    } -> tensor<10x10xf64>
    return %0 : tensor<10x10xf64>
  }
  func.func @main() -> i64 {
    %c8 = arith.constant 8 : index
    %cst = arith.constant 0.000000e+00 : f64
    %c1 = arith.constant 1 : index
    %c10 = arith.constant 10 : index
    %c0 = arith.constant 0 : index
    %cst_0 = arith.constant dense<[[5.0072820879405331, 2.1420497309468542, 8.4364357946217474, 3.3512684114489364, 4.8578737173077684, 6.5026873298607608, 4.481183080848961, 1.6018142840321781, 1.6482067031075565, 2.7697353449463433], [8.2796435610104453, 9.7956308688691446, 5.066309369035312, 1.0691978274975567, 7.2754747197326219, 7.4679216752662611, 1.8460472498040226, 1.7245060332115747, 9.828847678500983, 5.8523888503628294], [4.735129046344202, 0.21389279999051047, 9.9823910553584571, 0.22751442405574696, 4.3063298537464378, 1.0300462704374436, 7.1885192597496097, 1.7297134743393461, 7.4494154821665912, 8.2180913094628564], [0.55370097211729696, 7.0871105126860554, 7.7450498540614178, 4.2448327660994876, 1.2746000519648371, 9.4391729894286023, 6.1902689198805465, 6.0312877871821424, 8.7890699247898425, 3.1611885774377635], [8.9903796016343396, 3.4471256572948263, 8.4932841564173884, 9.9373309006088171, 2.6191045587156303, 0.77351004199567641, 1.4024547359632467, 7.454551829233095, 2.6194195569905077, 4.0298520046877577], [4.7641019675563543, 3.8129279818642861, 9.0747728919768225, 6.4920816381757511, 6.7882405668469881, 7.0063465072165911, 5.7386637585592792, 7.5230234961300599, 0.91592641387099771, 8.6646639602141899], [5.6862365678538973, 4.8755032417073192, 9.5859588536709328, 8.1186668576209513, 5.3811119011589454, 3.8280043169558411, 9.9983397606134918, 6.1835824149566241, 3.4201107815517515, 0.84968218962971687], [2.791270331453247, 2.9735813587818685, 3.0654358664150494, 5.4929582569491755, 3.9238922832952996, 9.2657934977933269, 5.0681592194030571, 9.6910348814034712, 2.0972430846802959, 0.96789458347651514], [3.1989914495545624, 3.7607248895716507, 5.5182323136835318, 2.4724154287944913, 7.2920674615977124, 9.7009225179758473, 9.9421519655410044, 2.6109645810252315, 9.0484630420475316, 3.6771724535825703], [6.305746358135309, 7.6948754823713771, 3.6012681436537397, 1.263350310992416, 3.8581878444772943, 7.1047027925517909, 2.1904752468927735, 0.32914734762647391, 3.1668377278172235, 2.0518472657841924]]> : tensor<10x10xf64>
    %0 = tensor.empty() : tensor<10x10xf64>
    %1 = call @assemble_sparse() : () -> tensor<10x10xf64, #sparse>
    %2 = call @matmul(%1, %cst_0, %0) : (tensor<10x10xf64, #sparse>, tensor<10x10xf64>, tensor<10x10xf64>) -> tensor<10x10xf64>
    scf.for %arg0 = %c0 to %c10 step %c1 {
      %4 = vector.transfer_read %2[%arg0, %c0], %cst {in_bounds = [true]} : tensor<10x10xf64>, vector<10xf64>
      vector.print %4 : vector<10xf64>
    }
    %extracted = tensor.extract %2[%c8, %c8] : tensor<10x10xf64>
    %3 = arith.fptosi %extracted : f64 to i64
    return %3 : i64
  }
  func.func @assemble_sparse() -> tensor<10x10xf64, #sparse> {
    %cst = arith.constant dense<[4.7563469999999999, 2.102859, 5.4238689999999998, 5.577680e+00, 3.001240e-01, 4.8357549999999998, 8.8596050000000002, 1.592490e+00, 7.372070e+00, 7.2462879999999998, 5.9191609999999999, 5.9593920000000002, 4.6956530000000001, 6.328630e-01, 3.1591619999999998, 4.7083050000000002, 8.4356449999999992, 5.4309390000000004, 2.1190630000000001, 1.545420e-01, 2.595040e+00, 1.4655819999999999, 1.321259, 3.702925, 3.542246, 6.831162, 1.723510e+00, 7.8729019999999998, 6.0081550000000004, 1.047045]> : tensor<30xf64>
    %cst_0 = arith.constant dense<[0, 1, 5, 7, 14, 16, 21, 25, 27, 29, 30]> : tensor<11xindex>
    %cst_1 = arith.constant dense<[8, 3, 4, 6, 9, 2, 4, 0, 1, 2, 3, 5, 7, 8, 3, 6, 2, 3, 4, 5, 8, 1, 5, 7, 8, 5, 9, 4, 7, 7]> : tensor<30xindex>
    %0 = sparse_tensor.assemble (%cst_0, %cst_1), %cst : (tensor<11xindex>, tensor<30xindex>), tensor<30xf64> to tensor<10x10xf64, #sparse>
    return %0 : tensor<10x10xf64, #sparse>
  }
}


// -----// IR Dump After EmptyTensorToAllocTensorPass (empty-tensor-to-alloc-tensor) //----- //
#map = affine_map<(d0, d1, d2) -> (d0, d2)>
#map1 = affine_map<(d0, d1, d2) -> (d2, d1)>
#map2 = affine_map<(d0, d1, d2) -> (d0, d1)>
#sparse = #sparse_tensor.encoding<{ map = (d0, d1) -> (d0 : dense, d1 : compressed) }>
module {
  func.func @matmul(%arg0: tensor<10x10xf64, #sparse>, %arg1: tensor<10x10xf64>, %arg2: tensor<10x10xf64>) -> tensor<10x10xf64> {
    %0 = linalg.generic {indexing_maps = [#map, #map1, #map2], iterator_types = ["parallel", "parallel", "reduction"]} ins(%arg0, %arg1 : tensor<10x10xf64, #sparse>, tensor<10x10xf64>) outs(%arg2 : tensor<10x10xf64>) {
    ^bb0(%in: f64, %in_0: f64, %out: f64):
      %1 = arith.mulf %in, %in_0 : f64
      %2 = arith.addf %out, %1 : f64
      linalg.yield %2 : f64
    } -> tensor<10x10xf64>
    return %0 : tensor<10x10xf64>
  }
  func.func @main() -> i64 {
    %c8 = arith.constant 8 : index
    %cst = arith.constant 0.000000e+00 : f64
    %c1 = arith.constant 1 : index
    %c10 = arith.constant 10 : index
    %c0 = arith.constant 0 : index
    %cst_0 = arith.constant dense<[[5.0072820879405331, 2.1420497309468542, 8.4364357946217474, 3.3512684114489364, 4.8578737173077684, 6.5026873298607608, 4.481183080848961, 1.6018142840321781, 1.6482067031075565, 2.7697353449463433], [8.2796435610104453, 9.7956308688691446, 5.066309369035312, 1.0691978274975567, 7.2754747197326219, 7.4679216752662611, 1.8460472498040226, 1.7245060332115747, 9.828847678500983, 5.8523888503628294], [4.735129046344202, 0.21389279999051047, 9.9823910553584571, 0.22751442405574696, 4.3063298537464378, 1.0300462704374436, 7.1885192597496097, 1.7297134743393461, 7.4494154821665912, 8.2180913094628564], [0.55370097211729696, 7.0871105126860554, 7.7450498540614178, 4.2448327660994876, 1.2746000519648371, 9.4391729894286023, 6.1902689198805465, 6.0312877871821424, 8.7890699247898425, 3.1611885774377635], [8.9903796016343396, 3.4471256572948263, 8.4932841564173884, 9.9373309006088171, 2.6191045587156303, 0.77351004199567641, 1.4024547359632467, 7.454551829233095, 2.6194195569905077, 4.0298520046877577], [4.7641019675563543, 3.8129279818642861, 9.0747728919768225, 6.4920816381757511, 6.7882405668469881, 7.0063465072165911, 5.7386637585592792, 7.5230234961300599, 0.91592641387099771, 8.6646639602141899], [5.6862365678538973, 4.8755032417073192, 9.5859588536709328, 8.1186668576209513, 5.3811119011589454, 3.8280043169558411, 9.9983397606134918, 6.1835824149566241, 3.4201107815517515, 0.84968218962971687], [2.791270331453247, 2.9735813587818685, 3.0654358664150494, 5.4929582569491755, 3.9238922832952996, 9.2657934977933269, 5.0681592194030571, 9.6910348814034712, 2.0972430846802959, 0.96789458347651514], [3.1989914495545624, 3.7607248895716507, 5.5182323136835318, 2.4724154287944913, 7.2920674615977124, 9.7009225179758473, 9.9421519655410044, 2.6109645810252315, 9.0484630420475316, 3.6771724535825703], [6.305746358135309, 7.6948754823713771, 3.6012681436537397, 1.263350310992416, 3.8581878444772943, 7.1047027925517909, 2.1904752468927735, 0.32914734762647391, 3.1668377278172235, 2.0518472657841924]]> : tensor<10x10xf64>
    %0 = bufferization.alloc_tensor() : tensor<10x10xf64>
    %1 = call @assemble_sparse() : () -> tensor<10x10xf64, #sparse>
    %2 = call @matmul(%1, %cst_0, %0) : (tensor<10x10xf64, #sparse>, tensor<10x10xf64>, tensor<10x10xf64>) -> tensor<10x10xf64>
    scf.for %arg0 = %c0 to %c10 step %c1 {
      %4 = vector.transfer_read %2[%arg0, %c0], %cst {in_bounds = [true]} : tensor<10x10xf64>, vector<10xf64>
      vector.print %4 : vector<10xf64>
    }
    %extracted = tensor.extract %2[%c8, %c8] : tensor<10x10xf64>
    %3 = arith.fptosi %extracted : f64 to i64
    return %3 : i64
  }
  func.func @assemble_sparse() -> tensor<10x10xf64, #sparse> {
    %cst = arith.constant dense<[4.7563469999999999, 2.102859, 5.4238689999999998, 5.577680e+00, 3.001240e-01, 4.8357549999999998, 8.8596050000000002, 1.592490e+00, 7.372070e+00, 7.2462879999999998, 5.9191609999999999, 5.9593920000000002, 4.6956530000000001, 6.328630e-01, 3.1591619999999998, 4.7083050000000002, 8.4356449999999992, 5.4309390000000004, 2.1190630000000001, 1.545420e-01, 2.595040e+00, 1.4655819999999999, 1.321259, 3.702925, 3.542246, 6.831162, 1.723510e+00, 7.8729019999999998, 6.0081550000000004, 1.047045]> : tensor<30xf64>
    %cst_0 = arith.constant dense<[0, 1, 5, 7, 14, 16, 21, 25, 27, 29, 30]> : tensor<11xindex>
    %cst_1 = arith.constant dense<[8, 3, 4, 6, 9, 2, 4, 0, 1, 2, 3, 5, 7, 8, 3, 6, 2, 3, 4, 5, 8, 1, 5, 7, 8, 5, 9, 4, 7, 7]> : tensor<30xindex>
    %0 = sparse_tensor.assemble (%cst_0, %cst_1), %cst : (tensor<11xindex>, tensor<30xindex>), tensor<30xf64> to tensor<10x10xf64, #sparse>
    return %0 : tensor<10x10xf64, #sparse>
  }
}


// -----// IR Dump After SparseReinterpretMap (sparse-reinterpret-map) //----- //
#map = affine_map<(d0, d1, d2) -> (d0, d1)>
#map1 = affine_map<(d0, d1, d2) -> (d1, d2)>
#map2 = affine_map<(d0, d1, d2) -> (d0, d2)>
#sparse = #sparse_tensor.encoding<{ map = (d0, d1) -> (d0 : dense, d1 : compressed) }>
module {
  func.func @matmul(%arg0: tensor<10x10xf64, #sparse>, %arg1: tensor<10x10xf64>, %arg2: tensor<10x10xf64>) -> tensor<10x10xf64> {
    %0 = linalg.generic {indexing_maps = [#map, #map1, #map2], iterator_types = ["parallel", "reduction", "parallel"]} ins(%arg0, %arg1 : tensor<10x10xf64, #sparse>, tensor<10x10xf64>) outs(%arg2 : tensor<10x10xf64>) attrs =  {sorted = true} {
    ^bb0(%in: f64, %in_0: f64, %out: f64):
      %1 = arith.mulf %in, %in_0 : f64
      %2 = arith.addf %out, %1 : f64
      linalg.yield %2 : f64
    } -> tensor<10x10xf64>
    return %0 : tensor<10x10xf64>
  }
  func.func @main() -> i64 {
    %c8 = arith.constant 8 : index
    %cst = arith.constant 0.000000e+00 : f64
    %c1 = arith.constant 1 : index
    %c10 = arith.constant 10 : index
    %c0 = arith.constant 0 : index
    %cst_0 = arith.constant dense<[[5.0072820879405331, 2.1420497309468542, 8.4364357946217474, 3.3512684114489364, 4.8578737173077684, 6.5026873298607608, 4.481183080848961, 1.6018142840321781, 1.6482067031075565, 2.7697353449463433], [8.2796435610104453, 9.7956308688691446, 5.066309369035312, 1.0691978274975567, 7.2754747197326219, 7.4679216752662611, 1.8460472498040226, 1.7245060332115747, 9.828847678500983, 5.8523888503628294], [4.735129046344202, 0.21389279999051047, 9.9823910553584571, 0.22751442405574696, 4.3063298537464378, 1.0300462704374436, 7.1885192597496097, 1.7297134743393461, 7.4494154821665912, 8.2180913094628564], [0.55370097211729696, 7.0871105126860554, 7.7450498540614178, 4.2448327660994876, 1.2746000519648371, 9.4391729894286023, 6.1902689198805465, 6.0312877871821424, 8.7890699247898425, 3.1611885774377635], [8.9903796016343396, 3.4471256572948263, 8.4932841564173884, 9.9373309006088171, 2.6191045587156303, 0.77351004199567641, 1.4024547359632467, 7.454551829233095, 2.6194195569905077, 4.0298520046877577], [4.7641019675563543, 3.8129279818642861, 9.0747728919768225, 6.4920816381757511, 6.7882405668469881, 7.0063465072165911, 5.7386637585592792, 7.5230234961300599, 0.91592641387099771, 8.6646639602141899], [5.6862365678538973, 4.8755032417073192, 9.5859588536709328, 8.1186668576209513, 5.3811119011589454, 3.8280043169558411, 9.9983397606134918, 6.1835824149566241, 3.4201107815517515, 0.84968218962971687], [2.791270331453247, 2.9735813587818685, 3.0654358664150494, 5.4929582569491755, 3.9238922832952996, 9.2657934977933269, 5.0681592194030571, 9.6910348814034712, 2.0972430846802959, 0.96789458347651514], [3.1989914495545624, 3.7607248895716507, 5.5182323136835318, 2.4724154287944913, 7.2920674615977124, 9.7009225179758473, 9.9421519655410044, 2.6109645810252315, 9.0484630420475316, 3.6771724535825703], [6.305746358135309, 7.6948754823713771, 3.6012681436537397, 1.263350310992416, 3.8581878444772943, 7.1047027925517909, 2.1904752468927735, 0.32914734762647391, 3.1668377278172235, 2.0518472657841924]]> : tensor<10x10xf64>
    %0 = bufferization.alloc_tensor() : tensor<10x10xf64>
    %1 = call @assemble_sparse() : () -> tensor<10x10xf64, #sparse>
    %2 = call @matmul(%1, %cst_0, %0) : (tensor<10x10xf64, #sparse>, tensor<10x10xf64>, tensor<10x10xf64>) -> tensor<10x10xf64>
    scf.for %arg0 = %c0 to %c10 step %c1 {
      %4 = vector.transfer_read %2[%arg0, %c0], %cst {in_bounds = [true]} : tensor<10x10xf64>, vector<10xf64>
      vector.print %4 : vector<10xf64>
    }
    %extracted = tensor.extract %2[%c8, %c8] : tensor<10x10xf64>
    %3 = arith.fptosi %extracted : f64 to i64
    return %3 : i64
  }
  func.func @assemble_sparse() -> tensor<10x10xf64, #sparse> {
    %cst = arith.constant dense<[4.7563469999999999, 2.102859, 5.4238689999999998, 5.577680e+00, 3.001240e-01, 4.8357549999999998, 8.8596050000000002, 1.592490e+00, 7.372070e+00, 7.2462879999999998, 5.9191609999999999, 5.9593920000000002, 4.6956530000000001, 6.328630e-01, 3.1591619999999998, 4.7083050000000002, 8.4356449999999992, 5.4309390000000004, 2.1190630000000001, 1.545420e-01, 2.595040e+00, 1.4655819999999999, 1.321259, 3.702925, 3.542246, 6.831162, 1.723510e+00, 7.8729019999999998, 6.0081550000000004, 1.047045]> : tensor<30xf64>
    %cst_0 = arith.constant dense<[0, 1, 5, 7, 14, 16, 21, 25, 27, 29, 30]> : tensor<11xindex>
    %cst_1 = arith.constant dense<[8, 3, 4, 6, 9, 2, 4, 0, 1, 2, 3, 5, 7, 8, 3, 6, 2, 3, 4, 5, 8, 1, 5, 7, 8, 5, 9, 4, 7, 7]> : tensor<30xindex>
    %0 = sparse_tensor.assemble (%cst_0, %cst_1), %cst : (tensor<11xindex>, tensor<30xindex>), tensor<30xf64> to tensor<10x10xf64, #sparse>
    return %0 : tensor<10x10xf64, #sparse>
  }
}


// -----// IR Dump After SparsificationPass (sparsification) //----- //
#sparse = #sparse_tensor.encoding<{ map = (d0, d1) -> (d0 : dense, d1 : compressed) }>
module {
  func.func @matmul(%arg0: tensor<10x10xf64, #sparse>, %arg1: tensor<10x10xf64>, %arg2: tensor<10x10xf64>) -> tensor<10x10xf64> {
    %c1 = arith.constant 1 : index
    %c0 = arith.constant 0 : index
    %c10 = arith.constant 10 : index
    %0 = sparse_tensor.values %arg0 : tensor<10x10xf64, #sparse> to memref<?xf64>
    %1 = bufferization.to_memref %arg1 : tensor<10x10xf64> to memref<10x10xf64>
    %2 = bufferization.to_memref %arg2 : tensor<10x10xf64> to memref<10x10xf64>
    %3 = sparse_tensor.positions %arg0 {level = 1 : index} : tensor<10x10xf64, #sparse> to memref<?xindex>
    %4 = sparse_tensor.coordinates %arg0 {level = 1 : index} : tensor<10x10xf64, #sparse> to memref<?xindex>
    scf.for %arg3 = %c0 to %c10 step %c1 {
      %6 = memref.load %3[%arg3] : memref<?xindex>
      %7 = arith.addi %arg3, %c1 : index
      %8 = memref.load %3[%7] : memref<?xindex>
      scf.for %arg4 = %6 to %8 step %c1 {
        %9 = memref.load %4[%arg4] : memref<?xindex>
        %10 = memref.load %0[%arg4] : memref<?xf64>
        scf.for %arg5 = %c0 to %c10 step %c1 {
          %11 = memref.load %2[%arg3, %arg5] : memref<10x10xf64>
          %12 = memref.load %1[%9, %arg5] : memref<10x10xf64>
          %13 = arith.mulf %10, %12 : f64
          %14 = arith.addf %11, %13 : f64
          memref.store %14, %2[%arg3, %arg5] : memref<10x10xf64>
        } {"Emitted from" = "linalg.generic"}
      } {"Emitted from" = "linalg.generic"}
    } {"Emitted from" = "linalg.generic"}
    %5 = bufferization.to_tensor %2 : memref<10x10xf64> to tensor<10x10xf64>
    return %5 : tensor<10x10xf64>
  }
  func.func @main() -> i64 {
    %c8 = arith.constant 8 : index
    %cst = arith.constant 0.000000e+00 : f64
    %c1 = arith.constant 1 : index
    %c10 = arith.constant 10 : index
    %c0 = arith.constant 0 : index
    %cst_0 = arith.constant dense<[[5.0072820879405331, 2.1420497309468542, 8.4364357946217474, 3.3512684114489364, 4.8578737173077684, 6.5026873298607608, 4.481183080848961, 1.6018142840321781, 1.6482067031075565, 2.7697353449463433], [8.2796435610104453, 9.7956308688691446, 5.066309369035312, 1.0691978274975567, 7.2754747197326219, 7.4679216752662611, 1.8460472498040226, 1.7245060332115747, 9.828847678500983, 5.8523888503628294], [4.735129046344202, 0.21389279999051047, 9.9823910553584571, 0.22751442405574696, 4.3063298537464378, 1.0300462704374436, 7.1885192597496097, 1.7297134743393461, 7.4494154821665912, 8.2180913094628564], [0.55370097211729696, 7.0871105126860554, 7.7450498540614178, 4.2448327660994876, 1.2746000519648371, 9.4391729894286023, 6.1902689198805465, 6.0312877871821424, 8.7890699247898425, 3.1611885774377635], [8.9903796016343396, 3.4471256572948263, 8.4932841564173884, 9.9373309006088171, 2.6191045587156303, 0.77351004199567641, 1.4024547359632467, 7.454551829233095, 2.6194195569905077, 4.0298520046877577], [4.7641019675563543, 3.8129279818642861, 9.0747728919768225, 6.4920816381757511, 6.7882405668469881, 7.0063465072165911, 5.7386637585592792, 7.5230234961300599, 0.91592641387099771, 8.6646639602141899], [5.6862365678538973, 4.8755032417073192, 9.5859588536709328, 8.1186668576209513, 5.3811119011589454, 3.8280043169558411, 9.9983397606134918, 6.1835824149566241, 3.4201107815517515, 0.84968218962971687], [2.791270331453247, 2.9735813587818685, 3.0654358664150494, 5.4929582569491755, 3.9238922832952996, 9.2657934977933269, 5.0681592194030571, 9.6910348814034712, 2.0972430846802959, 0.96789458347651514], [3.1989914495545624, 3.7607248895716507, 5.5182323136835318, 2.4724154287944913, 7.2920674615977124, 9.7009225179758473, 9.9421519655410044, 2.6109645810252315, 9.0484630420475316, 3.6771724535825703], [6.305746358135309, 7.6948754823713771, 3.6012681436537397, 1.263350310992416, 3.8581878444772943, 7.1047027925517909, 2.1904752468927735, 0.32914734762647391, 3.1668377278172235, 2.0518472657841924]]> : tensor<10x10xf64>
    %0 = bufferization.alloc_tensor() : tensor<10x10xf64>
    %1 = call @assemble_sparse() : () -> tensor<10x10xf64, #sparse>
    %2 = call @matmul(%1, %cst_0, %0) : (tensor<10x10xf64, #sparse>, tensor<10x10xf64>, tensor<10x10xf64>) -> tensor<10x10xf64>
    scf.for %arg0 = %c0 to %c10 step %c1 {
      %4 = vector.transfer_read %2[%arg0, %c0], %cst {in_bounds = [true]} : tensor<10x10xf64>, vector<10xf64>
      vector.print %4 : vector<10xf64>
    }
    %extracted = tensor.extract %2[%c8, %c8] : tensor<10x10xf64>
    %3 = arith.fptosi %extracted : f64 to i64
    return %3 : i64
  }
  func.func @assemble_sparse() -> tensor<10x10xf64, #sparse> {
    %cst = arith.constant dense<[4.7563469999999999, 2.102859, 5.4238689999999998, 5.577680e+00, 3.001240e-01, 4.8357549999999998, 8.8596050000000002, 1.592490e+00, 7.372070e+00, 7.2462879999999998, 5.9191609999999999, 5.9593920000000002, 4.6956530000000001, 6.328630e-01, 3.1591619999999998, 4.7083050000000002, 8.4356449999999992, 5.4309390000000004, 2.1190630000000001, 1.545420e-01, 2.595040e+00, 1.4655819999999999, 1.321259, 3.702925, 3.542246, 6.831162, 1.723510e+00, 7.8729019999999998, 6.0081550000000004, 1.047045]> : tensor<30xf64>
    %cst_0 = arith.constant dense<[0, 1, 5, 7, 14, 16, 21, 25, 27, 29, 30]> : tensor<11xindex>
    %cst_1 = arith.constant dense<[8, 3, 4, 6, 9, 2, 4, 0, 1, 2, 3, 5, 7, 8, 3, 6, 2, 3, 4, 5, 8, 1, 5, 7, 8, 5, 9, 4, 7, 7]> : tensor<30xindex>
    %0 = sparse_tensor.assemble (%cst_0, %cst_1), %cst : (tensor<11xindex>, tensor<30xindex>), tensor<30xf64> to tensor<10x10xf64, #sparse>
    return %0 : tensor<10x10xf64, #sparse>
  }
}


// -----// IR Dump After StageSparseOperations (stage-sparse-ops) //----- //
func.func @matmul(%arg0: tensor<10x10xf64, #sparse_tensor.encoding<{ map = (d0, d1) -> (d0 : dense, d1 : compressed) }>>, %arg1: tensor<10x10xf64>, %arg2: tensor<10x10xf64>) -> tensor<10x10xf64> {
  %c1 = arith.constant 1 : index
  %c0 = arith.constant 0 : index
  %c10 = arith.constant 10 : index
  %0 = sparse_tensor.values %arg0 : tensor<10x10xf64, #sparse_tensor.encoding<{ map = (d0, d1) -> (d0 : dense, d1 : compressed) }>> to memref<?xf64>
  %1 = bufferization.to_memref %arg1 : tensor<10x10xf64> to memref<10x10xf64>
  %2 = bufferization.to_memref %arg2 : tensor<10x10xf64> to memref<10x10xf64>
  %3 = sparse_tensor.positions %arg0 {level = 1 : index} : tensor<10x10xf64, #sparse_tensor.encoding<{ map = (d0, d1) -> (d0 : dense, d1 : compressed) }>> to memref<?xindex>
  %4 = sparse_tensor.coordinates %arg0 {level = 1 : index} : tensor<10x10xf64, #sparse_tensor.encoding<{ map = (d0, d1) -> (d0 : dense, d1 : compressed) }>> to memref<?xindex>
  scf.for %arg3 = %c0 to %c10 step %c1 {
    %6 = memref.load %3[%arg3] : memref<?xindex>
    %7 = arith.addi %arg3, %c1 : index
    %8 = memref.load %3[%7] : memref<?xindex>
    scf.for %arg4 = %6 to %8 step %c1 {
      %9 = memref.load %4[%arg4] : memref<?xindex>
      %10 = memref.load %0[%arg4] : memref<?xf64>
      scf.for %arg5 = %c0 to %c10 step %c1 {
        %11 = memref.load %2[%arg3, %arg5] : memref<10x10xf64>
        %12 = memref.load %1[%9, %arg5] : memref<10x10xf64>
        %13 = arith.mulf %10, %12 : f64
        %14 = arith.addf %11, %13 : f64
        memref.store %14, %2[%arg3, %arg5] : memref<10x10xf64>
      } {"Emitted from" = "linalg.generic"}
    } {"Emitted from" = "linalg.generic"}
  } {"Emitted from" = "linalg.generic"}
  %5 = bufferization.to_tensor %2 : memref<10x10xf64> to tensor<10x10xf64>
  return %5 : tensor<10x10xf64>
}

// -----// IR Dump After StageSparseOperations (stage-sparse-ops) //----- //
func.func @main() -> i64 {
  %c8 = arith.constant 8 : index
  %cst = arith.constant 0.000000e+00 : f64
  %c1 = arith.constant 1 : index
  %c10 = arith.constant 10 : index
  %c0 = arith.constant 0 : index
  %cst_0 = arith.constant dense<[[5.0072820879405331, 2.1420497309468542, 8.4364357946217474, 3.3512684114489364, 4.8578737173077684, 6.5026873298607608, 4.481183080848961, 1.6018142840321781, 1.6482067031075565, 2.7697353449463433], [8.2796435610104453, 9.7956308688691446, 5.066309369035312, 1.0691978274975567, 7.2754747197326219, 7.4679216752662611, 1.8460472498040226, 1.7245060332115747, 9.828847678500983, 5.8523888503628294], [4.735129046344202, 0.21389279999051047, 9.9823910553584571, 0.22751442405574696, 4.3063298537464378, 1.0300462704374436, 7.1885192597496097, 1.7297134743393461, 7.4494154821665912, 8.2180913094628564], [0.55370097211729696, 7.0871105126860554, 7.7450498540614178, 4.2448327660994876, 1.2746000519648371, 9.4391729894286023, 6.1902689198805465, 6.0312877871821424, 8.7890699247898425, 3.1611885774377635], [8.9903796016343396, 3.4471256572948263, 8.4932841564173884, 9.9373309006088171, 2.6191045587156303, 0.77351004199567641, 1.4024547359632467, 7.454551829233095, 2.6194195569905077, 4.0298520046877577], [4.7641019675563543, 3.8129279818642861, 9.0747728919768225, 6.4920816381757511, 6.7882405668469881, 7.0063465072165911, 5.7386637585592792, 7.5230234961300599, 0.91592641387099771, 8.6646639602141899], [5.6862365678538973, 4.8755032417073192, 9.5859588536709328, 8.1186668576209513, 5.3811119011589454, 3.8280043169558411, 9.9983397606134918, 6.1835824149566241, 3.4201107815517515, 0.84968218962971687], [2.791270331453247, 2.9735813587818685, 3.0654358664150494, 5.4929582569491755, 3.9238922832952996, 9.2657934977933269, 5.0681592194030571, 9.6910348814034712, 2.0972430846802959, 0.96789458347651514], [3.1989914495545624, 3.7607248895716507, 5.5182323136835318, 2.4724154287944913, 7.2920674615977124, 9.7009225179758473, 9.9421519655410044, 2.6109645810252315, 9.0484630420475316, 3.6771724535825703], [6.305746358135309, 7.6948754823713771, 3.6012681436537397, 1.263350310992416, 3.8581878444772943, 7.1047027925517909, 2.1904752468927735, 0.32914734762647391, 3.1668377278172235, 2.0518472657841924]]> : tensor<10x10xf64>
  %0 = bufferization.alloc_tensor() : tensor<10x10xf64>
  %1 = call @assemble_sparse() : () -> tensor<10x10xf64, #sparse_tensor.encoding<{ map = (d0, d1) -> (d0 : dense, d1 : compressed) }>>
  %2 = call @matmul(%1, %cst_0, %0) : (tensor<10x10xf64, #sparse_tensor.encoding<{ map = (d0, d1) -> (d0 : dense, d1 : compressed) }>>, tensor<10x10xf64>, tensor<10x10xf64>) -> tensor<10x10xf64>
  scf.for %arg0 = %c0 to %c10 step %c1 {
    %4 = vector.transfer_read %2[%arg0, %c0], %cst {in_bounds = [true]} : tensor<10x10xf64>, vector<10xf64>
    vector.print %4 : vector<10xf64>
  }
  %extracted = tensor.extract %2[%c8, %c8] : tensor<10x10xf64>
  %3 = arith.fptosi %extracted : f64 to i64
  return %3 : i64
}

// -----// IR Dump After StageSparseOperations (stage-sparse-ops) //----- //
func.func @assemble_sparse() -> tensor<10x10xf64, #sparse_tensor.encoding<{ map = (d0, d1) -> (d0 : dense, d1 : compressed) }>> {
  %cst = arith.constant dense<[4.7563469999999999, 2.102859, 5.4238689999999998, 5.577680e+00, 3.001240e-01, 4.8357549999999998, 8.8596050000000002, 1.592490e+00, 7.372070e+00, 7.2462879999999998, 5.9191609999999999, 5.9593920000000002, 4.6956530000000001, 6.328630e-01, 3.1591619999999998, 4.7083050000000002, 8.4356449999999992, 5.4309390000000004, 2.1190630000000001, 1.545420e-01, 2.595040e+00, 1.4655819999999999, 1.321259, 3.702925, 3.542246, 6.831162, 1.723510e+00, 7.8729019999999998, 6.0081550000000004, 1.047045]> : tensor<30xf64>
  %cst_0 = arith.constant dense<[0, 1, 5, 7, 14, 16, 21, 25, 27, 29, 30]> : tensor<11xindex>
  %cst_1 = arith.constant dense<[8, 3, 4, 6, 9, 2, 4, 0, 1, 2, 3, 5, 7, 8, 3, 6, 2, 3, 4, 5, 8, 1, 5, 7, 8, 5, 9, 4, 7, 7]> : tensor<30xindex>
  %0 = sparse_tensor.assemble (%cst_0, %cst_1), %cst : (tensor<11xindex>, tensor<30xindex>), tensor<30xf64> to tensor<10x10xf64, #sparse_tensor.encoding<{ map = (d0, d1) -> (d0 : dense, d1 : compressed) }>>
  return %0 : tensor<10x10xf64, #sparse_tensor.encoding<{ map = (d0, d1) -> (d0 : dense, d1 : compressed) }>>
}

// -----// IR Dump After LowerSparseOpsToForeach (lower-sparse-ops-to-foreach) //----- //
#sparse = #sparse_tensor.encoding<{ map = (d0, d1) -> (d0 : dense, d1 : compressed) }>
module {
  func.func @matmul(%arg0: tensor<10x10xf64, #sparse>, %arg1: tensor<10x10xf64>, %arg2: tensor<10x10xf64>) -> tensor<10x10xf64> {
    %c1 = arith.constant 1 : index
    %c0 = arith.constant 0 : index
    %c10 = arith.constant 10 : index
    %0 = sparse_tensor.values %arg0 : tensor<10x10xf64, #sparse> to memref<?xf64>
    %1 = bufferization.to_memref %arg1 : tensor<10x10xf64> to memref<10x10xf64>
    %2 = bufferization.to_memref %arg2 : tensor<10x10xf64> to memref<10x10xf64>
    %3 = sparse_tensor.positions %arg0 {level = 1 : index} : tensor<10x10xf64, #sparse> to memref<?xindex>
    %4 = sparse_tensor.coordinates %arg0 {level = 1 : index} : tensor<10x10xf64, #sparse> to memref<?xindex>
    scf.for %arg3 = %c0 to %c10 step %c1 {
      %6 = memref.load %3[%arg3] : memref<?xindex>
      %7 = arith.addi %arg3, %c1 : index
      %8 = memref.load %3[%7] : memref<?xindex>
      scf.for %arg4 = %6 to %8 step %c1 {
        %9 = memref.load %4[%arg4] : memref<?xindex>
        %10 = memref.load %0[%arg4] : memref<?xf64>
        scf.for %arg5 = %c0 to %c10 step %c1 {
          %11 = memref.load %2[%arg3, %arg5] : memref<10x10xf64>
          %12 = memref.load %1[%9, %arg5] : memref<10x10xf64>
          %13 = arith.mulf %10, %12 : f64
          %14 = arith.addf %11, %13 : f64
          memref.store %14, %2[%arg3, %arg5] : memref<10x10xf64>
        } {"Emitted from" = "linalg.generic"}
      } {"Emitted from" = "linalg.generic"}
    } {"Emitted from" = "linalg.generic"}
    %5 = bufferization.to_tensor %2 : memref<10x10xf64> to tensor<10x10xf64>
    return %5 : tensor<10x10xf64>
  }
  func.func @main() -> i64 {
    %c8 = arith.constant 8 : index
    %cst = arith.constant 0.000000e+00 : f64
    %c1 = arith.constant 1 : index
    %c10 = arith.constant 10 : index
    %c0 = arith.constant 0 : index
    %cst_0 = arith.constant dense<[[5.0072820879405331, 2.1420497309468542, 8.4364357946217474, 3.3512684114489364, 4.8578737173077684, 6.5026873298607608, 4.481183080848961, 1.6018142840321781, 1.6482067031075565, 2.7697353449463433], [8.2796435610104453, 9.7956308688691446, 5.066309369035312, 1.0691978274975567, 7.2754747197326219, 7.4679216752662611, 1.8460472498040226, 1.7245060332115747, 9.828847678500983, 5.8523888503628294], [4.735129046344202, 0.21389279999051047, 9.9823910553584571, 0.22751442405574696, 4.3063298537464378, 1.0300462704374436, 7.1885192597496097, 1.7297134743393461, 7.4494154821665912, 8.2180913094628564], [0.55370097211729696, 7.0871105126860554, 7.7450498540614178, 4.2448327660994876, 1.2746000519648371, 9.4391729894286023, 6.1902689198805465, 6.0312877871821424, 8.7890699247898425, 3.1611885774377635], [8.9903796016343396, 3.4471256572948263, 8.4932841564173884, 9.9373309006088171, 2.6191045587156303, 0.77351004199567641, 1.4024547359632467, 7.454551829233095, 2.6194195569905077, 4.0298520046877577], [4.7641019675563543, 3.8129279818642861, 9.0747728919768225, 6.4920816381757511, 6.7882405668469881, 7.0063465072165911, 5.7386637585592792, 7.5230234961300599, 0.91592641387099771, 8.6646639602141899], [5.6862365678538973, 4.8755032417073192, 9.5859588536709328, 8.1186668576209513, 5.3811119011589454, 3.8280043169558411, 9.9983397606134918, 6.1835824149566241, 3.4201107815517515, 0.84968218962971687], [2.791270331453247, 2.9735813587818685, 3.0654358664150494, 5.4929582569491755, 3.9238922832952996, 9.2657934977933269, 5.0681592194030571, 9.6910348814034712, 2.0972430846802959, 0.96789458347651514], [3.1989914495545624, 3.7607248895716507, 5.5182323136835318, 2.4724154287944913, 7.2920674615977124, 9.7009225179758473, 9.9421519655410044, 2.6109645810252315, 9.0484630420475316, 3.6771724535825703], [6.305746358135309, 7.6948754823713771, 3.6012681436537397, 1.263350310992416, 3.8581878444772943, 7.1047027925517909, 2.1904752468927735, 0.32914734762647391, 3.1668377278172235, 2.0518472657841924]]> : tensor<10x10xf64>
    %0 = bufferization.alloc_tensor() : tensor<10x10xf64>
    %1 = call @assemble_sparse() : () -> tensor<10x10xf64, #sparse>
    %2 = call @matmul(%1, %cst_0, %0) : (tensor<10x10xf64, #sparse>, tensor<10x10xf64>, tensor<10x10xf64>) -> tensor<10x10xf64>
    scf.for %arg0 = %c0 to %c10 step %c1 {
      %4 = vector.transfer_read %2[%arg0, %c0], %cst {in_bounds = [true]} : tensor<10x10xf64>, vector<10xf64>
      vector.print %4 : vector<10xf64>
    }
    %extracted = tensor.extract %2[%c8, %c8] : tensor<10x10xf64>
    %3 = arith.fptosi %extracted : f64 to i64
    return %3 : i64
  }
  func.func @assemble_sparse() -> tensor<10x10xf64, #sparse> {
    %cst = arith.constant dense<[4.7563469999999999, 2.102859, 5.4238689999999998, 5.577680e+00, 3.001240e-01, 4.8357549999999998, 8.8596050000000002, 1.592490e+00, 7.372070e+00, 7.2462879999999998, 5.9191609999999999, 5.9593920000000002, 4.6956530000000001, 6.328630e-01, 3.1591619999999998, 4.7083050000000002, 8.4356449999999992, 5.4309390000000004, 2.1190630000000001, 1.545420e-01, 2.595040e+00, 1.4655819999999999, 1.321259, 3.702925, 3.542246, 6.831162, 1.723510e+00, 7.8729019999999998, 6.0081550000000004, 1.047045]> : tensor<30xf64>
    %cst_0 = arith.constant dense<[0, 1, 5, 7, 14, 16, 21, 25, 27, 29, 30]> : tensor<11xindex>
    %cst_1 = arith.constant dense<[8, 3, 4, 6, 9, 2, 4, 0, 1, 2, 3, 5, 7, 8, 3, 6, 2, 3, 4, 5, 8, 1, 5, 7, 8, 5, 9, 4, 7, 7]> : tensor<30xindex>
    %0 = sparse_tensor.assemble (%cst_0, %cst_1), %cst : (tensor<11xindex>, tensor<30xindex>), tensor<30xf64> to tensor<10x10xf64, #sparse>
    return %0 : tensor<10x10xf64, #sparse>
  }
}


// -----// IR Dump After SparseReinterpretMap (sparse-reinterpret-map) //----- //
#sparse = #sparse_tensor.encoding<{ map = (d0, d1) -> (d0 : dense, d1 : compressed) }>
module {
  func.func @matmul(%arg0: tensor<10x10xf64, #sparse>, %arg1: tensor<10x10xf64>, %arg2: tensor<10x10xf64>) -> tensor<10x10xf64> {
    %c1 = arith.constant 1 : index
    %c0 = arith.constant 0 : index
    %c10 = arith.constant 10 : index
    %0 = sparse_tensor.values %arg0 : tensor<10x10xf64, #sparse> to memref<?xf64>
    %1 = bufferization.to_memref %arg1 : tensor<10x10xf64> to memref<10x10xf64>
    %2 = bufferization.to_memref %arg2 : tensor<10x10xf64> to memref<10x10xf64>
    %3 = sparse_tensor.positions %arg0 {level = 1 : index} : tensor<10x10xf64, #sparse> to memref<?xindex>
    %4 = sparse_tensor.coordinates %arg0 {level = 1 : index} : tensor<10x10xf64, #sparse> to memref<?xindex>
    scf.for %arg3 = %c0 to %c10 step %c1 {
      %6 = memref.load %3[%arg3] : memref<?xindex>
      %7 = arith.addi %arg3, %c1 : index
      %8 = memref.load %3[%7] : memref<?xindex>
      scf.for %arg4 = %6 to %8 step %c1 {
        %9 = memref.load %4[%arg4] : memref<?xindex>
        %10 = memref.load %0[%arg4] : memref<?xf64>
        scf.for %arg5 = %c0 to %c10 step %c1 {
          %11 = memref.load %2[%arg3, %arg5] : memref<10x10xf64>
          %12 = memref.load %1[%9, %arg5] : memref<10x10xf64>
          %13 = arith.mulf %10, %12 : f64
          %14 = arith.addf %11, %13 : f64
          memref.store %14, %2[%arg3, %arg5] : memref<10x10xf64>
        } {"Emitted from" = "linalg.generic"}
      } {"Emitted from" = "linalg.generic"}
    } {"Emitted from" = "linalg.generic"}
    %5 = bufferization.to_tensor %2 : memref<10x10xf64> to tensor<10x10xf64>
    return %5 : tensor<10x10xf64>
  }
  func.func @main() -> i64 {
    %c8 = arith.constant 8 : index
    %cst = arith.constant 0.000000e+00 : f64
    %c1 = arith.constant 1 : index
    %c10 = arith.constant 10 : index
    %c0 = arith.constant 0 : index
    %cst_0 = arith.constant dense<[[5.0072820879405331, 2.1420497309468542, 8.4364357946217474, 3.3512684114489364, 4.8578737173077684, 6.5026873298607608, 4.481183080848961, 1.6018142840321781, 1.6482067031075565, 2.7697353449463433], [8.2796435610104453, 9.7956308688691446, 5.066309369035312, 1.0691978274975567, 7.2754747197326219, 7.4679216752662611, 1.8460472498040226, 1.7245060332115747, 9.828847678500983, 5.8523888503628294], [4.735129046344202, 0.21389279999051047, 9.9823910553584571, 0.22751442405574696, 4.3063298537464378, 1.0300462704374436, 7.1885192597496097, 1.7297134743393461, 7.4494154821665912, 8.2180913094628564], [0.55370097211729696, 7.0871105126860554, 7.7450498540614178, 4.2448327660994876, 1.2746000519648371, 9.4391729894286023, 6.1902689198805465, 6.0312877871821424, 8.7890699247898425, 3.1611885774377635], [8.9903796016343396, 3.4471256572948263, 8.4932841564173884, 9.9373309006088171, 2.6191045587156303, 0.77351004199567641, 1.4024547359632467, 7.454551829233095, 2.6194195569905077, 4.0298520046877577], [4.7641019675563543, 3.8129279818642861, 9.0747728919768225, 6.4920816381757511, 6.7882405668469881, 7.0063465072165911, 5.7386637585592792, 7.5230234961300599, 0.91592641387099771, 8.6646639602141899], [5.6862365678538973, 4.8755032417073192, 9.5859588536709328, 8.1186668576209513, 5.3811119011589454, 3.8280043169558411, 9.9983397606134918, 6.1835824149566241, 3.4201107815517515, 0.84968218962971687], [2.791270331453247, 2.9735813587818685, 3.0654358664150494, 5.4929582569491755, 3.9238922832952996, 9.2657934977933269, 5.0681592194030571, 9.6910348814034712, 2.0972430846802959, 0.96789458347651514], [3.1989914495545624, 3.7607248895716507, 5.5182323136835318, 2.4724154287944913, 7.2920674615977124, 9.7009225179758473, 9.9421519655410044, 2.6109645810252315, 9.0484630420475316, 3.6771724535825703], [6.305746358135309, 7.6948754823713771, 3.6012681436537397, 1.263350310992416, 3.8581878444772943, 7.1047027925517909, 2.1904752468927735, 0.32914734762647391, 3.1668377278172235, 2.0518472657841924]]> : tensor<10x10xf64>
    %0 = bufferization.alloc_tensor() : tensor<10x10xf64>
    %1 = call @assemble_sparse() : () -> tensor<10x10xf64, #sparse>
    %2 = call @matmul(%1, %cst_0, %0) : (tensor<10x10xf64, #sparse>, tensor<10x10xf64>, tensor<10x10xf64>) -> tensor<10x10xf64>
    scf.for %arg0 = %c0 to %c10 step %c1 {
      %4 = vector.transfer_read %2[%arg0, %c0], %cst {in_bounds = [true]} : tensor<10x10xf64>, vector<10xf64>
      vector.print %4 : vector<10xf64>
    }
    %extracted = tensor.extract %2[%c8, %c8] : tensor<10x10xf64>
    %3 = arith.fptosi %extracted : f64 to i64
    return %3 : i64
  }
  func.func @assemble_sparse() -> tensor<10x10xf64, #sparse> {
    %cst = arith.constant dense<[4.7563469999999999, 2.102859, 5.4238689999999998, 5.577680e+00, 3.001240e-01, 4.8357549999999998, 8.8596050000000002, 1.592490e+00, 7.372070e+00, 7.2462879999999998, 5.9191609999999999, 5.9593920000000002, 4.6956530000000001, 6.328630e-01, 3.1591619999999998, 4.7083050000000002, 8.4356449999999992, 5.4309390000000004, 2.1190630000000001, 1.545420e-01, 2.595040e+00, 1.4655819999999999, 1.321259, 3.702925, 3.542246, 6.831162, 1.723510e+00, 7.8729019999999998, 6.0081550000000004, 1.047045]> : tensor<30xf64>
    %cst_0 = arith.constant dense<[0, 1, 5, 7, 14, 16, 21, 25, 27, 29, 30]> : tensor<11xindex>
    %cst_1 = arith.constant dense<[8, 3, 4, 6, 9, 2, 4, 0, 1, 2, 3, 5, 7, 8, 3, 6, 2, 3, 4, 5, 8, 1, 5, 7, 8, 5, 9, 4, 7, 7]> : tensor<30xindex>
    %0 = sparse_tensor.assemble (%cst_0, %cst_1), %cst : (tensor<11xindex>, tensor<30xindex>), tensor<30xf64> to tensor<10x10xf64, #sparse>
    return %0 : tensor<10x10xf64, #sparse>
  }
}


// -----// IR Dump After LowerForeachToSCF (lower-sparse-foreach-to-scf) //----- //
func.func @matmul(%arg0: tensor<10x10xf64, #sparse_tensor.encoding<{ map = (d0, d1) -> (d0 : dense, d1 : compressed) }>>, %arg1: tensor<10x10xf64>, %arg2: tensor<10x10xf64>) -> tensor<10x10xf64> {
  %c1 = arith.constant 1 : index
  %c0 = arith.constant 0 : index
  %c10 = arith.constant 10 : index
  %0 = sparse_tensor.values %arg0 : tensor<10x10xf64, #sparse_tensor.encoding<{ map = (d0, d1) -> (d0 : dense, d1 : compressed) }>> to memref<?xf64>
  %1 = bufferization.to_memref %arg1 : tensor<10x10xf64> to memref<10x10xf64>
  %2 = bufferization.to_memref %arg2 : tensor<10x10xf64> to memref<10x10xf64>
  %3 = sparse_tensor.positions %arg0 {level = 1 : index} : tensor<10x10xf64, #sparse_tensor.encoding<{ map = (d0, d1) -> (d0 : dense, d1 : compressed) }>> to memref<?xindex>
  %4 = sparse_tensor.coordinates %arg0 {level = 1 : index} : tensor<10x10xf64, #sparse_tensor.encoding<{ map = (d0, d1) -> (d0 : dense, d1 : compressed) }>> to memref<?xindex>
  scf.for %arg3 = %c0 to %c10 step %c1 {
    %6 = memref.load %3[%arg3] : memref<?xindex>
    %7 = arith.addi %arg3, %c1 : index
    %8 = memref.load %3[%7] : memref<?xindex>
    scf.for %arg4 = %6 to %8 step %c1 {
      %9 = memref.load %4[%arg4] : memref<?xindex>
      %10 = memref.load %0[%arg4] : memref<?xf64>
      scf.for %arg5 = %c0 to %c10 step %c1 {
        %11 = memref.load %2[%arg3, %arg5] : memref<10x10xf64>
        %12 = memref.load %1[%9, %arg5] : memref<10x10xf64>
        %13 = arith.mulf %10, %12 : f64
        %14 = arith.addf %11, %13 : f64
        memref.store %14, %2[%arg3, %arg5] : memref<10x10xf64>
      } {"Emitted from" = "linalg.generic"}
    } {"Emitted from" = "linalg.generic"}
  } {"Emitted from" = "linalg.generic"}
  %5 = bufferization.to_tensor %2 : memref<10x10xf64> to tensor<10x10xf64>
  return %5 : tensor<10x10xf64>
}

// -----// IR Dump After LowerForeachToSCF (lower-sparse-foreach-to-scf) //----- //
func.func @main() -> i64 {
  %c8 = arith.constant 8 : index
  %cst = arith.constant 0.000000e+00 : f64
  %c1 = arith.constant 1 : index
  %c10 = arith.constant 10 : index
  %c0 = arith.constant 0 : index
  %cst_0 = arith.constant dense<[[5.0072820879405331, 2.1420497309468542, 8.4364357946217474, 3.3512684114489364, 4.8578737173077684, 6.5026873298607608, 4.481183080848961, 1.6018142840321781, 1.6482067031075565, 2.7697353449463433], [8.2796435610104453, 9.7956308688691446, 5.066309369035312, 1.0691978274975567, 7.2754747197326219, 7.4679216752662611, 1.8460472498040226, 1.7245060332115747, 9.828847678500983, 5.8523888503628294], [4.735129046344202, 0.21389279999051047, 9.9823910553584571, 0.22751442405574696, 4.3063298537464378, 1.0300462704374436, 7.1885192597496097, 1.7297134743393461, 7.4494154821665912, 8.2180913094628564], [0.55370097211729696, 7.0871105126860554, 7.7450498540614178, 4.2448327660994876, 1.2746000519648371, 9.4391729894286023, 6.1902689198805465, 6.0312877871821424, 8.7890699247898425, 3.1611885774377635], [8.9903796016343396, 3.4471256572948263, 8.4932841564173884, 9.9373309006088171, 2.6191045587156303, 0.77351004199567641, 1.4024547359632467, 7.454551829233095, 2.6194195569905077, 4.0298520046877577], [4.7641019675563543, 3.8129279818642861, 9.0747728919768225, 6.4920816381757511, 6.7882405668469881, 7.0063465072165911, 5.7386637585592792, 7.5230234961300599, 0.91592641387099771, 8.6646639602141899], [5.6862365678538973, 4.8755032417073192, 9.5859588536709328, 8.1186668576209513, 5.3811119011589454, 3.8280043169558411, 9.9983397606134918, 6.1835824149566241, 3.4201107815517515, 0.84968218962971687], [2.791270331453247, 2.9735813587818685, 3.0654358664150494, 5.4929582569491755, 3.9238922832952996, 9.2657934977933269, 5.0681592194030571, 9.6910348814034712, 2.0972430846802959, 0.96789458347651514], [3.1989914495545624, 3.7607248895716507, 5.5182323136835318, 2.4724154287944913, 7.2920674615977124, 9.7009225179758473, 9.9421519655410044, 2.6109645810252315, 9.0484630420475316, 3.6771724535825703], [6.305746358135309, 7.6948754823713771, 3.6012681436537397, 1.263350310992416, 3.8581878444772943, 7.1047027925517909, 2.1904752468927735, 0.32914734762647391, 3.1668377278172235, 2.0518472657841924]]> : tensor<10x10xf64>
  %0 = bufferization.alloc_tensor() : tensor<10x10xf64>
  %1 = call @assemble_sparse() : () -> tensor<10x10xf64, #sparse_tensor.encoding<{ map = (d0, d1) -> (d0 : dense, d1 : compressed) }>>
  %2 = call @matmul(%1, %cst_0, %0) : (tensor<10x10xf64, #sparse_tensor.encoding<{ map = (d0, d1) -> (d0 : dense, d1 : compressed) }>>, tensor<10x10xf64>, tensor<10x10xf64>) -> tensor<10x10xf64>
  scf.for %arg0 = %c0 to %c10 step %c1 {
    %4 = vector.transfer_read %2[%arg0, %c0], %cst {in_bounds = [true]} : tensor<10x10xf64>, vector<10xf64>
    vector.print %4 : vector<10xf64>
  }
  %extracted = tensor.extract %2[%c8, %c8] : tensor<10x10xf64>
  %3 = arith.fptosi %extracted : f64 to i64
  return %3 : i64
}

// -----// IR Dump After LowerForeachToSCF (lower-sparse-foreach-to-scf) //----- //
func.func @assemble_sparse() -> tensor<10x10xf64, #sparse_tensor.encoding<{ map = (d0, d1) -> (d0 : dense, d1 : compressed) }>> {
  %cst = arith.constant dense<[4.7563469999999999, 2.102859, 5.4238689999999998, 5.577680e+00, 3.001240e-01, 4.8357549999999998, 8.8596050000000002, 1.592490e+00, 7.372070e+00, 7.2462879999999998, 5.9191609999999999, 5.9593920000000002, 4.6956530000000001, 6.328630e-01, 3.1591619999999998, 4.7083050000000002, 8.4356449999999992, 5.4309390000000004, 2.1190630000000001, 1.545420e-01, 2.595040e+00, 1.4655819999999999, 1.321259, 3.702925, 3.542246, 6.831162, 1.723510e+00, 7.8729019999999998, 6.0081550000000004, 1.047045]> : tensor<30xf64>
  %cst_0 = arith.constant dense<[0, 1, 5, 7, 14, 16, 21, 25, 27, 29, 30]> : tensor<11xindex>
  %cst_1 = arith.constant dense<[8, 3, 4, 6, 9, 2, 4, 0, 1, 2, 3, 5, 7, 8, 3, 6, 2, 3, 4, 5, 8, 1, 5, 7, 8, 5, 9, 4, 7, 7]> : tensor<30xindex>
  %0 = sparse_tensor.assemble (%cst_0, %cst_1), %cst : (tensor<11xindex>, tensor<30xindex>), tensor<30xf64> to tensor<10x10xf64, #sparse_tensor.encoding<{ map = (d0, d1) -> (d0 : dense, d1 : compressed) }>>
  return %0 : tensor<10x10xf64, #sparse_tensor.encoding<{ map = (d0, d1) -> (d0 : dense, d1 : compressed) }>>
}

// -----// IR Dump After LoopInvariantCodeMotion (loop-invariant-code-motion) //----- //
#sparse = #sparse_tensor.encoding<{ map = (d0, d1) -> (d0 : dense, d1 : compressed) }>
module {
  func.func @matmul(%arg0: tensor<10x10xf64, #sparse>, %arg1: tensor<10x10xf64>, %arg2: tensor<10x10xf64>) -> tensor<10x10xf64> {
    %c1 = arith.constant 1 : index
    %c0 = arith.constant 0 : index
    %c10 = arith.constant 10 : index
    %0 = sparse_tensor.values %arg0 : tensor<10x10xf64, #sparse> to memref<?xf64>
    %1 = bufferization.to_memref %arg1 : tensor<10x10xf64> to memref<10x10xf64>
    %2 = bufferization.to_memref %arg2 : tensor<10x10xf64> to memref<10x10xf64>
    %3 = sparse_tensor.positions %arg0 {level = 1 : index} : tensor<10x10xf64, #sparse> to memref<?xindex>
    %4 = sparse_tensor.coordinates %arg0 {level = 1 : index} : tensor<10x10xf64, #sparse> to memref<?xindex>
    scf.for %arg3 = %c0 to %c10 step %c1 {
      %6 = memref.load %3[%arg3] : memref<?xindex>
      %7 = arith.addi %arg3, %c1 : index
      %8 = memref.load %3[%7] : memref<?xindex>
      scf.for %arg4 = %6 to %8 step %c1 {
        %9 = memref.load %4[%arg4] : memref<?xindex>
        %10 = memref.load %0[%arg4] : memref<?xf64>
        scf.for %arg5 = %c0 to %c10 step %c1 {
          %11 = memref.load %2[%arg3, %arg5] : memref<10x10xf64>
          %12 = memref.load %1[%9, %arg5] : memref<10x10xf64>
          %13 = arith.mulf %10, %12 : f64
          %14 = arith.addf %11, %13 : f64
          memref.store %14, %2[%arg3, %arg5] : memref<10x10xf64>
        } {"Emitted from" = "linalg.generic"}
      } {"Emitted from" = "linalg.generic"}
    } {"Emitted from" = "linalg.generic"}
    %5 = bufferization.to_tensor %2 : memref<10x10xf64> to tensor<10x10xf64>
    return %5 : tensor<10x10xf64>
  }
  func.func @main() -> i64 {
    %c8 = arith.constant 8 : index
    %cst = arith.constant 0.000000e+00 : f64
    %c1 = arith.constant 1 : index
    %c10 = arith.constant 10 : index
    %c0 = arith.constant 0 : index
    %cst_0 = arith.constant dense<[[5.0072820879405331, 2.1420497309468542, 8.4364357946217474, 3.3512684114489364, 4.8578737173077684, 6.5026873298607608, 4.481183080848961, 1.6018142840321781, 1.6482067031075565, 2.7697353449463433], [8.2796435610104453, 9.7956308688691446, 5.066309369035312, 1.0691978274975567, 7.2754747197326219, 7.4679216752662611, 1.8460472498040226, 1.7245060332115747, 9.828847678500983, 5.8523888503628294], [4.735129046344202, 0.21389279999051047, 9.9823910553584571, 0.22751442405574696, 4.3063298537464378, 1.0300462704374436, 7.1885192597496097, 1.7297134743393461, 7.4494154821665912, 8.2180913094628564], [0.55370097211729696, 7.0871105126860554, 7.7450498540614178, 4.2448327660994876, 1.2746000519648371, 9.4391729894286023, 6.1902689198805465, 6.0312877871821424, 8.7890699247898425, 3.1611885774377635], [8.9903796016343396, 3.4471256572948263, 8.4932841564173884, 9.9373309006088171, 2.6191045587156303, 0.77351004199567641, 1.4024547359632467, 7.454551829233095, 2.6194195569905077, 4.0298520046877577], [4.7641019675563543, 3.8129279818642861, 9.0747728919768225, 6.4920816381757511, 6.7882405668469881, 7.0063465072165911, 5.7386637585592792, 7.5230234961300599, 0.91592641387099771, 8.6646639602141899], [5.6862365678538973, 4.8755032417073192, 9.5859588536709328, 8.1186668576209513, 5.3811119011589454, 3.8280043169558411, 9.9983397606134918, 6.1835824149566241, 3.4201107815517515, 0.84968218962971687], [2.791270331453247, 2.9735813587818685, 3.0654358664150494, 5.4929582569491755, 3.9238922832952996, 9.2657934977933269, 5.0681592194030571, 9.6910348814034712, 2.0972430846802959, 0.96789458347651514], [3.1989914495545624, 3.7607248895716507, 5.5182323136835318, 2.4724154287944913, 7.2920674615977124, 9.7009225179758473, 9.9421519655410044, 2.6109645810252315, 9.0484630420475316, 3.6771724535825703], [6.305746358135309, 7.6948754823713771, 3.6012681436537397, 1.263350310992416, 3.8581878444772943, 7.1047027925517909, 2.1904752468927735, 0.32914734762647391, 3.1668377278172235, 2.0518472657841924]]> : tensor<10x10xf64>
    %0 = bufferization.alloc_tensor() : tensor<10x10xf64>
    %1 = call @assemble_sparse() : () -> tensor<10x10xf64, #sparse>
    %2 = call @matmul(%1, %cst_0, %0) : (tensor<10x10xf64, #sparse>, tensor<10x10xf64>, tensor<10x10xf64>) -> tensor<10x10xf64>
    scf.for %arg0 = %c0 to %c10 step %c1 {
      %4 = vector.transfer_read %2[%arg0, %c0], %cst {in_bounds = [true]} : tensor<10x10xf64>, vector<10xf64>
      vector.print %4 : vector<10xf64>
    }
    %extracted = tensor.extract %2[%c8, %c8] : tensor<10x10xf64>
    %3 = arith.fptosi %extracted : f64 to i64
    return %3 : i64
  }
  func.func @assemble_sparse() -> tensor<10x10xf64, #sparse> {
    %cst = arith.constant dense<[4.7563469999999999, 2.102859, 5.4238689999999998, 5.577680e+00, 3.001240e-01, 4.8357549999999998, 8.8596050000000002, 1.592490e+00, 7.372070e+00, 7.2462879999999998, 5.9191609999999999, 5.9593920000000002, 4.6956530000000001, 6.328630e-01, 3.1591619999999998, 4.7083050000000002, 8.4356449999999992, 5.4309390000000004, 2.1190630000000001, 1.545420e-01, 2.595040e+00, 1.4655819999999999, 1.321259, 3.702925, 3.542246, 6.831162, 1.723510e+00, 7.8729019999999998, 6.0081550000000004, 1.047045]> : tensor<30xf64>
    %cst_0 = arith.constant dense<[0, 1, 5, 7, 14, 16, 21, 25, 27, 29, 30]> : tensor<11xindex>
    %cst_1 = arith.constant dense<[8, 3, 4, 6, 9, 2, 4, 0, 1, 2, 3, 5, 7, 8, 3, 6, 2, 3, 4, 5, 8, 1, 5, 7, 8, 5, 9, 4, 7, 7]> : tensor<30xindex>
    %0 = sparse_tensor.assemble (%cst_0, %cst_1), %cst : (tensor<11xindex>, tensor<30xindex>), tensor<30xf64> to tensor<10x10xf64, #sparse>
    return %0 : tensor<10x10xf64, #sparse>
  }
}


// -----// IR Dump After SparseVectorization (sparse-vectorization) //----- //
#map = affine_map<(d0, d1)[s0] -> (4, d0 - d1)>
#sparse = #sparse_tensor.encoding<{ map = (d0, d1) -> (d0 : dense, d1 : compressed) }>
module {
  func.func @matmul(%arg0: tensor<10x10xf64, #sparse>, %arg1: tensor<10x10xf64>, %arg2: tensor<10x10xf64>) -> tensor<10x10xf64> {
    %cst = arith.constant dense<0.000000e+00> : vector<4xf64>
    %c4 = arith.constant 4 : index
    %c1 = arith.constant 1 : index
    %c0 = arith.constant 0 : index
    %c10 = arith.constant 10 : index
    %0 = sparse_tensor.values %arg0 : tensor<10x10xf64, #sparse> to memref<?xf64>
    %1 = bufferization.to_memref %arg1 : tensor<10x10xf64> to memref<10x10xf64>
    %2 = bufferization.to_memref %arg2 : tensor<10x10xf64> to memref<10x10xf64>
    %3 = sparse_tensor.positions %arg0 {level = 1 : index} : tensor<10x10xf64, #sparse> to memref<?xindex>
    %4 = sparse_tensor.coordinates %arg0 {level = 1 : index} : tensor<10x10xf64, #sparse> to memref<?xindex>
    scf.for %arg3 = %c0 to %c10 step %c1 {
      %6 = memref.load %3[%arg3] : memref<?xindex>
      %7 = arith.addi %arg3, %c1 : index
      %8 = memref.load %3[%7] : memref<?xindex>
      scf.for %arg4 = %6 to %8 step %c1 {
        %9 = memref.load %4[%arg4] : memref<?xindex>
        %10 = memref.load %0[%arg4] : memref<?xf64>
        scf.for %arg5 = %c0 to %c10 step %c4 {
          %11 = affine.min #map(%c10, %arg5)[%c4]
          %12 = vector.create_mask %11 : vector<4xi1>
          %13 = vector.maskedload %2[%arg3, %arg5], %12, %cst : memref<10x10xf64>, vector<4xi1>, vector<4xf64> into vector<4xf64>
          %14 = vector.broadcast %10 : f64 to vector<4xf64>
          %15 = vector.maskedload %1[%9, %arg5], %12, %cst : memref<10x10xf64>, vector<4xi1>, vector<4xf64> into vector<4xf64>
          %16 = arith.mulf %14, %15 : vector<4xf64>
          %17 = arith.addf %13, %16 : vector<4xf64>
          vector.maskedstore %2[%arg3, %arg5], %12, %17 : memref<10x10xf64>, vector<4xi1>, vector<4xf64>
        } {"Emitted from" = "linalg.generic"}
      } {"Emitted from" = "linalg.generic"}
    } {"Emitted from" = "linalg.generic"}
    %5 = bufferization.to_tensor %2 : memref<10x10xf64> to tensor<10x10xf64>
    return %5 : tensor<10x10xf64>
  }
  func.func @main() -> i64 {
    %c8 = arith.constant 8 : index
    %cst = arith.constant 0.000000e+00 : f64
    %c1 = arith.constant 1 : index
    %c10 = arith.constant 10 : index
    %c0 = arith.constant 0 : index
    %cst_0 = arith.constant dense<[[5.0072820879405331, 2.1420497309468542, 8.4364357946217474, 3.3512684114489364, 4.8578737173077684, 6.5026873298607608, 4.481183080848961, 1.6018142840321781, 1.6482067031075565, 2.7697353449463433], [8.2796435610104453, 9.7956308688691446, 5.066309369035312, 1.0691978274975567, 7.2754747197326219, 7.4679216752662611, 1.8460472498040226, 1.7245060332115747, 9.828847678500983, 5.8523888503628294], [4.735129046344202, 0.21389279999051047, 9.9823910553584571, 0.22751442405574696, 4.3063298537464378, 1.0300462704374436, 7.1885192597496097, 1.7297134743393461, 7.4494154821665912, 8.2180913094628564], [0.55370097211729696, 7.0871105126860554, 7.7450498540614178, 4.2448327660994876, 1.2746000519648371, 9.4391729894286023, 6.1902689198805465, 6.0312877871821424, 8.7890699247898425, 3.1611885774377635], [8.9903796016343396, 3.4471256572948263, 8.4932841564173884, 9.9373309006088171, 2.6191045587156303, 0.77351004199567641, 1.4024547359632467, 7.454551829233095, 2.6194195569905077, 4.0298520046877577], [4.7641019675563543, 3.8129279818642861, 9.0747728919768225, 6.4920816381757511, 6.7882405668469881, 7.0063465072165911, 5.7386637585592792, 7.5230234961300599, 0.91592641387099771, 8.6646639602141899], [5.6862365678538973, 4.8755032417073192, 9.5859588536709328, 8.1186668576209513, 5.3811119011589454, 3.8280043169558411, 9.9983397606134918, 6.1835824149566241, 3.4201107815517515, 0.84968218962971687], [2.791270331453247, 2.9735813587818685, 3.0654358664150494, 5.4929582569491755, 3.9238922832952996, 9.2657934977933269, 5.0681592194030571, 9.6910348814034712, 2.0972430846802959, 0.96789458347651514], [3.1989914495545624, 3.7607248895716507, 5.5182323136835318, 2.4724154287944913, 7.2920674615977124, 9.7009225179758473, 9.9421519655410044, 2.6109645810252315, 9.0484630420475316, 3.6771724535825703], [6.305746358135309, 7.6948754823713771, 3.6012681436537397, 1.263350310992416, 3.8581878444772943, 7.1047027925517909, 2.1904752468927735, 0.32914734762647391, 3.1668377278172235, 2.0518472657841924]]> : tensor<10x10xf64>
    %0 = bufferization.alloc_tensor() : tensor<10x10xf64>
    %1 = call @assemble_sparse() : () -> tensor<10x10xf64, #sparse>
    %2 = call @matmul(%1, %cst_0, %0) : (tensor<10x10xf64, #sparse>, tensor<10x10xf64>, tensor<10x10xf64>) -> tensor<10x10xf64>
    scf.for %arg0 = %c0 to %c10 step %c1 {
      %4 = vector.transfer_read %2[%arg0, %c0], %cst {in_bounds = [true]} : tensor<10x10xf64>, vector<10xf64>
      vector.print %4 : vector<10xf64>
    }
    %extracted = tensor.extract %2[%c8, %c8] : tensor<10x10xf64>
    %3 = arith.fptosi %extracted : f64 to i64
    return %3 : i64
  }
  func.func @assemble_sparse() -> tensor<10x10xf64, #sparse> {
    %cst = arith.constant dense<[4.7563469999999999, 2.102859, 5.4238689999999998, 5.577680e+00, 3.001240e-01, 4.8357549999999998, 8.8596050000000002, 1.592490e+00, 7.372070e+00, 7.2462879999999998, 5.9191609999999999, 5.9593920000000002, 4.6956530000000001, 6.328630e-01, 3.1591619999999998, 4.7083050000000002, 8.4356449999999992, 5.4309390000000004, 2.1190630000000001, 1.545420e-01, 2.595040e+00, 1.4655819999999999, 1.321259, 3.702925, 3.542246, 6.831162, 1.723510e+00, 7.8729019999999998, 6.0081550000000004, 1.047045]> : tensor<30xf64>
    %cst_0 = arith.constant dense<[0, 1, 5, 7, 14, 16, 21, 25, 27, 29, 30]> : tensor<11xindex>
    %cst_1 = arith.constant dense<[8, 3, 4, 6, 9, 2, 4, 0, 1, 2, 3, 5, 7, 8, 3, 6, 2, 3, 4, 5, 8, 1, 5, 7, 8, 5, 9, 4, 7, 7]> : tensor<30xindex>
    %0 = sparse_tensor.assemble (%cst_0, %cst_1), %cst : (tensor<11xindex>, tensor<30xindex>), tensor<30xf64> to tensor<10x10xf64, #sparse>
    return %0 : tensor<10x10xf64, #sparse>
  }
}


from_scratch.mlir:11:14: error: 'bufferization.to_tensor' op to_tensor ops without `restrict` are not supported by One-Shot Analysis
        %0 = linalg.matmul
             ^
from_scratch.mlir:11:14: note: see current operation: %10 = "bufferization.to_tensor"(%7) : (memref<10x10xf64>) -> tensor<10x10xf64>
// -----// IR Dump After OneShotBufferizePass Failed (one-shot-bufferize) //----- //
#map = affine_map<(d0, d1)[s0] -> (4, d0 - d1)>
#sparse = #sparse_tensor.encoding<{ map = (d0, d1) -> (d0 : dense, d1 : compressed) }>
module {
  func.func @matmul(%arg0: tensor<10x10xf64, #sparse>, %arg1: tensor<10x10xf64>, %arg2: tensor<10x10xf64>) -> tensor<10x10xf64> {
    %cst = arith.constant dense<0.000000e+00> : vector<4xf64>
    %c4 = arith.constant 4 : index
    %c1 = arith.constant 1 : index
    %c0 = arith.constant 0 : index
    %c10 = arith.constant 10 : index
    %0 = sparse_tensor.values %arg0 : tensor<10x10xf64, #sparse> to memref<?xf64>
    %1 = bufferization.to_memref %arg1 : tensor<10x10xf64> to memref<10x10xf64>
    %2 = bufferization.to_memref %arg2 : tensor<10x10xf64> to memref<10x10xf64>
    %3 = sparse_tensor.positions %arg0 {level = 1 : index} : tensor<10x10xf64, #sparse> to memref<?xindex>
    %4 = sparse_tensor.coordinates %arg0 {level = 1 : index} : tensor<10x10xf64, #sparse> to memref<?xindex>
    scf.for %arg3 = %c0 to %c10 step %c1 {
      %6 = memref.load %3[%arg3] : memref<?xindex>
      %7 = arith.addi %arg3, %c1 : index
      %8 = memref.load %3[%7] : memref<?xindex>
      scf.for %arg4 = %6 to %8 step %c1 {
        %9 = memref.load %4[%arg4] : memref<?xindex>
        %10 = memref.load %0[%arg4] : memref<?xf64>
        scf.for %arg5 = %c0 to %c10 step %c4 {
          %11 = affine.min #map(%c10, %arg5)[%c4]
          %12 = vector.create_mask %11 : vector<4xi1>
          %13 = vector.maskedload %2[%arg3, %arg5], %12, %cst : memref<10x10xf64>, vector<4xi1>, vector<4xf64> into vector<4xf64>
          %14 = vector.broadcast %10 : f64 to vector<4xf64>
          %15 = vector.maskedload %1[%9, %arg5], %12, %cst : memref<10x10xf64>, vector<4xi1>, vector<4xf64> into vector<4xf64>
          %16 = arith.mulf %14, %15 : vector<4xf64>
          %17 = arith.addf %13, %16 : vector<4xf64>
          vector.maskedstore %2[%arg3, %arg5], %12, %17 : memref<10x10xf64>, vector<4xi1>, vector<4xf64>
        } {"Emitted from" = "linalg.generic"}
      } {"Emitted from" = "linalg.generic"}
    } {"Emitted from" = "linalg.generic"}
    %5 = bufferization.to_tensor %2 : memref<10x10xf64> to tensor<10x10xf64>
    return %5 : tensor<10x10xf64>
  }
  func.func @main() -> i64 {
    %c8 = arith.constant 8 : index
    %cst = arith.constant 0.000000e+00 : f64
    %c1 = arith.constant 1 : index
    %c10 = arith.constant 10 : index
    %c0 = arith.constant 0 : index
    %cst_0 = arith.constant dense<[[5.0072820879405331, 2.1420497309468542, 8.4364357946217474, 3.3512684114489364, 4.8578737173077684, 6.5026873298607608, 4.481183080848961, 1.6018142840321781, 1.6482067031075565, 2.7697353449463433], [8.2796435610104453, 9.7956308688691446, 5.066309369035312, 1.0691978274975567, 7.2754747197326219, 7.4679216752662611, 1.8460472498040226, 1.7245060332115747, 9.828847678500983, 5.8523888503628294], [4.735129046344202, 0.21389279999051047, 9.9823910553584571, 0.22751442405574696, 4.3063298537464378, 1.0300462704374436, 7.1885192597496097, 1.7297134743393461, 7.4494154821665912, 8.2180913094628564], [0.55370097211729696, 7.0871105126860554, 7.7450498540614178, 4.2448327660994876, 1.2746000519648371, 9.4391729894286023, 6.1902689198805465, 6.0312877871821424, 8.7890699247898425, 3.1611885774377635], [8.9903796016343396, 3.4471256572948263, 8.4932841564173884, 9.9373309006088171, 2.6191045587156303, 0.77351004199567641, 1.4024547359632467, 7.454551829233095, 2.6194195569905077, 4.0298520046877577], [4.7641019675563543, 3.8129279818642861, 9.0747728919768225, 6.4920816381757511, 6.7882405668469881, 7.0063465072165911, 5.7386637585592792, 7.5230234961300599, 0.91592641387099771, 8.6646639602141899], [5.6862365678538973, 4.8755032417073192, 9.5859588536709328, 8.1186668576209513, 5.3811119011589454, 3.8280043169558411, 9.9983397606134918, 6.1835824149566241, 3.4201107815517515, 0.84968218962971687], [2.791270331453247, 2.9735813587818685, 3.0654358664150494, 5.4929582569491755, 3.9238922832952996, 9.2657934977933269, 5.0681592194030571, 9.6910348814034712, 2.0972430846802959, 0.96789458347651514], [3.1989914495545624, 3.7607248895716507, 5.5182323136835318, 2.4724154287944913, 7.2920674615977124, 9.7009225179758473, 9.9421519655410044, 2.6109645810252315, 9.0484630420475316, 3.6771724535825703], [6.305746358135309, 7.6948754823713771, 3.6012681436537397, 1.263350310992416, 3.8581878444772943, 7.1047027925517909, 2.1904752468927735, 0.32914734762647391, 3.1668377278172235, 2.0518472657841924]]> : tensor<10x10xf64>
    %0 = bufferization.alloc_tensor() : tensor<10x10xf64>
    %1 = call @assemble_sparse() : () -> tensor<10x10xf64, #sparse>
    %2 = call @matmul(%1, %cst_0, %0) : (tensor<10x10xf64, #sparse>, tensor<10x10xf64>, tensor<10x10xf64>) -> tensor<10x10xf64>
    scf.for %arg0 = %c0 to %c10 step %c1 {
      %4 = vector.transfer_read %2[%arg0, %c0], %cst {in_bounds = [true]} : tensor<10x10xf64>, vector<10xf64>
      vector.print %4 : vector<10xf64>
    }
    %extracted = tensor.extract %2[%c8, %c8] : tensor<10x10xf64>
    %3 = arith.fptosi %extracted : f64 to i64
    return %3 : i64
  }
  func.func @assemble_sparse() -> tensor<10x10xf64, #sparse> {
    %cst = arith.constant dense<[4.7563469999999999, 2.102859, 5.4238689999999998, 5.577680e+00, 3.001240e-01, 4.8357549999999998, 8.8596050000000002, 1.592490e+00, 7.372070e+00, 7.2462879999999998, 5.9191609999999999, 5.9593920000000002, 4.6956530000000001, 6.328630e-01, 3.1591619999999998, 4.7083050000000002, 8.4356449999999992, 5.4309390000000004, 2.1190630000000001, 1.545420e-01, 2.595040e+00, 1.4655819999999999, 1.321259, 3.702925, 3.542246, 6.831162, 1.723510e+00, 7.8729019999999998, 6.0081550000000004, 1.047045]> : tensor<30xf64>
    %cst_0 = arith.constant dense<[0, 1, 5, 7, 14, 16, 21, 25, 27, 29, 30]> : tensor<11xindex>
    %cst_1 = arith.constant dense<[8, 3, 4, 6, 9, 2, 4, 0, 1, 2, 3, 5, 7, 8, 3, 6, 2, 3, 4, 5, 8, 1, 5, 7, 8, 5, 9, 4, 7, 7]> : tensor<30xindex>
    %0 = sparse_tensor.assemble (%cst_0, %cst_1), %cst : (tensor<11xindex>, tensor<30xindex>), tensor<30xf64> to tensor<10x10xf64, #sparse>
    return %0 : tensor<10x10xf64, #sparse>
  }
}


make: *** [from_scratch.llvm.mlir] Error 1
